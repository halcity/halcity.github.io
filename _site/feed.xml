<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ArthurChiao's Blog</title>
    <description>ArthurChiao's Blog</description>
    <link>http://0.0.0.0:4000/</link>
    <atom:link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 27 Apr 2019 13:16:09 +0800</pubDate>
    <lastBuildDate>Sat, 27 Apr 2019 13:16:09 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      
      <item>
        <title>GoBGP Cheat Sheet</title>
        <description>&lt;h3 id=&quot;tldr&quot;&gt;TL;DR&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/osrg/gobgp&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GoBGP&lt;/code&gt;&lt;/a&gt; is an open source BGP implementation,
implemented in Golang [1].&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/cloudnativelabs/kube-router&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kube-router&lt;/code&gt;&lt;/a&gt; is a 
Kubernetes networking solution with aim to provide operational simplicity
and high performance. &lt;code class=&quot;highlighter-rouge&quot;&gt;kube-router&lt;/code&gt; internally uses &lt;code class=&quot;highlighter-rouge&quot;&gt;GoBGP&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This post serves as a cheat sheet of GoBGP CLIs. Note that command set varies
among different gobgp releases, you should run &lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp -h&lt;/code&gt; to get the full
list of your installed version.&lt;/p&gt;

&lt;p&gt;CLI list of version &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Command&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Used For&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp bmp       [ add | del ]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp global    [ del | policy | rib ]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Manage global settings&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp monitor   [ adj-in | global | neighbor]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp mtr       [ inject ]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp neighbor  [ add | del | update ]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Manage neighbors&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp policy    [ add | as-path | community | del | ext-community | large-community | neighbor | prefix | set | statement ]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp rpki      [ server | table | validate ]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp vrf       [ add | del ]&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Manage VRFs&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For each subcommand, &lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp [subcommand] -h&lt;/code&gt; will print the detailed usage,
e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp global -h&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;gobgp bmp add -h&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Looking at the commands’ outputs is a good way for learning gobgp. So in the
following, we will give some illustrative examples and the respective
outputs.&lt;/p&gt;

&lt;h2 id=&quot;1-bmp&quot;&gt;1 BMP&lt;/h2&gt;

&lt;h2 id=&quot;2-global&quot;&gt;2 Global&lt;/h2&gt;

&lt;p&gt;Check configurations of this BGP agent:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp global
AS:        65342
Router-ID: 192.168.1.101
Listening Port: 179, Addresses: 192.168.1.101, ::1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Check global policies:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp global policy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Check global RIBs (Routing Information Base):&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp global rib
   Network              Next Hop             AS_PATH              Age        Attrs
&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 192.168.100.0/24     192.168.1.101                             00:00:06   &lt;span class=&quot;o&quot;&gt;[{&lt;/span&gt;Origin: i&lt;span class=&quot;o&quot;&gt;}]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# gobgp global rib summary&lt;/span&gt;
Table ipv4-unicast
Destination: 1, Path: 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;TODO: The RIB entries started with &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt; are those that &lt;strong&gt;announced to
neighbors&lt;/strong&gt; by this GoBGP agent?&lt;/p&gt;

&lt;h2 id=&quot;3-monitor&quot;&gt;3 Monitor&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp monitor global rib

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp monitor neighbor
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-mrt&quot;&gt;4 MRT&lt;/h2&gt;

&lt;h2 id=&quot;5-neighbor&quot;&gt;5 Neighbor&lt;/h2&gt;

&lt;p&gt;Check BGP neighbors (peers) of this node:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp neighbor
Peer           AS     Up/Down State       |#Received  Accepted
192.168.255.1 65342 1d 18:32:30 Establ      |        0         0
192.168.255.2 65342 1d 18:28:07 Establ      |        0         0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Neighbor details:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp neighbor 192.168.255.1
BGP neighbor is 192.168.255.1, remote AS 65342
  BGP version 4, remote router ID 192.168.255.1
  BGP state &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; established, up &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;1d 18:55:34
  BGP OutQ &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0, Flops &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0
  Hold &lt;span class=&quot;nb&quot;&gt;time &lt;/span&gt;is 90, keepalive interval is 30 seconds
  Configured hold &lt;span class=&quot;nb&quot;&gt;time &lt;/span&gt;is 90, keepalive interval is 30 seconds

  Neighbor capabilities:
    multiprotocol:
        ipv4-unicast:   advertised and received
    route-refresh:      advertised and received
    extended-nexthop:   received
        Remote: nlri: ipv4-unicast, nexthop: ipv6
    graceful-restart:   received
        Remote: restart &lt;span class=&quot;nb&quot;&gt;time &lt;/span&gt;120 sec
            ipv4-unicast
    4-octet-as: advertised and received
    UnknownCapability&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;66&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:      received
    UnknownCapability&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;67&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:      received
    cisco-route-refresh:        received
  Message statistics:
                         Sent       Rcvd
    Opens:                  1          1
    Notifications:          0          0
    Updates:              517          1
    Keepalives:          5152       5150
    Route Refresh:          0          1
    Discarded:              0          0
    Total:               5670       5153
  Route statistics:
    Advertised:             1
    Received:               0
    Accepted:               0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;6-policy&quot;&gt;6 Policy&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp policy
Name kube_router:
    StatementName kube_router_stmt0:
      Conditions:
        PrefixSet: any clusteripprefixset
        NeighborSet: any externalpeerset
      Actions:
         accept
    StatementName kube_router_stmt1:
      Conditions:
        PrefixSet: any podcidrprefixset
        NeighborSet: any externalpeerset
      Actions:
         accept
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gobgp policy statement
StatementName kube_router_stmt0:
  Conditions:
    PrefixSet: any clusteripprefixset
    NeighborSet: any externalpeerset
  Actions:
     accept
StatementName kube_router_stmt1:
  Conditions:
    PrefixSet: any podcidrprefixset
    NeighborSet: any externalpeerset
  Actions:
     accept
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;7-rpki&quot;&gt;7 RPKI&lt;/h2&gt;

&lt;h2 id=&quot;8-vrf&quot;&gt;8 VRF&lt;/h2&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/osrg/gobgp&quot;&gt;GoBGP: Github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/osrg/gobgp/blob/master/docs/sources/cli-command-syntax.md&quot;&gt;GoBGP CLI syntax&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/cloudnativelabs/kube-router&quot;&gt;kube-router: Github&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        
          <description>&lt;h3 id=&quot;tldr&quot;&gt;TL;DR&lt;/h3&gt;

</description>
        
        <pubDate>Thu, 18 Apr 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/gobgp-cheat-sheet/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/gobgp-cheat-sheet/</guid>
        
        
        <category>gobgp</category>
        
        <category>kube-router</category>
        
      </item>
      
    
      
      <item>
        <title>Ctrip Network Architecture Evolution in the Cloud Computing Era</title>
        <description>&lt;h3 id=&quot;preface&quot;&gt;Preface&lt;/h3&gt;

&lt;p&gt;This article comes from my talk &lt;strong&gt;&lt;em&gt;Ctrip Network Architecture Evolution in the
Cloud Computing Era&lt;/em&gt;&lt;/strong&gt; at &lt;a href=&quot;https://www.bagevent.com/event/GOPS2019-shenzhen&quot;&gt;GOPS 2019
Shenzhen&lt;/a&gt; (a tech conference
in Chinese). The content is gently re-structured to make it more
ease of reading as a post, and slightly updated to correct some inaccuracies.&lt;/p&gt;

&lt;h3 id=&quot;about-me&quot;&gt;About Me&lt;/h3&gt;

&lt;p&gt;I’m currently a senior achitect at Ctrip cloud, and leading the network &amp;amp;
storage development team. My main focus is on &lt;strong&gt;network virtualization&lt;/strong&gt; and
&lt;strong&gt;distributed storage&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Let’s start.&lt;/p&gt;

&lt;p&gt;This post presents Ctrip’s network architecure evolution in the cloud
computing era. The content is as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A brief introduction to Ctrip Cloud&lt;/li&gt;
  &lt;li&gt;VLAN-based L2 Network&lt;/li&gt;
  &lt;li&gt;SDN-based Large L2 Network&lt;/li&gt;
  &lt;li&gt;K8S and Hybrid Network&lt;/li&gt;
  &lt;li&gt;Cloud Native Solutions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;0-about-ctrip-cloud&quot;&gt;0 About Ctrip Cloud&lt;/h2&gt;

&lt;p&gt;Ctrip’s cloud computing team started at ~2013.&lt;/p&gt;

&lt;p&gt;We started our business by providing compute resources to our internal customers
based on OpenStack. Since then, we have developed our own baremetal platform,
and further, deployed container platforms like Mesos and K8S.&lt;/p&gt;

&lt;p&gt;In recent years, we have packed all our cloud services into a unified platform,
we named it CDOS - &lt;strong&gt;&lt;em&gt;Ctrip Datacenter Operating System&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/1.jpg&quot; width=&quot;40%&quot; height=&quot;40%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 1. Ctrip Datacenter Operation System (CDOS)&lt;/p&gt;

&lt;p&gt;CDOS manages all our compute, network and storage resources on both private and
public cloud (from vendors). In the private cloud, we provision VM, BM and container
instances. In the public cloud, we have integrated public cloud vendors like
AWS, Tecent cloud, UCloud, etc to provide VM and container instances to our internal
customers.&lt;/p&gt;

&lt;h3 id=&quot;network-evolution-timeline&quot;&gt;Network Evolution Timeline&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/2.jpg&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 2. Timeline of the Network Architecture Evolution&lt;/p&gt;

&lt;p&gt;Fig 2 is a rough timeline of our network evolution.&lt;/p&gt;

&lt;p&gt;At 2013, we started building our private cloud based on OpenStack, and we chose
a simple VLAN-based &lt;strong&gt;L2 network&lt;/strong&gt; model. The underlying HW network topolopy was
traditional hierarchical network model (3-layer network model).&lt;/p&gt;

&lt;p&gt;At 2016, we evolved to a SDN-based &lt;strong&gt;large L2 network&lt;/strong&gt;, and the underlying HW
network evolved to Spine-Leaf model.&lt;/p&gt;

&lt;p&gt;Starting from 2017, we began to deploy container platforms (mesos, k8s) on both
private and public cloud. In the private cloud, we extended our SDN
solution to integration container networks. On the public cloud, we also
designed our container network solution, and connected the public and private
cloud.&lt;/p&gt;

&lt;p&gt;Now (2019), we are doing some investigations on &lt;strong&gt;cloud native solutions&lt;/strong&gt; to
address the new challenges we are facing.&lt;/p&gt;

&lt;p&gt;Let’s dig into those solutions in more detail.&lt;/p&gt;

&lt;h2 id=&quot;1-vlan-based-l2-network&quot;&gt;1 VLAN-based L2 Network&lt;/h2&gt;

&lt;p&gt;At 2013, we started building our private cloud based on OpenStack, provisioning
VM and BM instances to our internal customers.&lt;/p&gt;

&lt;h3 id=&quot;11-requirements&quot;&gt;1.1 Requirements&lt;/h3&gt;

&lt;p&gt;The requirements for network were as follows:&lt;/p&gt;

&lt;p&gt;First, performance of the virtualized network should not be too bad compared
with baremetal networks, measuring with metrics such as instance-to-instance
latency, throughput, etc.&lt;/p&gt;

&lt;p&gt;Secondly, it should have some L2 isolations to prevent common L2 problems e.g. flooding.&lt;/p&gt;

&lt;p&gt;Thirdly, and this is really important - the &lt;strong&gt;instance IP should be routable&lt;/strong&gt;.
That is to say, we could not utilize any tunnling techniques within the host.&lt;/p&gt;

&lt;p&gt;At last, security concerns were less critical at that time. If sacrificing a
little security could give us a significant performance increase, that would be
acceptable. As in a private cloud environment, we have other means to ensure
security.&lt;/p&gt;

&lt;h3 id=&quot;12-solution-openstack-provider-network-model&quot;&gt;1.2 Solution: OpenStack Provider Network Model&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/3.jpg&quot; width=&quot;25%&quot; height=&quot;25%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 3. OpenStack Provider Network Model&lt;/p&gt;

&lt;p&gt;After some investigation, we chose the OpenStack &lt;strong&gt;&lt;em&gt;provider network model&lt;/em&gt;&lt;/strong&gt;
[1], as depicted in Fig 3.&lt;/p&gt;

&lt;p&gt;The provider network model has following characteristics:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;L2 forwarding&lt;/strong&gt; within host, &lt;strong&gt;L2 forwarding + L3 routing&lt;/strong&gt; outside host&lt;/li&gt;
  &lt;li&gt;Tenant gateways configured on HW devices. So this is a &lt;strong&gt;SW + HW solution&lt;/strong&gt;,
rather than a pure SW solution&lt;/li&gt;
  &lt;li&gt;Instance &lt;strong&gt;IP routable&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt;. This comes mainly from two aspects:
    &lt;ul&gt;
      &lt;li&gt;No overlay encapsulation/decapsulation&lt;/li&gt;
      &lt;li&gt;Gateways configured on HW device, which has far more better performance
compared with SW implemented virtual routers (L3 agent) in OpenStack&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Other aspects in our design:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;L2 segmentation: VLAN&lt;/li&gt;
  &lt;li&gt;ML2: OVS&lt;/li&gt;
  &lt;li&gt;L2 Agent：Neutron OVS Agent&lt;/li&gt;
  &lt;li&gt;L3 Agent: NO&lt;/li&gt;
  &lt;li&gt;DHCP: NO&lt;/li&gt;
  &lt;li&gt;Floating IP: NO&lt;/li&gt;
  &lt;li&gt;Security Group：NO&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;13-hw-network-topology&quot;&gt;1.3 HW Network Topology&lt;/h3&gt;

&lt;p&gt;The HW network topology in our data center is Fig 4.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/4.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 4. Physical Network Topology in the Datacenter&lt;/p&gt;

&lt;p&gt;The bottom part are rack rows.  Each blade in the rack had two physical
NIC, connected to two adjacent ToR for physical HA.&lt;/p&gt;

&lt;p&gt;The above part is a typical &lt;strong&gt;&lt;em&gt;access - aggregate - core&lt;/em&gt;&lt;/strong&gt; hierarchical network
model. Aggregate layer communicates with access layer via L2 forwarding, and
with core layer via L3 routing.&lt;/p&gt;

&lt;p&gt;All OpenStack network gateways are configured on core routers. Besides, there
are HW firewalls connected to core routers to perform some security
enforcements.&lt;/p&gt;

&lt;h3 id=&quot;14-host-network-topology&quot;&gt;1.4 Host Network Topology&lt;/h3&gt;

&lt;p&gt;The virtual network topology within a compute node is shown in Fig 5.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/5.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 5. Designed Virtual Network Topology within A Compute Node&lt;/p&gt;

&lt;p&gt;Some highlights:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Two OVS bridges &lt;code class=&quot;highlighter-rouge&quot;&gt;br-int&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;br-bond&lt;/code&gt;, connected directly&lt;/li&gt;
  &lt;li&gt;Two physical NICs bonded into one virtual device, attached to &lt;code class=&quot;highlighter-rouge&quot;&gt;br-bond&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Host IP address also configured on &lt;code class=&quot;highlighter-rouge&quot;&gt;br-bond&lt;/code&gt;, serving as management IP&lt;/li&gt;
  &lt;li&gt;All instance devices (virtual NICs) attached to &lt;code class=&quot;highlighter-rouge&quot;&gt;br-int&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the picture, &lt;code class=&quot;highlighter-rouge&quot;&gt;inst1&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;inst2&lt;/code&gt; are two instances from different networks.
The numbered devices started from &lt;code class=&quot;highlighter-rouge&quot;&gt;inst1&lt;/code&gt; and ended at &lt;code class=&quot;highlighter-rouge&quot;&gt;inst2&lt;/code&gt; is just the
packet traversing path between the two (cross network) instances. As can be
seen, there are 18 hops in total.&lt;/p&gt;

&lt;p&gt;In contrast, Fig 6 shows the topology in legacy OpenStack provider network
model.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/6.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 6. Virtual Network Topology within A Compute Node in Legacy OpenStack&lt;/p&gt;

&lt;p&gt;The biggest difference here is: &lt;strong&gt;a Linux bridge sits between each instance
and &lt;code class=&quot;highlighter-rouge&quot;&gt;br-int&lt;/code&gt;&lt;/strong&gt;. This is because OpenStack supports a feature called “security
group”, which uses &lt;code class=&quot;highlighter-rouge&quot;&gt;iptables&lt;/code&gt; in the behind. Unfortunately, OVS ports do not
support &lt;code class=&quot;highlighter-rouge&quot;&gt;iptables&lt;/code&gt; rules; but Linux bridge ports do support, so in OpenStack
a Linux bridge is inserted between each instance and &lt;code class=&quot;highlighter-rouge&quot;&gt;br-int&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Except this, other parts are similar, so in this circumstance, the total hops is
24.&lt;/p&gt;

&lt;h3 id=&quot;15-summary&quot;&gt;1.5 Summary&lt;/h3&gt;

&lt;h4 id=&quot;advantages&quot;&gt;Advantages&lt;/h4&gt;

&lt;p&gt;First of all, we simplified OpenStack deployment architecture, removed some
components that we did not need, e.g. L3 agent, DHCP agent, Neutron metadata
agent, etc, and we no longer needed a standalone network node. For a team which
just started private cloud with not so much experience, the developing and
operating costs became relatively low.&lt;/p&gt;

&lt;p&gt;Secondly, we simplified the host network topology by removing security groups.
The total hops between two instances from different networks was decreased from
24 to 18, thus has lower latency.&lt;/p&gt;

&lt;p&gt;Thirdly, we had our gateways configured on HW devices, which had far more
better performance than OpenStack’s pure SW solutions.&lt;/p&gt;

&lt;p&gt;And at last, the instance IP was routable, which benifited a lot to upper layer
systems such as tracking and monitoring systems.&lt;/p&gt;

&lt;h4 id=&quot;disadvantags&quot;&gt;Disadvantags&lt;/h4&gt;

&lt;p&gt;First, as has been said, we removed security groups. So the security is
sacrified at some extent. We compensated this partly by enforcing some security
rules on HW firewalls.&lt;/p&gt;

&lt;p&gt;Secondly, the network provision process was less automatic. For example,
we had to configure the core routers whenever we add/delete networks to/from
OpenStack. Although these operations have a very low frequency, the impact of
core router misconfiguration is dramatic - it could affect the entire network.&lt;/p&gt;

&lt;h2 id=&quot;2-sdn-based-large-l2-network&quot;&gt;2 SDN-based Large L2 Network&lt;/h2&gt;

&lt;h3 id=&quot;21-new-challenges&quot;&gt;2.1 New Challenges&lt;/h3&gt;

&lt;p&gt;Time arrived 2016, due to the scale expansion of our cluster and network, the
VLAN-based L2 network reached some limitations.&lt;/p&gt;

&lt;p&gt;First of all, if you are familiar with data center networks you may know that
&lt;strong&gt;hierachical network model is hard to scale&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Secondly, all the OpenStack gateways were configured on the core
routers, which made them the potential bottleneck and &lt;strong&gt;single point of failure&lt;/strong&gt;.
And more, core router failures will disrupt the entire network, so the &lt;strong&gt;failure
radius is very large&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Another limitation is that our blade was equipped with 2 x 1 Gbps NICs, which was
too old for modern data center and morden applications.&lt;/p&gt;

&lt;p&gt;Besides, the VLAN has its own limitations: flooding in large VLAN segmentations
is still a problem, and number of avialble VLAN IDs is less than 4096.&lt;/p&gt;

&lt;p&gt;On the other hand, we had also some new needs, as such:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Our corp acquired some companies during the past years, and the networks of
those companies needed to connect/integrate to ours. At network
level, we’d like to treat those subsidiary companies as tenants, so we had
multitenancy and VPC needs.&lt;/li&gt;
  &lt;li&gt;We’d like the network provision more automatic, with little human
intervention.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;22-solution-openstack--sdn&quot;&gt;2.2 Solution: OpenStack + SDN&lt;/h3&gt;

&lt;p&gt;Regarding to these requirements, we designed a &lt;strong&gt;HW+SW, OpenStack+SDN&lt;/strong&gt; 
solution jointly with the &lt;strong&gt;&lt;em&gt;data center network team&lt;/em&gt;&lt;/strong&gt; in our corporation,
shifted the network &lt;strong&gt;from L2 to Large L2&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;hw-topology&quot;&gt;HW Topology&lt;/h4&gt;

&lt;p&gt;For the HW network topology, we evolved from the traditional 3-layer hierachical
model to &lt;strong&gt;Spine-Leaf model&lt;/strong&gt;, which gets more and more popular in modern data
centers.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/7.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 7. Spine-Leaf Topology in the New Datacenter&lt;/p&gt;

&lt;p&gt;Spine-Leaf model is full-mesh connected, which means every device in Spine
layer connects to every device in Leaf layer, and there is no connectitiy among
nodes in the same layer. This connectivity pattern brings many benifits:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Shorter traversing path and estimable latency&lt;/strong&gt;: a server could reach any
other server in exactly 3 hops (server-to-server latency)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ease of expansing&lt;/strong&gt;: to increase the bandwidth, just add a node in one
layer and connect it to all other nodes in the other layer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;More resilent to HW failures&lt;/strong&gt;: all nodes are active, node failure radius
is far more smaller than in hierachical model&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For blades, we upgraded the NICs to 10 Gbps, and further to 25 Gbps.&lt;/p&gt;

&lt;h4 id=&quot;sdn-control-and-data-plane&quot;&gt;SDN: Control and Data Plane&lt;/h4&gt;

&lt;p&gt;We have separate control and data planes [2]:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Data plane: VxLAN&lt;/li&gt;
  &lt;li&gt;Control plane: MP-BGP EVPN&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These are standard RFC protocols, refer to [2] for more protocol details and use
cases.&lt;/p&gt;

&lt;p&gt;One additional benefit of this model is that it supports &lt;strong&gt;distributed
gateway&lt;/strong&gt;, which means all leaf nodes are acted as (active) gateways, which
eliminates the performance bottleneck of traditional gateways on core routers.&lt;/p&gt;

&lt;p&gt;This solution physically support multitenancy (via VRF).&lt;/p&gt;

&lt;h4 id=&quot;sdn-components-and-implementation&quot;&gt;SDN: Components And Implementation&lt;/h4&gt;

&lt;p&gt;We developed our own SDN controller &lt;strong&gt;Ctrip Network Controller&lt;/strong&gt; (CNC).&lt;/p&gt;

&lt;p&gt;CNC is a central SDN controller, and manges all Spine and Leaf nodes. It
integrates with Neutron server via Neutron plugins, and is able to dynamically
add configurations to Spine/Leaf nodes.&lt;/p&gt;

&lt;p&gt;Neutron changes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add CNC ML2 &amp;amp; L3 plugins&lt;/li&gt;
  &lt;li&gt;New finite state machine (FSM) for port status&lt;/li&gt;
  &lt;li&gt;New APIs interact with CNC&lt;/li&gt;
  &lt;li&gt;DB schema changes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is the monitoring panel for the neutron port states in a real data center.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/8.png&quot; width=&quot;40%&quot; height=&quot;40%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 8. Monitoring Panel for Neutron Port States&lt;/p&gt;

&lt;h3 id=&quot;23-hw--sw-topology&quot;&gt;2.3 HW + SW Topology&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/9.png&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 9. HW + SW Topology of the Designed SDN Solution&lt;/p&gt;

&lt;p&gt;Fig 9 is the overall HW + SW topology.&lt;/p&gt;

&lt;p&gt;VxLAN encap/decap is done on the leaf
nodes. If we draw a horizeontal line to cross all Leaf nodes, this line splits
the entire network into underlay and overlay. The bottom part (below leaf)
belongs to underlay and is isolated by VLAN; The above part (above leaf) is
overlay and isolated by VxLAN.&lt;/p&gt;

&lt;p&gt;Underlay is controlled by Neutron server, OVS and neutron-ovs-agent, overlay is
controlled by CNC. CNC integrates with Neutron via Neutron plugins.&lt;/p&gt;

&lt;p&gt;As has been said, this is a joint work by cloud network team &amp;amp; data center
network team. We cloud network team focuses mainly on the underlay part.&lt;/p&gt;

&lt;h3 id=&quot;24-spawn-an-instance&quot;&gt;2.4 Spawn An Instance&lt;/h3&gt;

&lt;p&gt;In this solution, when spawning an instance, how the instance’s network gets reachable?&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/10.png&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 10. Flow of Spawn An Instance&lt;/p&gt;

&lt;p&gt;Major steps depicted in Fig 10:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Nova API (controller node): Create instance -&amp;gt; schedule to one compute node&lt;/li&gt;
  &lt;li&gt;Nova compute: spawn instance on this node&lt;/li&gt;
  &lt;li&gt;Nova compute -&amp;gt; Neutron server: create neutron port&lt;/li&gt;
  &lt;li&gt;Neutron server: create port (IP, MAC, GW, etc)&lt;/li&gt;
  &lt;li&gt;Neutron server -&amp;gt; CNC plugin -&amp;gt; CNC: send port info&lt;/li&gt;
  &lt;li&gt;CNC: save port info to its own DB&lt;/li&gt;
  &lt;li&gt;Neutron server -&amp;gt; Nova compute: return the created port’s info&lt;/li&gt;
  &lt;li&gt;Nova compute: create network device (virtual NIC) for instance, configure device (IP, MAC, GW, etc), then attach it to OVS&lt;/li&gt;
  &lt;li&gt;OVS agent: detect new device attached -&amp;gt; configure OVS (add flow) -&amp;gt; &lt;strong&gt;Underlay network OK&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Nova compute -&amp;gt; Neutron server: update port &lt;code class=&quot;highlighter-rouge&quot;&gt;host_id&lt;/code&gt;. The message is something like this: port &lt;code class=&quot;highlighter-rouge&quot;&gt;1234&lt;/code&gt; is on host &lt;code class=&quot;highlighter-rouge&quot;&gt;node-1&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Neutron server -&amp;gt; CNC: update port &lt;code class=&quot;highlighter-rouge&quot;&gt;host_id&lt;/code&gt;, something like this: port &lt;code class=&quot;highlighter-rouge&quot;&gt;1234&lt;/code&gt; is on host &lt;code class=&quot;highlighter-rouge&quot;&gt;node-1&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;CNC: retrieve database, get the leaf interfaces that &lt;code class=&quot;highlighter-rouge&quot;&gt;node-1&lt;/code&gt; connected to, dynamically add configurations to these interfaces -&amp;gt; &lt;strong&gt;Overlay network OK&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Both underlay and overlay networks OK -&amp;gt; instance reachable&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In Fig 10, black lines are legacy OpenStack flows, and blue lines are newly
added by us.&lt;/p&gt;

&lt;h3 id=&quot;25-summary&quot;&gt;2.5 Summary&lt;/h3&gt;

&lt;p&gt;A summary of the SDN-based large L2 network solution.&lt;/p&gt;

&lt;h4 id=&quot;hw&quot;&gt;HW&lt;/h4&gt;

&lt;p&gt;First, HW network model evolved from hierarchical (3-layer) network to
Spine-Leaf (2-tier). With the Spine-Leaf full-mesh connectivity,
server-to-server latency gets more lower.  Spine-Leaf also supports distributed
gateway, which means all leaf nodes act as gateway for the same network, not
only decreased the traversing path, but also alleviated the bottleneck of
central gateways.&lt;/p&gt;

&lt;p&gt;Another benefit of full-mesh connectivity is that the HW network are now more
resilient to failures. All devices are active rather than active-backup
(traditional 3-layer model), thus when one device fails, it has far more
smaller failure radius.&lt;/p&gt;

&lt;h4 id=&quot;sw&quot;&gt;SW&lt;/h4&gt;

&lt;p&gt;For the SW part, we developed our own SDN controller, and integrated it with
OpenStack neutron via plugins.  The SDN controller cloud dynamically send
configurations to HW devices.&lt;/p&gt;

&lt;p&gt;Although we have only mentioned VM here, this solution actually
supports both VM and BM provision.&lt;/p&gt;

&lt;h4 id=&quot;multi-tenancy--vpc-support&quot;&gt;Multi-tenancy &amp;amp; VPC support&lt;/h4&gt;

&lt;p&gt;At last, this solution supports multi-tenancy and VPC.&lt;/p&gt;

&lt;h2 id=&quot;3-k8s--hybrid-cloud-network&quot;&gt;3 K8S &amp;amp; Hybrid Cloud Network&lt;/h2&gt;

&lt;p&gt;At 2017, we started to deploy container platforms, migrating some
applications from VM/BM to containers.&lt;/p&gt;

&lt;p&gt;Container orchestrators (e.g. Mesos, K8S) has different characteristics compared
with VM orchestrator (e.g OpenStack), such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Large scale instances, 10K ~ 100K containers per cluster is commonly seen&lt;/li&gt;
  &lt;li&gt;Higher deploy/destroy frequencies&lt;/li&gt;
  &lt;li&gt;Shorter spawn/destroy time: ~10s (VM: ~100s)&lt;/li&gt;
  &lt;li&gt;Container failure/drifting is the norm rather than exception&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;31-k8s-network-in-private-cloud&quot;&gt;3.1 K8S Network In Private Cloud&lt;/h3&gt;

&lt;p&gt;Characteristics of container platform raised new requirements to the network.&lt;/p&gt;

&lt;h4 id=&quot;311-network-requirements&quot;&gt;3.1.1 Network Requirements&lt;/h4&gt;

&lt;p&gt;First, The network API must be high performance, and supporting concurrency.&lt;/p&gt;

&lt;p&gt;Secondly, whether using an agent or a binary to configure network (create vNICs
and configure them), it should be fast enough.&lt;/p&gt;

&lt;p&gt;To sucessfully sell container platforms to our customers, we must keep
a considerable amount of compatibility with existing systems.&lt;/p&gt;

&lt;p&gt;One of these is: we must &lt;strong&gt;keep the IP address unchanged when container drifts
from one node to another&lt;/strong&gt;. This is an anti-pattern to container platform’s
philosophy, as those orchestrators are desgined to weaken the IP address: users
should only see the service that a container exposed, but not the IP address of
a single container.  The reason why we have to comprimise here is that in
OpenStack age, VM migration keeps the IP unchanged. So lots of outer systems
assumed that IP address is an immutable attribute of an instance during its
lifecycle, and they designed their systems based on this assumption. If we
suddenly break this assumption, lots of systems (SOA, SLB, etc) need to be
refactored, and this is out of our control.&lt;/p&gt;

&lt;h4 id=&quot;312-solution-extend-sdn-to-support-mesosk8s&quot;&gt;3.1.2 Solution: Extend SDN to Support Mesos/K8S&lt;/h4&gt;

&lt;p&gt;In private cloud, we decided to extend our SDN solution to integrate container
networks. We reused existing infrastructures, including Neutron, CNC, OVS,
Neutron-OVS-Agent. And then developed a CNI plugin for neutron.&lt;/p&gt;

&lt;p&gt;Some changes or newly added components listed below.&lt;/p&gt;

&lt;h5 id=&quot;neutron-changes&quot;&gt;Neutron Changes&lt;/h5&gt;

&lt;p&gt;First, we added some new APIs, e.g. legacy Neutron supports only allocating port
by network ID, we added label attributes to Neutron &lt;code class=&quot;highlighter-rouge&quot;&gt;networks&lt;/code&gt; model, supporting
allocating port by network labels. For example, CNI plugin will say, &lt;strong&gt;&lt;em&gt;“I want
a port allocated from any network with ‘prod-env’ label”&lt;/em&gt;&lt;/strong&gt;. This decouples K8S
from OpenStack details and is more scalable, because a label could mapping to
any number of networks.&lt;/p&gt;

&lt;p&gt;Next, we did some performance optimizations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add Bulk port API&lt;/li&gt;
  &lt;li&gt;Database access optimizations&lt;/li&gt;
  &lt;li&gt;Async API for high concurrency&lt;/li&gt;
  &lt;li&gt;Critical path refactor&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We also backported some new features from upstream, e.g. graceful OVS agent
restart, a big benefit for network operators.&lt;/p&gt;

&lt;h5 id=&quot;new-k8s-cni-plugin-for-neutron&quot;&gt;New K8S CNI plugin for neutron&lt;/h5&gt;

&lt;p&gt;K8S CNI plugin creates and deletes networks for each Pod. The jobs it does are
much the same with other CNI plugins (e.g Calico, Flannel): creates veth pair,
attaches to OVS and container netns, configures MAC, IP, GW, etc.&lt;/p&gt;

&lt;p&gt;Two big differences seperating it from other plugins:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Communicate with Neutron (central IPAM) to allocate/free port (IP address)&lt;/li&gt;
  &lt;li&gt;Update port information to neutron server after finishing&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;existing-network-servicescomponents-upgrade&quot;&gt;Existing network services/components upgrade&lt;/h5&gt;

&lt;p&gt;We also upgraded some network infra. E.g. we’ve hit some OVS bugs
during past few years:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ovs-vswitchd 100% CPU bug [3]&lt;/li&gt;
  &lt;li&gt;OVS port mirror bug [4]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So we upgraded OVS to the latest LTS &lt;code class=&quot;highlighter-rouge&quot;&gt;2.5.6&lt;/code&gt;, which has solved those bugs.&lt;/p&gt;

&lt;h4 id=&quot;313-pod-drifting&quot;&gt;3.1.3 Pod Drifting&lt;/h4&gt;

&lt;p&gt;Network steps in starting a container are much the same as in
spawning a VM in Fig. 10, so we do not detail it here.&lt;/p&gt;

&lt;p&gt;Fig 11 shows how the IP address stayed unchanged during container drifting. The
key point is: CNI plugin knows how to join some Pod labels into a port &lt;code class=&quot;highlighter-rouge&quot;&gt;name&lt;/code&gt;.
This &lt;code class=&quot;highlighter-rouge&quot;&gt;name&lt;/code&gt; is unique index, so the second node (node B) could get the IP
address information from neutron with this name.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/11.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 11. Pod drifting with the same IP within a K8S cluster &lt;/p&gt;

&lt;h4 id=&quot;314-summary&quot;&gt;3.1.4 Summary&lt;/h4&gt;

&lt;p&gt;A quick summary:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We integrated container platform into existing infra in a short time&lt;/li&gt;
  &lt;li&gt;Single global IPAM manages all VM/BM/container networks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sum up, &lt;strong&gt;this is the latest network solution int private cloud&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Current deployment scale of this new solution:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;4 availability zones (AZ)&lt;/li&gt;
  &lt;li&gt;Up to 500+ physical nodes (VM/BM/Container hosts) per AZ&lt;/li&gt;
  &lt;li&gt;Up to 500+ instances per host&lt;/li&gt;
  &lt;li&gt;Up to 20K+ instances per AZ&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;315-future-architecture&quot;&gt;3.1.5 Future Architecture&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/12.png&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 12. Layered view of the future network architecture&lt;/p&gt;

&lt;p&gt;Fig 12 is an architucture we’d like to achieve in the future.&lt;/p&gt;

&lt;p&gt;First, the network will be split into underlay and overlay planes. IaaS and other
Infra services deploy in underlay network, e.g OpenStack, CNC. Then creating VPC
in overlay networks, and deploying VM and BM instances in VPCs. These have been
achieved.&lt;/p&gt;

&lt;p&gt;One K8S cluster will be kept within one VPC, and each cluster manages its own
networks. All access via IP address should be kept within that cluster, and all
access from outside of the cluster should go through Ingress - the K8S native
way. We haven’t achieved this, because it needs lots of SW and HW system
refactors.&lt;/p&gt;

&lt;h3 id=&quot;32-k8s-on-public-cloud&quot;&gt;3.2 K8S on Public Cloud&lt;/h3&gt;

&lt;h4 id=&quot;321-requirements&quot;&gt;3.2.1 Requirements&lt;/h4&gt;

&lt;p&gt;Ctrip started its internationalization in recent years, in the techical layer,
we should be able to support global deployment, which means provisioning
resources outside mainland China.&lt;/p&gt;

&lt;p&gt;Building overseas private cloud is not practical, as the designing and building
process will take too much time. So we chose to purchase public cloud
resources, and integrate them to our private cloud infra, turning CDOS into
a hybrid cloud platform. CDOS API will abstract out all vendor-specific details,
and provide a unified API to our internal customers/systems.&lt;/p&gt;

&lt;p&gt;This work involves networking solutions on public cloud platforms.&lt;/p&gt;

&lt;h4 id=&quot;322-k8s-network-solution-on-aws&quot;&gt;3.2.2 K8S Network Solution on AWS&lt;/h4&gt;

&lt;p&gt;Taking AWS as example, let’s see our K8S network solution.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/13.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 13. K8S network solution on public cloud vendor (AWS)&lt;/p&gt;

&lt;p&gt;First, spawning EC2 instances as K8S nodes on AWS. Then we developed a CNI
plugin to dynamically plug/unplug ENI to EC2 [5, 6].  The ENIs were given to
Pods as its vNIC.&lt;/p&gt;

&lt;p&gt;We developed a global IPAM service (just like Neutron in OpenStack) and deployed
in VPC, it manages all network resources, and calls AWS APIs for real
allocation/deallocation.&lt;/p&gt;

&lt;p&gt;The CNI plugin also supports attach/detach floating IP to Pods.  And again, the
IP address stays the same when Pod drifts from one node to another.  This is
achieved by ENI drifting.&lt;/p&gt;

&lt;h4 id=&quot;323-vpcs-over-the-globe&quot;&gt;3.2.3 VPCs over the globe&lt;/h4&gt;

&lt;p&gt;Fig 14 is the global picture of our VPCs in both private and public cloud.&lt;/p&gt;

&lt;p&gt;We have some VPCs in our private cloud distributed in Shanghai and Nantong.
Outside mainland China, we have VPCs on public cloud regions, including
Seoul, Moscow, Frankfurt, California, Hong Kong, Melborne, and many more.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/14.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 14. VPCs distributed over the globe &lt;/p&gt;

&lt;p&gt;Network segments of VPCs on both prviate and public cloud are arranged to be
non-overlapped, so we connect them with direct connect techniques, and the IP
is routable (if needed).&lt;/p&gt;

&lt;p&gt;OK, right here, I have introduced all of the major aspects of our network
evolution. In the next, let’s see some new challenges in the cloud native age.&lt;/p&gt;

&lt;h2 id=&quot;4-cloud-native-solutions&quot;&gt;4 Cloud Native Solutions&lt;/h2&gt;

&lt;p&gt;The current network solution faced some new challenges in cloud native era:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Central IPAM may be the new bottleneck, and Neutron is not designed for performance&lt;/li&gt;
  &lt;li&gt;Cloud native prefers local IPAM (IPAM per host)&lt;/li&gt;
  &lt;li&gt;Large failure radius: IP drifting among entire AZ&lt;/li&gt;
  &lt;li&gt;Dense deployment of containers will hit HW limit of leaf nodes&lt;/li&gt;
  &lt;li&gt;Increasingly strong host firewall (L4-L7) needs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So we are doing some investigations on new solutions, e.g. Calico, Cilium.
Calico has been widely used nowadays, so I’ll skip it and give some
introduction to a relatively less well-known solution: Cilium.&lt;/p&gt;

&lt;h3 id=&quot;41-cilium-overview&quot;&gt;4.1 Cilium Overview&lt;/h3&gt;

&lt;p&gt;Cilium is a brand-new solution [7], and it needs Kernel 4.8+.&lt;/p&gt;

&lt;p&gt;Cilium’s core relies on eBPF/BPF, which is a bytecode sandbox in Linux kernel.
If you never heard of this, think BPF as iptables, it could hook and
modify packets in the kernel stack, we will tell the difference later.&lt;/p&gt;

&lt;p&gt;Cilium relies on BPF to achieve connectivity &amp;amp; security.
It has following components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CLI&lt;/li&gt;
  &lt;li&gt;Plugin for orchestrator (Mesos, K8S, etc) integration&lt;/li&gt;
  &lt;li&gt;Policy repository (etcd or consul)&lt;/li&gt;
  &lt;li&gt;Host agent (also acts as local IPAM)&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/15.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 15. Cilium&lt;/p&gt;

&lt;h3 id=&quot;42-host-networking&quot;&gt;4.2 Host Networking&lt;/h3&gt;

&lt;p&gt;Any networking solution could be split into two major parts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Host-networking: instance-to-instance communication, and instance-to-host communication&lt;/li&gt;
  &lt;li&gt;Multi-host-networking: cross-host and/or cross-subnet instance-to-instance communication&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s see the host-networking of Cilium.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/ctrip-net-evolution/16.png&quot; width=&quot;45%&quot; height=&quot;45%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Fig 16. Cilium host-networking&lt;/p&gt;

&lt;p&gt;First, each host runs a Cilium agent, the agent acts as local IPAM, and manages its CIDR.
Upon starting, it creates a veth pair named &lt;code class=&quot;highlighter-rouge&quot;&gt;cilium_host &amp;lt;--&amp;gt; cilium_net&lt;/code&gt;, and
sets the first IP address of the CIDR to &lt;code class=&quot;highlighter-rouge&quot;&gt;cilium_host&lt;/code&gt;, which then acts as the
gateway of the CIDR.&lt;/p&gt;

&lt;p&gt;When starting a Pod in this host, the CNI plugin will:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;allocate an IP address from this CIDR&lt;/li&gt;
  &lt;li&gt;create a veth pair for the Pod&lt;/li&gt;
  &lt;li&gt;configure the IP, gateway info to Pod&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then the topology will look like Fig 16. Note that there is no OVS or
Linux bridges among the Pods’ veth pairs and &lt;code class=&quot;highlighter-rouge&quot;&gt;cilium_host &amp;lt;--&amp;gt; cilium_net&lt;/code&gt;.
Actually there are also no special ARP entries or route entries to connect the
veth pairs. Then how does the packet been forwarded when it reaches the veth
pair end? The answer is &lt;strong&gt;BPF code&lt;/strong&gt;. CNI plugin will &lt;strong&gt;generate BPF rules,
compile them and inject them into kernel&lt;/strong&gt; to bridge the gaps between veth pairs.&lt;/p&gt;

&lt;p&gt;Summary of cilium host networking:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Inst-to-inst: BPF + Kernel Stack L2 forward&lt;/li&gt;
  &lt;li&gt;Inst-to-host: BPF + L3 Routing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;43-multi-host-networking&quot;&gt;4.3 Multi-host networking&lt;/h3&gt;

&lt;p&gt;For multi-host networking, Cilium provides two commonly used ways:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;VxLAN overlay&lt;/li&gt;
  &lt;li&gt;BGP direct routing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If using VxLAN, Cilium will create a &lt;code class=&quot;highlighter-rouge&quot;&gt;cilium_vxlan&lt;/code&gt; device in each host, and do
VxLAN encap/decap by software. The performance will be a big concern, although
VxLAN HW offload will partly alleviate the burden.&lt;/p&gt;

&lt;p&gt;BGP is another choice. In this case, you need to run a BGP agent in each host,
the BGP agent will do peering with outside network. This needs data center
network support. On public cloud, you could also try the BGP API.
BGP solution has better performance compared with VxLAN overlay, and more
importantly, it makes the container IP routable.&lt;/p&gt;

&lt;h3 id=&quot;44-pros--cons&quot;&gt;4.4 Pros &amp;amp; Cons&lt;/h3&gt;

&lt;p&gt;Here is a brief comparison according to my understanding and experiment.&lt;/p&gt;

&lt;h4 id=&quot;pros&quot;&gt;Pros&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;K8S-native L4-L7 security policy support&lt;/li&gt;
  &lt;li&gt;High performance network policy enforcement&lt;/li&gt;
  &lt;li&gt;Theoretical complexity: BPF O(1) vs iptables O(n)&lt;/li&gt;
  &lt;li&gt;High performance forwarding plane (veth pair, IPVLAN)&lt;/li&gt;
  &lt;li&gt;Dual stack support (IPv4/IPv6)&lt;/li&gt;
  &lt;li&gt;Support run over flannel (Cilium only handles network policy)&lt;/li&gt;
  &lt;li&gt;Active community
    &lt;ul&gt;
      &lt;li&gt;Development driven by a company&lt;/li&gt;
      &lt;li&gt;Core developers from kernel community&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cons&quot;&gt;Cons&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Latest kernel (4.8+ at least, 4.14+ better) needed&lt;/strong&gt;. lots of companies’
PROD environments run kernels older than this.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Not enough user stories &amp;amp; best practices yet&lt;/strong&gt;. Everyone say Cilium is
brilliant, but no one claim they have been widely used in their large scale
PROD environments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;High dev &amp;amp; ops costs&lt;/strong&gt;. Compared with iptables-based solutions, e.g. Calico.
Big companies usually have customization needs because all of reasons, e.g.
compatibility with old systems to not break the business. The development
would need a gentle understanding with kernel stack: you should be familir
with kernel data structures, know the packet traversing path, have a
considerable experience with C programming - as BPF code is written in C.&lt;/p&gt;

&lt;p&gt;Trouble shooting and debugging. You should equipped yourself with Cilium trouble
shooting skills, which are different from iptables-based solutions. While in
many cases, their maybe a shortage of proper trouble shooting tools.&lt;/p&gt;

&lt;p&gt;But at last, &lt;strong&gt;Cilium/eBPF is still one of the most exciting techs rised in
recent years&lt;/strong&gt;, and it’s still under fast developing. So, have a try and find
the fun!&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.openstack.org/neutron/rocky/admin/intro-os-networking.html&quot;&gt;OpenStack Doc: Networking Concepts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cisco.com/c/en/us/products/collateral/switches/nexus-7000-series-switches/white-paper-c11-737022.pdf&quot;&gt;Cisco Data Center Spine-and-Leaf Architecture: Design Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mail.openvswitch.org/pipermail/ovs-dev/2014-October/290600.html&quot;&gt;ovs-vswitchd: Fix high cpu utilization when acquire idle lock fails&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://bugs.launchpad.net/cloud-archive/+bug/1639273&quot;&gt;openvswitch port mirroring only mirrors egress traffic&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/lyft/cni-ipvlan-vpc-k8s&quot;&gt;Lyft CNI plugin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/aspyker/container-world-2018&quot;&gt;Netflix: run container at scale&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cilium.io/&quot;&gt;Cilium Project&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arthurchiao.github.io/blog/cilium-cheat-sheet/&quot;&gt;Cilium Cheat Sheet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arthurchiao.github.io/blog/cilium-code-walk-through-create-network/&quot;&gt;Cilium Code Walk Through: CNI Create Network&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        
          <description>&lt;h3 id=&quot;preface&quot;&gt;Preface&lt;/h3&gt;

</description>
        
        <pubDate>Wed, 17 Apr 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/ctrip-network-arch-evolution/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/ctrip-network-arch-evolution/</guid>
        
        
        <category>network</category>
        
        <category>architecture</category>
        
        <category>datacenter</category>
        
      </item>
      
    
      
      <item>
        <title>[译] 如何基于 Cilium 和 eBPF 打造可感知微服务的 Linux</title>
        <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

&lt;p&gt;本文内容来自 2019 年的一个技术分享 &lt;a href=&quot;https://www.infoq.com/presentations/linux-cilium-ebpf&quot;&gt;How to Make Linux Microservice-Aware with
Cilium and eBPF&lt;/a&gt;
，作者是 Cilium 项目的创始人和核心开发者，演讲为英文。&lt;/p&gt;

&lt;p&gt;本文翻译了演讲的技术性内容，其他少部分非技术内容（例如部分开场白）已略过。如有疑
问，请观看&lt;strong&gt;原视频&lt;/strong&gt;。注意，链接页面的英文讲稿很可能是语音识别出来的，其中包含一些
错误，会影响对内容的理解，所以有还是建议观看原视频。&lt;/p&gt;

&lt;p&gt;以下是译文。&lt;/p&gt;

&lt;hr /&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/1.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;今天在这里给大家介绍 BPF（Berkeley Packet Filter），以及如何基于 BPF 将 Linux 打
造成一个&lt;strong&gt;可感知微服务的操作系统&lt;/strong&gt;。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/2.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我有什么资格谈论这些内容？&lt;/p&gt;

&lt;p&gt;过去 15 年我一直都在从事 Linux 内核开发。&lt;/p&gt;

&lt;p&gt;其中有 10 年左右，我的主要关注点是网络和安全子系统。我参与编写了可能是世界上最大
的单体应用（Linux Kernel），现在有 12 million 行源代码。我参与过所有的网络子系统
、一些用户空间安全组件、netlink、iptables 等等的开发。&lt;/p&gt;

&lt;p&gt;过去的 2 年，我创建了 Cilium 项目，之后又联合创立了一个公司在背后支持 Cilium。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/3.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这次分享中，我将讨论以下内容：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;应用运行方式的演进&lt;/li&gt;
  &lt;li&gt;微服务时代 Linux 内核存在的问题&lt;/li&gt;
  &lt;li&gt;BPF 和 Cilium&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;应用运行方式的演进&quot;&gt;应用运行方式的演进&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/4.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最早的时代是单任务时代。每个进程拥有对机器的所有权限。我对这个时代没什么了解，
我太年轻了。&lt;/p&gt;

&lt;p&gt;然后多任务时代，多个 CPU 分给不同进程使用，开始有了 MMU、虚拟内存等概念。Linux 就是
从这个时候开始起飞的。你需要运行一个 Linux 发行版，管理应用的依赖。一个服务器上
所有的应用会共享一些库，你需要确保库的版本的正确性。&lt;strong&gt;多任务时代还是在物理服务器上
跑应用的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;再之后，我们就进入了虚拟化时代。突然间，所有的东西都开始跑在虚拟机内部。我们将应
用和操作系统打包到一起，基本上，每个应用都可以跑在不同的操作系统上，而你可以将这
些应用运行在同一台物理服务器（宿主机）上。然后我们开始虚拟硬件，很多名词前面
都开始加上 “虚拟”（“v”），例如虚拟交换机、虚拟网桥、虚拟设备。
&lt;strong&gt;所有东西都变成了软件定义的。本质上，这些都是以前硬件上的功能，我们用软件重做了
一遍，运行在虚拟机内部&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;现在，我们正在进入微服务和容器时代。&lt;strong&gt;本质上，我们正在重新回到将应用跑在宿主机上的
时代&lt;/strong&gt;：我们将不同应用直接跑在宿主机操作系统上，不再是每个应用一个虚拟机。这些应用
需要通过宿主机操作系统、容器、namespace等进行隔离和资源管理，后面会介绍这些内容。&lt;/p&gt;

&lt;p&gt;这对&lt;strong&gt;操作系统需要提供什么功能&lt;/strong&gt;产生了巨大的影响。不再是“喔，我需要将网络包转发给
这个虚拟机。我需要做一些防火墙工作”。&lt;strong&gt;我们真正需要考虑的是应用&lt;/strong&gt;。同样的，这是一个
巨大的转变。这和单任务到多任务的转变还不一样。突然间，我们开始有一些只会持续几
十秒的应用，这导致完全不同的需求。另外，还有多租户系统，以及其他非常不同的场景。&lt;/p&gt;

&lt;h2 id=&quot;微服务时代-linux-内核的问题&quot;&gt;微服务时代 Linux 内核的问题&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/5.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这种情况下，Linux 内核有哪些问题？显然，它不是为这个时代设计的。&lt;/p&gt;

&lt;h3 id=&quot;问题一抽象&quot;&gt;问题一：抽象&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/6.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;软件开发者都喜欢抽象。上面这张图只是网络相关的抽象，但它清楚地展示了 Linux 内核里
的抽象长什么样子。如果我们想用 Netfilter 做包过滤，那就必须要经过 socket 和
TCP协议栈。而如果从网卡往上看的话，包得经过网络设备抽象层、流量整形（traffic
shaping）、以太网层、IP 层等等才能到达应用。上下都需要经历协议栈。&lt;/p&gt;

&lt;p&gt;这种抽象会带来几方面好处：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;用户空间 API 强兼容性&lt;/strong&gt;：例如，20 年前编译的可执行文件现在仍然能工作。这
太神奇了，非常伟大&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;使大部分内核代码不依赖硬件&lt;/strong&gt;：我已经（作为内核开发者）工作 15 年了，但从来
没写过一个驱动程序。我对硬件所知甚少（have no clue about hardware），但我写过
很多底层代码（low level code），例如 IP、路由和防火墙相关的。对于真实的硬件，
我几乎没有什么了解&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;抽象带来的坏处：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;巨大的性能开销&lt;/strong&gt;（massive performance overhead）：接下来我们会看到为什么会
有这些性能开销，以及如何解决这个问题&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;很难绕过（bypass）这些层&lt;/strong&gt;：虽然有一些场景可以做到 bypass，但大部分都是
bypass 不掉的&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;问题二每个子系统都有自己的-api&quot;&gt;问题二：每个子系统都有自己的 API&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/7.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这张图展示的是网络相关的（子系统），但对于存储和其他系统，问题都是类似的。我在图
中列出了对这些子系统进行操作所需的工具。例如，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;配置以太网驱动或者网络设备需要使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;ethtool&lt;/code&gt; 命令&lt;/li&gt;
  &lt;li&gt;配置路由使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;ip&lt;/code&gt; 命令&lt;/li&gt;
  &lt;li&gt;配置过滤使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;seccom&lt;/code&gt; 命令&lt;/li&gt;
  &lt;li&gt;配置 IP 防火墙使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;iptables&lt;/code&gt; 命令，但如果你使用的是 raw sockets，那有很多地方都
会 bypass，因此这并不是一个完整的防火墙&lt;/li&gt;
  &lt;li&gt;配置流量整形使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;tc&lt;/code&gt; 命令&lt;/li&gt;
  &lt;li&gt;抓包使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;tcpdump&lt;/code&gt;命令，但同样的，它并没有展示出全部信息，因为它只关注了一层&lt;/li&gt;
  &lt;li&gt;如果有虚拟交换机，那使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;brctl&lt;/code&gt; 或 &lt;code class=&quot;highlighter-rouge&quot;&gt;ovsctl&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以我们看到，每个子系统都有自己的 API，这意味着如果要自动化这些东西，必须单独的
使用这些工具。有一些工具这样做了，但这种方式意味着我们需要了解其中的每一层。&lt;/p&gt;

&lt;h3 id=&quot;问题三开发过程&quot;&gt;问题三：开发过程&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/8.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果你需要改动 Linux 内核，那这项工作将是非常困难的。&lt;/p&gt;

&lt;p&gt;但是，先来看一些好的方面。Linux 内核是开放和透明的，任何人都可以看到其他任何人的
改动，而且它的代码质量非常高。另
外，Linux内核非常稳定，可能是目前最稳定的系统，而且获取它非常方便。一旦你将自己
的改动合并到内核，每个使用内核的人都会用到你的改动，这几乎完全是厂商无关的（
vendor-neutral）。&lt;/p&gt;

&lt;p&gt;不好的方面：不好的方面太多了。&lt;/p&gt;

&lt;p&gt;首先，内核是非常，非常难改。通常需要大喊大叫（Shouting is involved）。
但这种状况也正在明显地改善。Linux 内核是一个非常庞大和复
杂的代码库，包含 12 million 行 C 和其他语言代码，其中一些代码已经 30 多岁高龄了
。向upstream
提交代码很难，需要达成共识。如果你有特殊的使用场景，而且没有发现其他人认同你的观
点，那你的代码是无法合并进内核的。在这种情况下，你只能 fork 一份内核，维护自己的
包含 12 million 行代码的内核分支。&lt;/p&gt;

&lt;p&gt;视所使用的 Linux 内核发行版的不同，其他用户可
能得几年之后才能用到某个改动。一些人还在运行 10 年前的内核。&lt;/p&gt;

&lt;p&gt;最大的问题可能是，每个人都在维护自己的内核 fork，很多时候涉及到上千个 patch 需要
backport。如果你运行的是 Android，那你运行的是 Linux，具体的说是 Android Linux。
如果你在运行 Rail，那你运行的是 Linux，具体的说是有 4 万个 patch 的 Linux。它们
和上游的Linux 还是不太一样的，而只是上游的一个 fork。因此，大家都在运行自己的
Linux。&lt;/p&gt;

&lt;h3 id=&quot;问题四linux-感知不到容器&quot;&gt;问题四：Linux 感知不到容器&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/9.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这也许是最严重的问题：事实上内核感知不到容器的存在。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;内核知道的是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;进程和线程&lt;/li&gt;
  &lt;li&gt;cgroups&lt;/li&gt;
  &lt;li&gt;Namespaces&lt;/li&gt;
  &lt;li&gt;IP 地址和端口号&lt;/li&gt;
  &lt;li&gt;系统调用和 SELinux 上下文&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cgroups 是一个逻辑结构，你可以将进程关联到一个 group，然后指定这个 group 的资源
限制，例如可以使用的 CPU、内存、IOPS 等等。&lt;/p&gt;

&lt;p&gt;Namespace 是一种隔离技术，例如给一个 group 的进程指定 namespace 限制一个虚拟地址
空间，使它们只能看到这个 namespace 的进程。网络 namespace 的网络设备只能看到这个
namespace 内的网络设备。&lt;/p&gt;

&lt;p&gt;内核知道 IP 地址和系统调用。因此应用发起系统调用时，内核可以对它进行跟踪和过滤。
内核还知道 SELinux 上下文，因此有过滤网络安全相关的功能，例如控制进程是否/如何与
其他进程通信。听起来很有用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这些都是多任务时代（multitasking age）的基石。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;内核不知道的是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;容器或 K8S pods&lt;/li&gt;
  &lt;li&gt;暴露（到宿主机外面）的需求&lt;/li&gt;
  &lt;li&gt;容器/Pods 之间的 API 调用&lt;/li&gt;
  &lt;li&gt;service mesh&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;内核无法感知（作为一个整体的）容器&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;你可以在 cgroup 文件中找到容器 ID，但内
核本身并不理解一个容器是什么。它只能看到 cgroups 里面的 namespaces。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;内核理解应用是否需要暴露给外部&lt;/strong&gt;。在多任务时代，内核其实知道一个应用绑定了哪个
IP 和 port，以及是否对外暴露。例如如果一个web server 运行在 localhost 的 80
端口，内核就理解它不应该被暴露到外部。在容器时代，内核已经不清楚什么应该被暴露，
什么不应该被暴露了。&lt;/p&gt;

&lt;p&gt;另外一个大问题：&lt;strong&gt;以前通过 IPC 或 Linux domain socket pipe 方式的通信，现在换成
REST、GRPC 等方式了。内核无法感知到后者&lt;/strong&gt;。内核知道的仅仅是网络包、端口号等，
内核会知道：“嘿，这里有一个进程，它监听在 80 端口，运行在自己的 namespace 内。”
除此之外的（更上层）东西，内核就不知道了，例如跑在这个端口上的是什么服务。
在之前，内核还知道这是一个正在通过 IPC 和其他进程通信的进程，这种情况是简单的进
程到进程、服务到服务通信。而 service mesh —— 我不知道在坐有多少人正在关注
service mesh—— 内核无法感知到 service mesh。很多东西都是内核不知道的。&lt;/p&gt;

&lt;h3 id=&quot;解决办法&quot;&gt;解决办法&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/10.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;面对这种情况，我们该怎么办呢？有几种解决方式。&lt;/p&gt;

&lt;p&gt;第一种方式，针对第一个问题（内核实现的抽象和分层问题），我们可以&lt;strong&gt;给用户空间程序
访问硬件的权限，完全绕过内核&lt;/strong&gt;。我是认真的（I mean it will be
fine），内核可以处理好这些事情。应用可能也知道如何使用硬件。这类用户空间程序包括
DMA、DPDK 及类似框架。&lt;/p&gt;

&lt;p&gt;第二种解决方式：&lt;strong&gt;Unikernel&lt;/strong&gt;。Linus 错了，&lt;strong&gt;每个应用应该自带它们自己的操作系统&lt;/strong&gt;，
这完全可行（definitely feasible）。这类例子也很多，包括 ClickOS、MirageOS、
Rumprun 等等。每个应用自带自己的操作系统，而不是共享同一个操作系统。&lt;/p&gt;

&lt;p&gt;第三种方式：&lt;strong&gt;将操作系统上移到用户空间&lt;/strong&gt;。gVisor 是一个例子，已经好多年了。我们
可以&lt;strong&gt;将操作系统的大部分功能都跑在用户空间，只将最小的子集跑在内核空间&lt;/strong&gt;，处理硬
件等相关的事情。这样对于很多网络和存储问题，我们就不需要和内核社区协商了（直接在
用户空间自己改）。这个想法非常棒，但是，代价是性能会有非常大的（massive）下降。&lt;/p&gt;

&lt;p&gt;最后，我们还有一种解决方式：从头来过，&lt;strong&gt;重写一切&lt;/strong&gt;（rewrite everything）。显然，
这也是一种办法。&lt;strong&gt;我相信今天晚些时候 Brian 会分享如何用 Rust 重写一切&lt;/strong&gt;（高级黑
！）。我认为重写一切是非常大的一项工程，因此我去 google 了一下重写 Linux 内核需要
多少预算，这是给出的数字：&lt;code class=&quot;highlighter-rouge&quot;&gt;$1,372,340,206&lt;/code&gt;。我不清楚计算所用的工资水平跟现在比是
否已经过时，但我们已经看出来：重写 Linux 内核基本上是不可行的。&lt;/p&gt;

&lt;h2 id=&quot;bpf-是什么&quot;&gt;BPF 是什么？&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/11.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BPF 是一个解决所有这些问题的方案&lt;/strong&gt;。那什么是 BPF？&lt;/p&gt;

&lt;p&gt;BPF 是 Linux 内核中的一个高性能&lt;strong&gt;沙盒虚拟机&lt;/strong&gt;（sandbox virtual machine），它将内
核变成了可编程的（programmable）。它由我们团队和 Facebook 的一些工程师维护，另外
还有很多 Google、RedHat、Netflix、Netronome 等工程师协助。BPF 生成的代码如上图所
示，这使得开发者可以&lt;strong&gt;对内核进行编程（program the Linux Kernel）&lt;/strong&gt;，我们接下来会
看到这是如何工作的。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/12.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;要理解 BPF 首先要意识到：&lt;strong&gt;Linux 内核本质上是事件驱动的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在图中最上面，有进程进行系统调用，它们会连接到其他应用，写数据到磁盘，读写
socket，请求定时器等等。这些都是事件驱动的。这些过程都是系统调用。&lt;/p&gt;

&lt;p&gt;在图最下面，是硬件层。这些可以是真实的硬件，也可以是虚拟的硬件，它们会处理中断事
件，例如：“嗨，我收到了一个网络包”，“嗨，你在这个设备上请求的数据现在可以读了”，
等等。因此，内核所作的一切事情都是事件驱动的。&lt;/p&gt;

&lt;p&gt;在图中间，是 12 million 行巨型单体应用（Linux Kernel）的代码，这些代码处理
各种事件。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/13.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BPF 给我们提供了&lt;strong&gt;在事件发生时运行指定的 BPF 程序&lt;/strong&gt;的能力。&lt;/p&gt;

&lt;p&gt;例如，我们可以在以下事件发生时运行我们的 BPF 程序：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;应用发起 &lt;code class=&quot;highlighter-rouge&quot;&gt;read&lt;/code&gt;/&lt;code class=&quot;highlighter-rouge&quot;&gt;write&lt;/code&gt;/&lt;code class=&quot;highlighter-rouge&quot;&gt;connect&lt;/code&gt; 等系统调用&lt;/li&gt;
  &lt;li&gt;TCP 发生重传&lt;/li&gt;
  &lt;li&gt;网络包达到网卡&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，BPF 允许我们在内核实现这些逻辑，当发生特定的内核事件时做相应的处理。对所有
的内核函数，可以通过 kprobes 做这些事情。也可以对 tracepoints 做这些事情。这
些都是定义良好的、稳定的函数（名）。我们甚至可以对用户空间函数做这些，使用
uprobe。这样当用户空间应用调用到这些函数时，我们就可以通过 uprobe 和 BPF 程序捕
获。这就是那些基于 BPF 实现的 profiling 和 tracing 工具的工作原理。我们在系统调用、
网络设备、socket 层交互甚至网卡驱动层（通过 DMA）等地方调用 BPF 程序，而且内核里
的可 attach 点越来越多。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/14.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BPF 程序之间可以通信，它们可以使用 BPF maps 保存状态信息。&lt;/p&gt;

&lt;p&gt;BPF maps 数据&lt;strong&gt;可以通过 BPF 程序访问，也可以从用户空间访问&lt;/strong&gt;。因此可以在 BPF
程序中向 BPF maps 写数据，然后从用户空间读取，例如导出一些采集数据。或者，可以将
配置信息写入 maps，然后从 BPF 程序读取配置。&lt;/p&gt;

&lt;p&gt;BPF maps 支持哈希表、数组、LRU、Ring Buffer、Stack trace、LPM 等等。其中一些支持
per-CPU variant，性能更高。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/15.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以调用 BPF 辅助函数。例如 BPF 程序本身不知道如何操作一个网络包，而我们可以通过
调用helper 函数实现。这些 helper 函数都是稳定的 API。这使得 BPF 程序可以通过
Linux内核理解的、已有的功能来和内核交互。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/16.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以做尾调用（tail call）；可以从一个程序调用另一个程序；可以实现逻辑程序链
（chains of logical programs），基于此可以实现函数调用。这使得可以构建一个小程序
，按顺序依次调用他们。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/17.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们有一个 JIT （Just-In-Time）编译器。当加载通用
的、CPU无关的字节码之后，内核会接管，验证它的合法性，然后将它编译成 CPU 相关的代
码，例如 x86。可以看到目前支持的 CPU 类型，目前主要支持的是 64 位 CPU。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/18.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BPF 的贡献者有哪些？以上是目前的列表，这个列表还在增长，这里展示的仅仅是 TOP10。
这是过去两年给 BPF 内核侧贡献过代码的开发者。Daniel 和 Alexei 目前共同维护 BPF。
然后有来自 Facebook、Reddit、Netronome 等公司的贡献者。我印象中大概有 186 位。
BPF 是目前内核最活跃的子系统之一。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/19.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;谁在使用 BPF？用来做什么？这个领域正在发生革命性的变化，但目前大家看到的还比较少
。&lt;/p&gt;

&lt;h3 id=&quot;use-case-1facebook&quot;&gt;Use case 1：Facebook&lt;/h3&gt;

&lt;p&gt;Facebook 用 BPF 重写了他们的大部分基础设施。&lt;/p&gt;

&lt;p&gt;11 月 12 号的 BPF 峰会上，他们会介绍 Facebook 如何用 BPF 替换了 iptables 和
network filter。这个分享肯定会在线直播的。如果你对此感兴趣，到时可以在线收听。他
们会提供大量的细节和性能数据。Facebook 基本上已经将他们的负载均衡器从 IPVS 换成了
BPF。他们已经将 BPF 用在流量优化（traffic optimization），在分享中，它们也将会介
绍他们在网络安全方面的工作。&lt;/p&gt;

&lt;h3 id=&quot;use-case-2google&quot;&gt;Use case 2：Google&lt;/h3&gt;

&lt;p&gt;Google 已经开始用 BPF 做 &lt;strong&gt;profiling&lt;/strong&gt;，找出在分布式系统中应用消耗多少 CPU。而且，他
们也开始将 BPF 的使用范围扩展到&lt;strong&gt;流量优化和网络安全&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;use-case-3redhat&quot;&gt;Use case 3：Redhat&lt;/h3&gt;

&lt;p&gt;Redhat 正在开发一个叫 &lt;code class=&quot;highlighter-rouge&quot;&gt;bpffilter&lt;/code&gt; 的上游项目，将来会替换掉内核里的 iptables，也
就是说，内核里基于 iptables做包过滤的功能，以后都会用 BPF 替换。另外还有一些论文
和项目，关于 XDP 和 BPF+NFV的场景。&lt;/p&gt;

&lt;h3 id=&quot;use-case-4netflix&quot;&gt;Use case 4：Netflix&lt;/h3&gt;

&lt;p&gt;如果你听说过 DPF，那你估计是看过 Brendan Gregg 的分享。他介绍了如何在大规模生产
环境中使用 BPF 定位 CPU 消耗问题，这个问题用传统方式是很难做的，需要特别轻量级的
工具。他基于 BPF 采集信息然后画出所谓的火焰图（flame graphs），帮助定位性能问题
。最近他开源了一个 BPF trace 的项目，可以帮助排查性能问题。&lt;/p&gt;

&lt;p&gt;另外还有大量的与 BPF 相关的项目。&lt;/p&gt;

&lt;h3 id=&quot;bpf-程序长什么样&quot;&gt;BPF 程序长什么样？&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/20.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上是一个（至少对我来说）简单的 BPF 程序。&lt;/p&gt;

&lt;p&gt;BPF 程序使用高级语言编写，例如 C 语言。以上这个例子中，每次系统调用返回时，就会
执行这个 BPF 程序。程序会获取进程的 PID 和 程序名，将信息送到用户空间。这样你就
可以监控你的系统。非常非常简单的例子，但这就是基于 BPF 的 profiling 和
monitoring 系统的工作原理。&lt;/p&gt;

&lt;h2 id=&quot;cilium-是什么&quot;&gt;Cilium 是什么？&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/21.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上就是关于 BPF 的介绍，非常的底层，那么，必须得了解所有这些细节才能使用 BPF 吗
？不，这就是我们创建 Cilium 项目的原因。&lt;/p&gt;

&lt;p&gt;Cilium 是一个开源项目，目标是为微服务环境提供网络、负载均衡、安全功能，主要定位
是容器平台。这个项目本身并不需要容器环境，但目前我们提供的是容器化的安装方式。
Cilium 基于 BPF。&lt;/p&gt;

&lt;h3 id=&quot;目标&quot;&gt;目标&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/22.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先是&lt;strong&gt;让 BPF 更易上手使用&lt;/strong&gt;（approachable）。BPF 本身很神奇、灵活、性能非常高，但
对内核不了解的话，要使用起来非常困难。而毫无疑问，大部分人并不想自己写 BPF 程序
，但想利用 BPF 来完成一些事情。因此，我们需要自动化 BPF 代码生成、自动化 BPF 管
理等等。这是第一个目标。&lt;/p&gt;

&lt;p&gt;第二个目标是&lt;strong&gt;利用 BPF 的灵活性使内核感知到 cloud native 应用&lt;/strong&gt;，我们后面会详细展开
。&lt;/p&gt;

&lt;p&gt;第三个目标是&lt;strong&gt;安全&lt;/strong&gt;，通过 BPF 使内核能够感知到 API 层。内核能够理解：“嗨，你有
两个应用互相通信，它们之间调用了哪些 API？”使内核能够为 API 调用提供安全保障。构
建一个基于身份认证（identity-based）机制使服务通信更安全。因此不同于以前简单的
IP+Port 过滤，&lt;strong&gt;现在内核可以理解什么是一个微服务&lt;/strong&gt;，微服务的 labels 有哪些，这个
微服务的安全性是怎么样的。&lt;/p&gt;

&lt;p&gt;进程级别的上下文 enforcement。利用 BPF 的强大功能使内核理解一个可执行文件是什么
，一个容器里的进程正在进行什么 API 调用。这非常有用。例如，大家都知道 &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl
exec&lt;/code&gt; 可以到一个容器里去执行命令，但是，谁来保证这个通信过程的安全？显然不是服务自身。
那你如何保证这个通信过程的安全呢，保证命令不会发送到错误的地方？&lt;/p&gt;

&lt;p&gt;最后一点就是 BPF 的性能。&lt;/p&gt;

&lt;h3 id=&quot;cilium-use-cases&quot;&gt;Cilium Use Cases&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/23.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先我们提供了 CNI 和 CNM plugin，你可以使用 cilium 作为容器的网络方案。
支持 IPv4/IPv6、NAT46、负载均衡等等。&lt;/p&gt;

&lt;p&gt;我们提供了微服务安全（microservice security），&lt;strong&gt;基于 identity 做安全，而不是传统
的基于 IP 和端口&lt;/strong&gt;。我们给服务指定 identity，允许基于 service label
定义安全策略。例如允许我的前端和后端通信，我们是在网络层做这种策略的。我们有&lt;strong&gt;增强
的 API 安全支持&lt;/strong&gt;，例如之允许部分 REST API 调用，或者只允许访问 Kafka 集群，并且只
能生产或消费特定的 topic 等等。&lt;/p&gt;

&lt;p&gt;我们有 DNS 服务器策略。下一个版本会支持 SSL。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/24.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后是 &lt;strong&gt;service mesh 的加速&lt;/strong&gt;。这里我介绍的稍微详细一点，因为我感觉这是很多人感
兴趣的地方。&lt;/p&gt;

&lt;p&gt;上面左边这张图就是 service mesh 中常见的两个服务通信的场景。两个服务并不是直接和
彼此通信，而是通过各自的 sidecar。看起来非常简单和简洁。&lt;/p&gt;

&lt;p&gt;右边是它实际的、在数据传输层的样子。服务出来的请求经过协议栈和 iptables 规则进入到
sidecar 的监听 socket，这个 TCP 连接到这里就是终点了。sidecar 会将请求收进来，检
查 HTTP头和其他一些信息，做一些它自己的处理，然后再将请求发送出去。这个过程并不
高效。&lt;strong&gt;加上这一层 sidecar 会有 10x 的性能损失&lt;/strong&gt;。&lt;strong&gt;这并不是 sidecar 本身的性能造成
的&lt;/strong&gt;（我这里放的图是 Envoy，已经很高效了），而是 sidecar 代理的工作方式造成的。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/25.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里为什么要使用 TCP？TCP 是为有质量差、有丢包的网络设计的。如果服务和 sidecar
永远都是在一台宿主机内部，我们为什么还要用 TCP？&lt;/p&gt;

&lt;p&gt;我们可以绕过 TCP，将两个 socket 以短路方式连接到一起。如果服务和 sidecar 永远在
一台宿主机上，我们可以直接在两个 socket 之间拷贝数据。我们实际测量，如果以 RPS
（每分钟请求数）衡量，&lt;strong&gt;性能可以 3x ~ 4x&lt;/strong&gt;。因此，这就是 Cilium 和 BPF 使 Linux
内核可感知微服务的一个例子。Cilium/BPF 的目的就是为服务化时代提供便利和所需的功
能。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/26.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其他一些 BPF 相关的项目。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/how-to-make-linux-microservice-aware-with-cilium/27.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

</description>
        
        <pubDate>Tue, 16 Apr 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/how-to-make-linux-microservice-aware-with-cilium-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/how-to-make-linux-microservice-aware-with-cilium-zh/</guid>
        
        
        <category>cilium</category>
        
        <category>ebpf</category>
        
        <category>microservice</category>
        
      </item>
      
    
      
      <item>
        <title>[笔记] Internet Routing Architecture (Cisco Press, 2000)</title>
        <description>&lt;h3 id=&quot;关于本文&quot;&gt;关于本文&lt;/h3&gt;

&lt;p&gt;本文是我在读 &lt;a href=&quot;https://www.amazon.com/Internet-Routing-Architectures-2nd-Halabi/dp/157870233X&quot;&gt;Internet Routing Architecture, 2nd Edition&lt;/a&gt; （
Cisco Press, 2000）时的读书笔记。&lt;/p&gt;

&lt;p&gt;注意这本书是 2000 年写的，因此有些内容可能已经过时，比如说到“当前大型网络都是使
用 xxx 协议”的时候，说的是距今 20 年前的情况，现在则并不一定。&lt;/p&gt;

&lt;p&gt;本书致力于解决实际问题，书中包含大量的架构图、拓扑图和真实场景示例，内容全面而且
易于上手，是不可多得的良心之作。本书目的是使读者成为&lt;strong&gt;将自有网络集成到全球互联网&lt;/strong&gt;
（integrating your network into the global Internet）领域的专家。&lt;/p&gt;

&lt;p&gt;以下是笔记内容。&lt;/p&gt;

&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_1&quot;&gt;互联网的演进&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.1&quot;&gt;互联网：起源及近史&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.2&quot;&gt;Network Access Points&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.3&quot;&gt;Routing Arbiter Project&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.4&quot;&gt;The Very High-Speed Backbone Network Service&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.5&quot;&gt;Transitioning the Regional Networks from the NSFNET&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.6&quot;&gt;NSF Solicits NIS Managers&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.7&quot;&gt;Other Internet Registries&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.8&quot;&gt;Internet Routing Registries&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.9&quot;&gt;The Once and Future Internet&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_2&quot;&gt;ISP Services and Characteristics&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;2.1 ISP Services&lt;/li&gt;
      &lt;li&gt;2.2 ISP Service Pricing, Service-Level Agreements, and Technical Characteristics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_3&quot;&gt;IP 寻址和分配&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;3.1 History of Internet Addressing&lt;/li&gt;
      &lt;li&gt;3.2 IP Address Space Depletion&lt;/li&gt;
      &lt;li&gt;3.3 Looking Ahead&lt;/li&gt;
      &lt;li&gt;3.4 Frequently Asked Questions&lt;/li&gt;
      &lt;li&gt;3.5 References&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_4&quot;&gt;域间路由基础&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;4.1 Overview of Routers and Routing&lt;/li&gt;
      &lt;li&gt;4.2 Routing Protocol Concepts&lt;/li&gt;
      &lt;li&gt;4.3 Segregating the World into Autonomous Systems&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_5&quot;&gt;边界网关协议第 4 版（BGP-4）&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;5.1 How BGP Works&lt;/li&gt;
      &lt;li&gt;5.2 BGP Capabilities Negotiation&lt;/li&gt;
      &lt;li&gt;5.3 Multiprotocol Extensions for BGP&lt;/li&gt;
      &lt;li&gt;5.4 TCP MD5 Signature Option&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_6&quot;&gt;Tuning BGP Capabilities&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;6.1 Building Peer Sessions&lt;/li&gt;
      &lt;li&gt;6.2 Sources of Routing Updates&lt;/li&gt;
      &lt;li&gt;6.3 Overlapping Protocols: Backdoors&lt;/li&gt;
      &lt;li&gt;6.4 The Routing Process Simplified&lt;/li&gt;
      &lt;li&gt;6.5 Controlling BGP Routes&lt;/li&gt;
      &lt;li&gt;6.6 Route Filtering and Attribute Manipulation&lt;/li&gt;
      &lt;li&gt;6.7 BGP-4 Aggregation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_7&quot;&gt;冗余、对称和负载均衡&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;7.1 Redundancy&lt;/li&gt;
      &lt;li&gt;7.2 Symmetry&lt;/li&gt;
      &lt;li&gt;7.3 Load Balancing&lt;/li&gt;
      &lt;li&gt;7.4 Specific Scenarios: Designing Redundancy, Symmetry, and Load Balancing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_8&quot;&gt;AS 内部路由控制&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;8.1 &lt;a href=&quot;#chap_8.1&quot;&gt;Interaction of Non-BGP Routers with BGP Routers&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;8.2 BGP Policies Conflicting with Internal Defaults&lt;/li&gt;
      &lt;li&gt;8.3 Policy Routing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_9&quot;&gt;大型 AS 控制管理&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;9.1 Route Reflectors&lt;/li&gt;
      &lt;li&gt;9.2 Confederations&lt;/li&gt;
      &lt;li&gt;9.3 Controlling IGP Expansion&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_10&quot;&gt;设计稳定的因特网&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;10.1 因特网路由的不稳定性&lt;/li&gt;
      &lt;li&gt;10.2 BGP Stability Features&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;互联网（Internet）起源于 1960s 的一个学术实验。&lt;/p&gt;

&lt;p&gt;一些人惊讶于网络会发生故障，另外一些人则惊讶于网络竟然会运行良好。&lt;/p&gt;

&lt;h3 id=&quot;目标&quot;&gt;目标&lt;/h3&gt;

&lt;p&gt;本书致力于使读者成为&lt;strong&gt;将自有网络集成到全球互联网&lt;/strong&gt;（integrating your network
into the global Internet）领域的专家。&lt;/p&gt;

&lt;p&gt;本书致力于解决实际问题，书中包含大量的架构图、拓扑图和真实场景示例，内容全面而且
易于上手（comprehensive and accessible）。&lt;/p&gt;

&lt;h3 id=&quot;目标读者&quot;&gt;目标读者&lt;/h3&gt;

&lt;p&gt;需要将自有网络接入互联网的公司的网络管理员、集成者、架构师。&lt;/p&gt;

&lt;p&gt;不需要太多 TCP/IP 基础。&lt;/p&gt;

&lt;h1 id=&quot;i-the-contemporary-internet&quot;&gt;I: The Contemporary Internet&lt;/h1&gt;

&lt;p&gt;路由问题和方案（routing problems and solutions）的复杂性和当代互联网的增长与演进密切相关。&lt;/p&gt;

&lt;p&gt;因此，在深入到路由协议细节之前，先了解互联网的发展历史，会对理解问题非常有帮助。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-互联网的演进&quot;&gt;1 互联网的演进&lt;/h2&gt;

&lt;p&gt;介绍互联网的发展历史，主要组件，理解互联网现在面临的挑战，以及如何构建可扩展互连
网络（internetworks）。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;11-互联网起源及近史&quot;&gt;1.1 互联网：起源及近史&lt;/h3&gt;

&lt;h4 id=&quot;arpanet&quot;&gt;ARPANET&lt;/h4&gt;

&lt;p&gt;1969 年 12 月，四个节点、通过 56kbps 电路连接的试验网络 ARPANET。&lt;/p&gt;

&lt;p&gt;这项技术大获成功，随后几千个大型和政府机构将他们的私有网络连接到了 ARPANET。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/1-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-1 ARPANET Architecture, December 1969 &lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/1-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-2 ARPANET Architecture, July 1976 &lt;/p&gt;

&lt;p&gt;这就是互联网（Internet）的前身。&lt;/p&gt;

&lt;p&gt;Internet 被禁止用于商业目的，不过大量的接入还是导致了扩展性和链路拥塞问题，因此
NSF开始研究 NSFNET。&lt;/p&gt;

&lt;h4 id=&quot;nsfnet&quot;&gt;NSFNET&lt;/h4&gt;

&lt;p&gt;NSFNET 是为了解决 ARPANET 的拥塞问题。设计：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;多个区域网络（regional networks）和对等网络（peer networks），&lt;/li&gt;
  &lt;li&gt;骨干网（backbone）：NSFNET 的核心&lt;/li&gt;
  &lt;li&gt;regional networks 和 peer networks 都接入骨干网&lt;/li&gt;
  &lt;li&gt;带宽升级到 T1（1.544 Mbps，1988），后来又到 T3（45 Mbps，1991）&lt;/li&gt;
&lt;/ol&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/1-3.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-3 The NSFNET-Based Internet Environment &lt;/p&gt;

&lt;p&gt;1990 年左右，NSFNET 仍然是用于科研和学术目的。之后，开始出现 ISP 产业。&lt;/p&gt;

&lt;p&gt;1990 年之后，这张网络开始连接到欧洲和亚洲。&lt;/p&gt;

&lt;p&gt;1995 年，这张网络完成了自己的历史使命。&lt;/p&gt;

&lt;h4 id=&quot;the-internet-today&quot;&gt;The Internet Today&lt;/h4&gt;

&lt;p&gt;今天的互联网是从一个核心网络（core network，也就是 NSFNET）转变成了一个由商业提
供商运营的分布式网络，这些供应商网络通过主要的网络交换节点或直连而连接到一起。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/1-4.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-4 The General Structure of Today's Internet&lt;/p&gt;

&lt;p&gt;ISP 在多个 region 都提供连接接入点，称为 POP（Points of Presence）。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-isp-服务和特点&quot;&gt;2 ISP 服务和特点&lt;/h2&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;21-isp-services&quot;&gt;2.1 ISP Services&lt;/h3&gt;

&lt;p&gt;For more details about switches, VLANs, and broadcast
domains, read Interconnections: Bridges, Routers, Switches, and Internetworking
Protocols,
Second Edition (Addison-Wesley, 1999) by Radia Perlman, or Cisco LAN Switching
(Cisco
Press, 1999) by Kennedy Clark and Kevin Hamilton.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-ip-寻址和分配&quot;&gt;3 IP 寻址和分配&lt;/h2&gt;

&lt;h3 id=&quot;31-history-of-internet-addressing&quot;&gt;3.1 History of Internet Addressing&lt;/h3&gt;

&lt;h3 id=&quot;32-ip-address-space-depletion&quot;&gt;3.2 IP Address Space Depletion&lt;/h3&gt;

&lt;p&gt;CIDR: Classless Inter-domain Routing&lt;/p&gt;

&lt;p&gt;路由条目越多，所需的处理能力和内存空间就更多。&lt;/p&gt;

&lt;p&gt;路由表规模在 1991~1995 年每 10 个月就翻一番：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/3-9.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 3-9 The Growth of Internet Routing Tables &lt;/p&gt;

&lt;p&gt;CIDR 相比于之前的有类别 IP 地址（classful IP addresses），是革命性的一步。通过
prefix 做路由聚合，大大减小路由表的规模。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/3-11.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 3-11 Classful Addressing Versus CIDR-Based Addressing&lt;/p&gt;

&lt;p&gt;路由安装最长前缀匹配算法（LPM）选择路由。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/3-12.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 3-12 Longest Match&lt;/p&gt;

&lt;p&gt;如图 3-12，如果因为一些原因 path 1 路由失效率，那会用到下一个最长匹配，在图中就
是 path 2。&lt;/p&gt;

&lt;h4 id=&quot;将自己聚合的路由指向黑洞&quot;&gt;将自己聚合的路由指向黑洞&lt;/h4&gt;

&lt;p&gt;每个路由器会对外通告自己聚合的路由，表面自己到这些路由是可达的。&lt;/p&gt;

&lt;p&gt;但是，为了避免出现路由环路，每个路由器在自己内部，要将自己聚合的路由指向黑洞，即
，丢弃所有到这条路由的包。来看个具体的例子。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/3-13.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 3-13 Following Less-Specific Routes of a Network's Own Aggregate Causes Loops&lt;/p&gt;

&lt;p&gt;ISP1 的配置：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;默认路由指向 ISP2&lt;/li&gt;
  &lt;li&gt;ISP1 到 Foonet 网络 198.32.1.0/24 可达&lt;/li&gt;
  &lt;li&gt;ISP1 经过路由聚合，对外通告自己到 198.32.0.0/13 可达&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;则，当 ISP1 和 Foonet 的网络发生故障之后，目的是 198.32.1.1 的流量从 ISP2 到达
ISP1 时，会匹配到默认路由，流量会绕回 ISP2，形成环路。&lt;/p&gt;

&lt;p&gt;解决办法是：在 ISP1 的路由表内添加一条到 198.32.0.0/13 的 null 路由，将所有流量
丢弃。这样网络正常时，流量会匹配 198.32.1.0/24 这条路由；网络异常导致这条路由失
效后，流量匹配到 198.32.0.0/13，丢弃所有流量。&lt;/p&gt;

&lt;h1 id=&quot;ii-routing-protocol-basics&quot;&gt;II: Routing Protocol Basics&lt;/h1&gt;

&lt;p&gt;本书主要介绍外部网关协议（exterior gateway protocols），即不同自治系统（AS）之间
的路由。但先了解一下内部网关协议（internal gateway protocols）会非常有帮助。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-域间路由基础&quot;&gt;4 域间路由基础&lt;/h2&gt;

&lt;p&gt;互联网是由自治系统（AS）组成的，这些 AS 由不同组织管理，拥有不同的路由策略。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_4.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;41-路由器和路由routers-and-routing&quot;&gt;4.1 路由器和路由（Routers and Routing）&lt;/h3&gt;

&lt;p&gt;内部网关协议（IGP）是为&lt;strong&gt;企业网&lt;/strong&gt;（enterprise）设计的，&lt;strong&gt;不适用于大型网络&lt;/strong&gt;，
例如上千个节点的、有上万条路由的网络。因此引入了外部网关协议（EGP），例如&lt;strong&gt;边界
网关协议&lt;/strong&gt;（BGP）。&lt;/p&gt;

&lt;p&gt;本章介绍 IGP 基础。&lt;/p&gt;

&lt;h3 id=&quot;42-路由协议&quot;&gt;4.2 路由协议&lt;/h3&gt;

&lt;p&gt;大部分路由协议都可以归为两类分布式路由算法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;链路-状态（link-state）&lt;/li&gt;
  &lt;li&gt;距离矢量（distance vector）&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;距离矢量算法&quot;&gt;距离矢量算法&lt;/h4&gt;

&lt;p&gt;为每条路由维护一个&lt;strong&gt;距离矢量&lt;/strong&gt;（vector of distances），其中“距离”用跳数（hops）或类
似指标衡量。&lt;/p&gt;

&lt;p&gt;每个节点独立计算最短路径，因此是分布式算法。&lt;/p&gt;

&lt;p&gt;每个节点向邻居通告自己已知的最短路径，邻居根据收到的消息判断是否有更短路径，如果
有就更新自己的路由信息，然后再次对外通告最短路径。如此反复，直到整个网络收敛到一
致状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;早期 IGP 代表&lt;/strong&gt;：RIP（Routing Information Protocol）&lt;/p&gt;

&lt;p&gt;早期 IGP 缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;早期协议（RIP-1）只计算跳数（相当于每跳权重一样），没有优先级和权重，而跳数最
少的路径不一定最优&lt;/li&gt;
  &lt;li&gt;早期协议（RIP-1）&lt;strong&gt;规定了最大跳数&lt;/strong&gt;（一般是 15），&lt;strong&gt;因此限制了网络的规模&lt;/strong&gt;（
但解决了 count to infinity 问题）&lt;/li&gt;
  &lt;li&gt;早期协议（RIP-1）靠&lt;strong&gt;定时器触发路由通告&lt;/strong&gt;（没有事件触发机制），因此路由发生变
动时，&lt;strong&gt;收敛比较慢&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;第一代协议不支持 CIDR&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;新 IGP 解决了以上问题，协议代表：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;RIP-2&lt;/li&gt;
  &lt;li&gt;EIGRP&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;距离矢量协议的优点&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;简单&lt;/li&gt;
  &lt;li&gt;成熟&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BGP 也是距离矢量协议，但它是通过引入路径矢量（path vector）解决 count to
infinity 问题。path vector 包含了路径上的 ASN，相同 ASN 的路径只会接受一条，因此
消除了路由环路。BGP 还支持基于域的策略（domain-based policies）。后面会详细介绍
BGP。&lt;/p&gt;

&lt;h4 id=&quot;链路状态算法&quot;&gt;链路状态算法&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;距离矢量算法：交换路由表信息&lt;/li&gt;
  &lt;li&gt;链路状态算法：交换邻居的链路状态信息，比距离矢量算法复杂&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分布式数据库（replicated distributed database），存储链路状态（link state）。&lt;/p&gt;

&lt;p&gt;代表：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;OSFP&lt;/li&gt;
  &lt;li&gt;IS-IS&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;路由可扩展性和收敛速度都有改善，可以支持更大的网络，但仍然只适用于域内路由&lt;/strong&gt;（
interior routing）。&lt;/p&gt;

&lt;p&gt;大部分大型服务供应商在域内（intra-domain）都使用 link-state 协议，主要是看中它的
&lt;strong&gt;快速收敛&lt;/strong&gt;特性。&lt;/p&gt;

&lt;h3 id=&quot;43-将互联网分割为自治系统as&quot;&gt;4.3 将互联网分割为自治系统（AS）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;外部路由协议（Exterior routing protocol）的提出是为了解决两个问题&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;控制路由表的膨胀&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;提供结构化的互联网视图&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将路由域划分为独立的管理单元，称为自治系统（autonomous systems，AS）。
每个 AS 有自己&lt;strong&gt;独立的路由策略&lt;/strong&gt;和 &lt;strong&gt;IGP&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;当前域间路由的事实标准：BGP-4。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;intra-domain 和 inter-domain routing 的主要区别&lt;/p&gt;

  &lt;p&gt;intra-domain 主要解决技术需求，而 inter-domain 主要反映网络和公司的政治与商
业关系。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;autonomous-systems&quot;&gt;Autonomous Systems&lt;/h5&gt;

&lt;p&gt;一个 AS 是拥有如下特点的一组路由器：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;共享相同的路由策略&lt;/li&gt;
  &lt;li&gt;被作为一个整体进行管理&lt;/li&gt;
  &lt;li&gt;通常路由器之间运行同一种 IGP 协议&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每个 AS 有一个编号，称为 ASN。AS 之间通过 BGP 交换路由。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/4-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4-2 AS 之间的路由交换&lt;/p&gt;

&lt;h4 id=&quot;三种-as-类型&quot;&gt;三种 AS 类型&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;stub AS：末梢 AS，只有一条默认出口，因此不需要同步路由信息&lt;/li&gt;
  &lt;li&gt;non-transient AS：只通告自己的路由，不传播学习到的路由&lt;/li&gt;
  &lt;li&gt;transit AS：既通告自己的路由，又传播学习到的路由&lt;/li&gt;
&lt;/ol&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/4-3.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4-3 Single-Homed (Stub) AS&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/4-5.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4-5 Multihomed Nontransit AS Example&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/4-6.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4-6 Multihomed Transit AS Using BGP Internally and Externally&lt;/p&gt;

&lt;h3 id=&quot;45-frequently-asked-questions&quot;&gt;4.5 Frequently Asked Questions&lt;/h3&gt;

&lt;h4 id=&quot;domain-和-as-有什么区别&quot;&gt;Domain 和 AS 有什么区别？&lt;/h4&gt;

&lt;p&gt;两者都是指满足某些条件的一组路由器。&lt;/p&gt;

&lt;p&gt;Domain 一般指&lt;strong&gt;运行相同路由协议&lt;/strong&gt;的一组路由器，例如一个 RIP domain 或一个 OSFP
domain。&lt;/p&gt;

&lt;p&gt;AS 是&lt;strong&gt;管理概念&lt;/strong&gt;，&lt;strong&gt;作为整体统一管理的、有相同路由策略&lt;/strong&gt;的一组路由器是一个 AS。
一个 AS 可能包含一个或多个 domain。&lt;/p&gt;

&lt;h4 id=&quot;bgp-是用于-as-之间的那用于-as-内的-bgp-又是什么&quot;&gt;BGP 是用于 AS 之间的。那用于 AS 内的 BGP 又是什么？&lt;/h4&gt;

&lt;p&gt;AS 内的 BGP 是 iBGP。&lt;/p&gt;

&lt;p&gt;如果 AS 是 transit AS，那 iBGP 可以保护这个 AS 内的 nontransit routers，不会被大
量的 AS 外路由撑爆路由表。另外，即使不是 transit AS，iBGP 也可以提供更强的控制能
力，例如本书后面会看到的选择 exit and entrance points。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-边界网关协议第-4-版bgp-4&quot;&gt;5 边界网关协议第 4 版（BGP-4）&lt;/h2&gt;

&lt;p&gt;BGP-4 1993 年开始部署，是第一个支持路由聚合的 BGP 版本。&lt;/p&gt;

&lt;h3 id=&quot;51-bgp-工作原理&quot;&gt;5.1 BGP 工作原理&lt;/h3&gt;

&lt;p&gt;BGP 是一种&lt;strong&gt;路径矢量协议（path vector protocol）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Path vector&lt;/em&gt;&lt;/strong&gt; 是一条路由（network prefix）经过的所有 AS 组成的路径。目的是防
止出现&lt;strong&gt;路由环路&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BGP 使用 TCP 协议，运行在 179 端口。&lt;/li&gt;
  &lt;li&gt;peer 之间建立连接之后交换全部路由，之后只交换更新的路由（增量更新）&lt;/li&gt;
  &lt;li&gt;交换路由是 UPDATE 消息&lt;/li&gt;
  &lt;li&gt;维护&lt;strong&gt;路由表&lt;/strong&gt;的&lt;strong&gt;版本号&lt;/strong&gt;，每次路由表有更新，版本号都会递增&lt;/li&gt;
  &lt;li&gt;通告 UPDATE 消息通告和撤回路由&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bgp-消息头格式&quot;&gt;BGP 消息头格式&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/5-6.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-6 BGP Message Header Format&lt;/p&gt;

&lt;p&gt;字段：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Marker：16 字节，用于 BGP 消息认证及检测 peer 是否同步&lt;/li&gt;
  &lt;li&gt;Length: 2 字节，BGP 消息总长度，包括 header。总长度在 19~4096 字节之间。&lt;/li&gt;
  &lt;li&gt;Type: 2 字节，四种类型：
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OPEN&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UPDATE&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NOTIFICATION&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;KEEPALIVE&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;52-bgp-功能协商&quot;&gt;5.2 BGP 功能协商&lt;/h3&gt;

&lt;p&gt;检测到错误时会发送 NOTIFICATION 消息，然后关闭 peer 连接。&lt;/p&gt;

&lt;h4 id=&quot;update-message-and-routing-information&quot;&gt;UPDATE Message and Routing Information&lt;/h4&gt;

&lt;p&gt;UPDATE 消息:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Network Layer Reachability Information (NLRI)&lt;/li&gt;
  &lt;li&gt;Path Attributes&lt;/li&gt;
  &lt;li&gt;Unfeasible Routes&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/5-10.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-10 BGP UPDATE Message&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/5-11.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-11 BGP Routing Update Example&lt;/p&gt;

&lt;h3 id=&quot;53-multiprotocol-extensions-for-bgp&quot;&gt;5.3 Multiprotocol Extensions for BGP&lt;/h3&gt;

&lt;p&gt;对 BGP-4 的兼容性扩展，支持除了 IPv4 之外的其他协议（所以叫多协议），例如 IPv6
等等。&lt;/p&gt;

&lt;h3 id=&quot;54-tcp-md5-signature-option&quot;&gt;5.4 TCP MD5 Signature Option&lt;/h3&gt;

&lt;h3 id=&quot;55-looking-ahead&quot;&gt;5.5 Looking Ahead&lt;/h3&gt;

&lt;h3 id=&quot;56-frequently-asked-questions&quot;&gt;5.6 Frequently Asked Questions&lt;/h3&gt;

&lt;h4 id=&quot;bgp-是否像-rip-一样定期发布路由更新消息&quot;&gt;BGP 是否像 RIP 一样定期发布路由更新消息？&lt;/h4&gt;

&lt;p&gt;不是。只有路由有变动时，才会通告，而且只通告变动的路由。&lt;/p&gt;

&lt;h4 id=&quot;asn-在-bgp-消息中的什么地方&quot;&gt;ASN 在 BGP 消息中的什么地方？&lt;/h4&gt;

&lt;p&gt;UPDATE 消息的 AS_PATH 属性中。&lt;/p&gt;

&lt;h1 id=&quot;iii-effective-internet-routing-designs&quot;&gt;III: Effective Internet Routing Designs&lt;/h1&gt;

&lt;p&gt;接下来用前面学到的知识解决实际问题。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_6&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;6-bgp-capabilities-调优&quot;&gt;6 BGP Capabilities 调优&lt;/h2&gt;

&lt;p&gt;从本章开始，内容从理论转向 BGP 实现。&lt;/p&gt;

&lt;h3 id=&quot;61-building-peer-sessions&quot;&gt;6.1 Building Peer Sessions&lt;/h3&gt;

&lt;p&gt;虽然 BGP 大部分情况都是用于 AS 之间，但是，它也可以用在 AS 内部，为 AS 内部的路
由器提供外部路由可达信息（external destination reachability information）。&lt;/p&gt;

&lt;p&gt;AS 内部的 BGP 称为 iBGP；AS 之间的 BGP 称为 eBGP。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-1 iBGP 和 eBGP&lt;/p&gt;

&lt;p&gt;邻居之间建立连接，然后通过 OPEN 消息进行协商，在这个过程中，peer routers 之间会
比较 ASN 来判断他们是否属于同一个 AS。&lt;/p&gt;

&lt;p&gt;iBGP 和 eBGP 的区别：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;对收到的 UPDATE 消息的处理不同&lt;/li&gt;
  &lt;li&gt;消息携带的属性不同&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;物理和逻辑连接&quot;&gt;物理和逻辑连接&lt;/h4&gt;

&lt;p&gt;eBGP 要求邻居之间必须是物理直连的，但是有些情况下两个 AS 之间的 BGP peer 无法满
足直连的要求，例如经过了一些非 GBP 路由器。这种情况下，需要对 BGP 做特殊配置。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-2 External BGP Multihop Environment&lt;/p&gt;

&lt;p&gt;iBGP 对于 peer 之间是否直连没有要求，只要 peer 之间 IP 通即可。&lt;/p&gt;

&lt;h4 id=&quot;synchronization-within-an-as&quot;&gt;Synchronization Within an AS&lt;/h4&gt;

&lt;p&gt;BGP 的默认行为是，只有 iBGP 收敛之后，才将 AS 内部的路由通告给其他 AS。&lt;/p&gt;

&lt;p&gt;否则，会出现问题。来看个例子。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-4.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-4 BGP Route Synchronization&lt;/p&gt;

&lt;p&gt;ISP3 里面只有 RTA 和 RTC 运行 BGP 协议。当 ISP1 将 192.213.1.0/24 通告给 ISP3 的
RTA 之后，RTA 进一步将消息通告给 RTC。RTC 再通告给 ISP2。当 ISP2 向这个路由发送
流量时，RTC 会将流量转发给 RTB，而 RTB 没有这个路由信息，会将流量丢弃。&lt;/p&gt;

&lt;p&gt;因此，BGP 规定，从 iBGP 邻居学习到的路由不应该通告给其他 AS，除非这条路由通告IGP
也能访问到（The BGP rule states that a BGP router should not advertise to
external neighbors destinations learned from IBGP neighbors unless those
destinations are also known via an IGP.）。这就是所谓的同步。如果 IGP 可达，那说
明这条路由在 AS 内部是可达的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;将 BGP 路由注入 IGP 路由是有代价的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先，这会&lt;strong&gt;给 IGP 节点带来额外的计算开销&lt;/strong&gt;。前面已经提到，IGP 并不是为处理大规
模路由设计的（IGPs are not designed to handle that many routes）。&lt;/p&gt;

&lt;p&gt;其次，&lt;strong&gt;没有必要将所有外部路由都同步到所有内部节点&lt;/strong&gt;。更简单的方式通常是，AS 内
分成non-BGP 路由器和 BGP 路由器，non-BGP 路由器的默认路由指向 BGP 路由器。这样可
能会导致路径并不是最优的，但是跟在 AS 内维护上千条外部路由相比，代价要小的多。&lt;/p&gt;

&lt;p&gt;除了 BGP+IGP 方式之外，解决这个问题的另一个办法是，AS 内部的非边界路由器之间做
iBGP full-mesh，这样路由可以&lt;strong&gt;通过 iBGP 保证同步&lt;/strong&gt;。向 IGP 内部插入成千上万条路
由太恐怖了。&lt;/p&gt;

&lt;p&gt;因此，一些 BGP 的实现里允许关掉同步，例如 Cisco 的 &lt;code class=&quot;highlighter-rouge&quot;&gt;no synchronization&lt;/code&gt; 命令，这
是当前的常见配置（disable BGP synchronization and rely on a full mesh of IBGP
routers）。&lt;/p&gt;

&lt;h3 id=&quot;62-路由更新方式&quot;&gt;6.2 路由更新方式&lt;/h3&gt;

&lt;p&gt;对于像互联网这样复杂的网络来说，&lt;strong&gt;路由稳定性&lt;/strong&gt;（route stability）是一个很大的问题。
这和链路的稳定性，以及路由的注入方式（动态/静态）有关系。&lt;/p&gt;

&lt;h4 id=&quot;bgp-动态注入&quot;&gt;BGP 动态注入&lt;/h4&gt;

&lt;p&gt;可以进一步分为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;纯动态注入：所有从 IGP 学习到的路由都注入到 BGP（通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;redistribute&lt;/code&gt; 命令）&lt;/li&gt;
  &lt;li&gt;半动态注入：部分从 IGP 学习到的路由注入到 BGP（通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;network&lt;/code&gt; 命令）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;动态注入：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优点
    &lt;ul&gt;
      &lt;li&gt;配置简单，IGP 路由自动注入 BGP，不管是具体哪种 IGP 类型（RIP、OSPF、IS-IS等等）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点
    &lt;ul&gt;
      &lt;li&gt;可能会泄露内网路由到公网，造成安全问题&lt;/li&gt;
      &lt;li&gt;IGP 路由抖动会影响到 BGP，想象一下几百个 AS 同时有 IGP 路由抖动给 BGP 造成
的影响&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了防止因特网的路由抖动，提出了一些技术，第十章会介绍到，一个叫 route dampening
的进程会对抖动的路由进行惩罚，抑制它进入 BGP 的时间。&lt;/p&gt;

&lt;p&gt;保证路由稳定性是一项很难的工作，因为很多因素都是不受控的，例如硬件故障。减少路由
不稳定的一种方式是路由聚合，可以在 AS 边界做，也可以在因特网边界做。&lt;/p&gt;

&lt;p&gt;最后，另一种解决路由不稳定的方式是静态注入路由。&lt;/p&gt;

&lt;h4 id=&quot;bgp-静态注入&quot;&gt;BGP 静态注入&lt;/h4&gt;

&lt;p&gt;静态注入的路由会一直存在于路由表，一直会被通告。&lt;/p&gt;

&lt;p&gt;可以解决路由不稳定的问题，但是会导致失效的路由无法自动从路由表删除，而且静态配置
相当繁琐，配置不当还容易产生环路。因此只在特定的场景下使用。&lt;/p&gt;

&lt;h4 id=&quot;静态路由和动态路由例子移动网络&quot;&gt;静态路由和动态路由例子：移动网络&lt;/h4&gt;

&lt;p&gt;移动网络中分配 IP 地址的问题。&lt;/p&gt;

&lt;p&gt;移动设备希望在从一个 AS 移动到另一个 AS 的过程中，需要切换 IP 地址。因此，静态路
由的方式不合适，只能通过动态注入 BGP 的方式。具体到实现，一种方式就是将 IGP 注入
BGP。这会带来一些问题，前面已经分析过，例如需要对路由做过滤。&lt;/p&gt;

&lt;p&gt;另一种实现方式是通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;network&lt;/code&gt; 命令，在所有位置的边界路由器定义这些网络。&lt;/p&gt;

&lt;h3 id=&quot;63-重叠的协议后门overlapping-protocols-backdoors&quot;&gt;6.3 重叠的协议：后门（Overlapping Protocols: Backdoors）&lt;/h3&gt;

&lt;p&gt;路由可以通过多种协议学习，选择不同的协议会影响流量的路径。例如，如果选择一条 RIP
路由，可能会走某链路；而选择一条 eBGP 路由，则可能会走另一条链路。&lt;/p&gt;

&lt;p&gt;后门链路（backdoor link）提供了一种 IGP 路径的备选方式，可以用来替代 eBGP 路径。
可以通过后门链路到达的 IGP 路由称作后门路由。&lt;/p&gt;

&lt;p&gt;有了这种后门路由，就需要一种机制，能够使得一种协议的优先级比另一种更高。例如，
Cisco 提供的 &lt;strong&gt;&lt;em&gt;administrative distance&lt;/em&gt;&lt;/strong&gt; 就是这个功能。&lt;/p&gt;

&lt;p&gt;通过设置不同协议的路由的优先级，使得后门路由被选中作为最优路由。
或者，前面介绍过，通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;distance&lt;/code&gt; BGP 命令也可以设置优先级。&lt;/p&gt;

&lt;h3 id=&quot;64-bgp-路由过程&quot;&gt;6.4 BGP 路由过程&lt;/h3&gt;

&lt;p&gt;简要查看完整的 BGP 路由处理过程。&lt;/p&gt;

&lt;p&gt;BGP 是一种相当简单的协议，这也是它灵活的原因。BGP peer 之间通过 UPDATE 消息交换
路由。BGP 路由器收到 UPDATE 消息后，运行一些策略或者对消息进行过滤，然后将路由转
发给其他 BGP peers。&lt;/p&gt;

&lt;p&gt;BGP 实现需要维护一张 BGP 路由表，这张表是和 IP 路由表独立的。如果到同一目的地有
多条路由，BGP 并不会将所有这些路由都转发给 peer；而是选出最优路由，然后将最优路
由转发给 peer。除了传递从 peer 来的 eBGP 路由，或从路由反射器客户端（RR client）
来的 iBGP 路由之外，BGP 路由器还可以主动发起路由更新，通告它所在 AS 内的内部网络。&lt;/p&gt;

&lt;p&gt;来源是本 AS 的合法的本地路由，以及从 BGP peer 学习到的最优路由，会被添加到 IP 路
由表。IP 路由表是最终的路由决策表，用于操控转发表。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-8.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-8 Routing Process Overview&lt;/p&gt;

&lt;h4 id=&quot;bgp-路由通告和存储&quot;&gt;BGP 路由：通告和存储&lt;/h4&gt;

&lt;p&gt;根据 RFC 1771，BGP 协议中路由（route）的定义是：一条路由是&lt;strong&gt;一个目标及其到达这个目
标的一条路径的属性&lt;/strong&gt;组成的信息单元（a route is defined as a unit of information that pairs a destination with the attributes of a path to that destination）。&lt;/p&gt;

&lt;p&gt;路由在 BGP peer 之间通过 UPDATE 消息进行通告：目标是 NLRI 字段，路径是 path 属性
字段。&lt;/p&gt;

&lt;p&gt;路由存储在 RIB（Routing Information Bases）。&lt;/p&gt;

&lt;p&gt;BGP speaker 选择通告一条路由的时候，可能会修改路由的 path 属性。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-9.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-9 BGP 路由表的逻辑表示&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个 Adj-RIB-In 逻辑上对应一个 peer，存储从 peer 学习到的路由&lt;/li&gt;
  &lt;li&gt;Loc-RIB 存储最优路由&lt;/li&gt;
  &lt;li&gt;一个 Adj-RIB-Out 逻辑上对应一个 peer，存储准备从这个路由器发送给对应 peer 的路由&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里的逻辑图是将过程分成了三部分，每部分都有自己的存储，但实现不一定这样，事实上
大部分实现都是共享一份路由表，以节省内存。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-10.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-10 Sample Routing Environment&lt;/p&gt;

&lt;h4 id=&quot;bgp-决策过程总结&quot;&gt;BGP 决策过程总结&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;如果下一跳不可达，则忽略此路由（这就是为什么有一条 IGP 路由作为下一跳如此重要
的原因）&lt;/li&gt;
  &lt;li&gt;选择权重最大的一条路径&lt;/li&gt;
  &lt;li&gt;如果权重相同，选择本地偏向（local preference）最大的一条路由&lt;/li&gt;
  &lt;li&gt;如果没有源自本地的路由（locally originated routes），并且 local preference 相
同，则选择 AS_PATH 最短的路由&lt;/li&gt;
  &lt;li&gt;如果 AS_PATH 相同，选择 origin type 最低（&lt;code class=&quot;highlighter-rouge&quot;&gt;IGP &amp;lt; EGP &amp;lt; INCOMPLETE&lt;/code&gt;）的路由&lt;/li&gt;
  &lt;li&gt;如果 origin type 相同，选择 MED 最低的，如果这些路由都是从同一个 AS 收到的&lt;/li&gt;
  &lt;li&gt;如果 MED 相同，优先选择 eBGP（相比于 iBGP）&lt;/li&gt;
  &lt;li&gt;如果前面所有条件都相同，选择经过最近的 IGP 邻居的路由——也就是选择 AS 内部最短
的到达目的的路径&lt;/li&gt;
  &lt;li&gt;如果内部路径也相同，那就依靠 BGP ROUTE_ID 来选择了。选择从 RID 最小的 BGP 路
由器来的路由。对 Cisco 路由器来说，RID 就是路由器的 loopback 地址。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;65-controlling-bgp-routes&quot;&gt;6.5 Controlling BGP Routes&lt;/h3&gt;

&lt;p&gt;介绍路由的每个属性。&lt;/p&gt;

&lt;h4 id=&quot;origintype-code-1&quot;&gt;ORIGIN（type code 1)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;0: &lt;code class=&quot;highlighter-rouge&quot;&gt;IGP&lt;/code&gt;, NLRI that is inteior to the originating AS&lt;/li&gt;
  &lt;li&gt;1: &lt;code class=&quot;highlighter-rouge&quot;&gt;EGP&lt;/code&gt;, NLRI learned via EGP&lt;/li&gt;
  &lt;li&gt;2: &lt;code class=&quot;highlighter-rouge&quot;&gt;INCOMPLETE&lt;/code&gt;, NLRI learned by some means&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;as_path&quot;&gt;AS_PATH&lt;/h4&gt;

&lt;p&gt;BGP 依靠这个字段实现路由无环路。里面存储了路径上的 ASN。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-11.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-11 Sample Loop Condition Addressed by the AS_PATH Attribute&lt;/p&gt;

&lt;h4 id=&quot;next_hop&quot;&gt;NEXT_HOP&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/6-12.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-12 BGP NEXT_HOP Example&lt;/p&gt;

&lt;h3 id=&quot;66-route-filtering-and-attribute-manipulation&quot;&gt;6.6 Route Filtering and Attribute Manipulation&lt;/h3&gt;

&lt;h3 id=&quot;67-bgp-4-aggregation&quot;&gt;6.7 BGP-4 Aggregation&lt;/h3&gt;

&lt;h3 id=&quot;68-looking-ahead&quot;&gt;6.8 Looking Ahead&lt;/h3&gt;

&lt;h3 id=&quot;69-frequently-asked-questions&quot;&gt;6.9 Frequently Asked Questions&lt;/h3&gt;

&lt;h4 id=&quot;是否应该将-bgp-路由注入-igp&quot;&gt;是否应该将 BGP 路由注入 IGP？&lt;/h4&gt;

&lt;p&gt;不。不推荐将 BGP 路由注入 IGP。应该关闭 BGP synchronization。&lt;/p&gt;

&lt;h3 id=&quot;61-references&quot;&gt;6.1 References&lt;/h3&gt;

&lt;p&gt;&lt;a name=&quot;chap_7&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;7-冗余对称和负载均衡&quot;&gt;7 冗余、对称和负载均衡&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;冗余：发生链路故障时，有备用路由&lt;/li&gt;
  &lt;li&gt;对称：流量在相同的点进出 AS（enters and exits an AS at the same point）&lt;/li&gt;
  &lt;li&gt;负载均衡：在多条链路之间均衡地分发流量&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;71-冗余&quot;&gt;7.1 冗余&lt;/h3&gt;

&lt;p&gt;冗余和对称这两个目标是有冲突的：&lt;strong&gt;一个网络提供的冗余越多，它的对称性越难保证&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;冗余最终会以路由的形式落到路由表&lt;/strong&gt;。为了避免路由表过于复杂，通常的冗余实现方式
就是默认路由（default routing）。&lt;/p&gt;

&lt;h4 id=&quot;设置默认路由&quot;&gt;设置默认路由&lt;/h4&gt;

&lt;p&gt;默认路由是&lt;strong&gt;优先级最低的路由&lt;/strong&gt;，因此是最后的选择（gateway of the last resort）。分为两种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;动态学习&lt;/li&gt;
  &lt;li&gt;静态配置&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;动态学习默认路由&quot;&gt;动态学习默认路由&lt;/h5&gt;

&lt;p&gt;0.0.0.0/0.0.0.0 是全网约定的默认路由，并且可以动态通告给其他路由器。通告此路由的
系统表示它可以&lt;strong&gt;作为其他系统最后尝试的网关&lt;/strong&gt;（represents itself as a gateway of
last resort for other systems）。&lt;/p&gt;

&lt;p&gt;动态默认路由可以通过 BGP 或 IGP 学习。出于冗余目的，应该设置允许从多个源学习默认
路由。在 BGP 中，可以通过设置 &lt;code class=&quot;highlighter-rouge&quot;&gt;local reference&lt;/code&gt; 给默认路由设置优先级。如果高优先
级的默认路由发生故障，低优先级的可以补上。&lt;/p&gt;

&lt;h5 id=&quot;静态配置默认路由&quot;&gt;静态配置默认路由&lt;/h5&gt;

&lt;p&gt;动态学习到的默认路由可能不是我们想要的，因此一些管理员会选择静态配置默认路由。&lt;/p&gt;

&lt;p&gt;静态默认路由也可以设置多条，用优先级区分。&lt;/p&gt;

&lt;h3 id=&quot;72-对称&quot;&gt;7.2 对称&lt;/h3&gt;

&lt;p&gt;流量从 AS 的哪个点出去的，也通过哪个点进来。&lt;/p&gt;

&lt;p&gt;大部分情况下都应该是对称的，但是特定的一些场景下也会有非对称的情况，与设计有关。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;实际上非对称路由在现实中并不少见（more often than not），而且也没有造成太大问
题。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;73-非对称路由&quot;&gt;7.3 非对称路由&lt;/h3&gt;

&lt;p&gt;流量要根据 inbound 和 outbound 分开考虑。
例如，如果网络和 ISP1 之间的带宽被打爆了，那你肯定是先问：是 inbound 还是
outbound 被打爆了？&lt;/p&gt;

&lt;p&gt;路由行为影响因素：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;inbound traffic&lt;/code&gt; 受&lt;strong&gt;本 AS 通告出去的路由&lt;/strong&gt;的影响&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;outbound traffic&lt;/code&gt; 受&lt;strong&gt;本 AS 从其他 AS 学习到的路由&lt;/strong&gt;的影响&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，要调整 inbound 流量，就需要调整从本 AS 通告出去的路由；而要调整 outbound，
就需要控制本 AS 如何学习邻居通告的路由。&lt;/p&gt;

&lt;h3 id=&quot;74-不同场景下对三者的权衡&quot;&gt;7.4 不同场景下对三者的权衡&lt;/h3&gt;

&lt;p&gt;可以看出，冗余、对称和负载均衡之间是有联系的，并且存在一些冲突。&lt;/p&gt;

&lt;p&gt;第六章介绍的路由属性（routing attributes）是实现这三个目标的工具。&lt;/p&gt;

&lt;h3 id=&quot;75-looking-ahead&quot;&gt;7.5 Looking Ahead&lt;/h3&gt;

&lt;h3 id=&quot;76-frequently-asked-questions&quot;&gt;7.6 Frequently Asked Questions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;BGP 本身不考虑链路速度和流量特性&lt;/strong&gt;，因此需要管理员通过策略配置达到所期望的目的。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_8&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;8-as-内部路由控制&quot;&gt;8 AS 内部路由控制&lt;/h2&gt;

&lt;h3 id=&quot;81-非-bgp-路由器和-bgp-路由器的交互&quot;&gt;8.1 非 BGP 路由器和 BGP 路由器的交互&lt;/h3&gt;

&lt;p&gt;非 BGP 路由器如何连接到外部网络：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将 BGP 注入到 IGP（即，将外部路由注入到 AS 内部）&lt;/li&gt;
  &lt;li&gt;静态配置 AS 内的默认路由到外网&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;811-bgp-注入-igp&quot;&gt;8.1.1 BGP 注入 IGP&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;不推荐将全部 BGP 路由注入到 IGP&lt;/strong&gt;，这会给 IGP 路由增加很大的负担。IGP 路由是针
对AS 内路由和很小的网络设计的，不适用于大规模网络。但可以将部分 BGP 路由注入 IGP。&lt;/p&gt;

&lt;p&gt;需要考虑的因素：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算路径和处理路由更新所需的内存、CPU&lt;/li&gt;
  &lt;li&gt;link utilization from routing control traffic&lt;/li&gt;
  &lt;li&gt;对收敛的影响&lt;/li&gt;
  &lt;li&gt;IGP 的限制&lt;/li&gt;
  &lt;li&gt;网络拓扑&lt;/li&gt;
  &lt;li&gt;其他&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果 IGP 非常老，例如 RIP-1，不支持 CIDR，那 BGP 过来的 CIDR 路由都会丢失&lt;/li&gt;
  &lt;li&gt;BGP 路由的抖动会引起 IGP 的抖动，很多 IGP 挂掉都是这个原因&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;812-静态配置默认路由&quot;&gt;8.1.2 静态配置默认路由&lt;/h4&gt;

&lt;p&gt;在每个 AS 的边界路由器上添加一条默认路由。&lt;/p&gt;

&lt;h3 id=&quot;82-bgp-policies-conflicting-with-internal-defaults&quot;&gt;8.2 BGP Policies Conflicting with Internal Defaults&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;BGP 路由策略和 IGP 的默认行为有冲突会导致出现路由环路&lt;/strong&gt;，来看 图 8-2 这个例子
。&lt;/p&gt;

&lt;h4 id=&quot;821-例子主备-bgp-策略和-igp-默认行为冲突导致环路&quot;&gt;8.2.1 例子：主备 BGP 策略和 IGP 默认行为冲突导致环路&lt;/h4&gt;

&lt;p&gt;考虑图 8-2。RTC 和 RTD 和外面的 AS 运行 eBGP；在 AS 内部，它们两个之间运行 iBGP
。但是，他们不是直连的，要经过 RTA 和 RTB 两个非 BGP 路由器。RTA 和 RTB 会和 AS
内的所有路由器运行 IGP 协议，因此它们看不到所有的外部路由（BGP 路由）。&lt;/p&gt;

&lt;p&gt;如果 BGP 策略是 RTD 做主，RTC 做备，那 RTC 收到流量时，会转发给 RTD，但因为 RTC
和 RTD 不是直连的，因此它会先转发给 RTA。RTA 根据 IGP 学习到的默认路由是 RTC，因
此它又会将流量转发回 RTC，形成了路由环路。&lt;/p&gt;

&lt;p&gt;RTC 和 RTD 之间出现环路：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/8-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 8-2 Following Defaults: Loop Situation&lt;/p&gt;

&lt;p&gt;解决这个问题的办法有如下几种。&lt;/p&gt;

&lt;h5 id=&quot;方案-1-修改-igp-metric&quot;&gt;方案 1: 修改 IGP Metric&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;将 RTA 的默认路由从指向 RTC 改为指向 RTD&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;具体地，将 RTC 的默认路由 0/0 的 metric 设置的非常大。这样 RTD 的路径相比之下很
短，RTA就会将 RTA-RTB-RTD 作为最优路径。&lt;/p&gt;

&lt;h5 id=&quot;方案-2-直连-rtc-和-rtd&quot;&gt;方案 2: 直连 RTC 和 RTD&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;直连 RTC 和 RTD，使得二者之间的最优路径不需要经过 RTA。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;RTC-RTD 是 iBGP 路径，RTC-RTA-RTB-RTD 是 IGP 路径。&lt;/p&gt;

&lt;h5 id=&quot;方案-3-transit-routers-都跑-bgp&quot;&gt;方案 3: Transit Routers 都跑 BGP&lt;/h5&gt;

&lt;p&gt;Transit routers 都跑 BGP，在图 8-2 中就是 RTA 和 RTB。&lt;/p&gt;

&lt;h5 id=&quot;方案-4-控制默认路由自动注入&quot;&gt;方案 4: 控制默认路由自动注入&lt;/h5&gt;

&lt;p&gt;RTD 和 RTC 只有一个注入默认路由，另一个不注入。&lt;/p&gt;

&lt;p&gt;缺点：在对 primary/backup 模式有用，而且 primary 挂掉之后，backup 用不了，因为它
没有注入默认路由。&lt;/p&gt;

&lt;h4 id=&quot;822-defaults-inside-the-as-other-bgp-policies&quot;&gt;8.2.2 Defaults Inside the AS: Other BGP Policies&lt;/h4&gt;

&lt;p&gt;IGP 默认配置和 BGP policy 冲突产生的环路。&lt;/p&gt;

&lt;h3 id=&quot;83-策略路由policy-routing&quot;&gt;8.3 策略路由（Policy Routing）&lt;/h3&gt;

&lt;p&gt;通常所说的路由，都是根据&lt;strong&gt;目的地址&lt;/strong&gt;做转发。&lt;/p&gt;

&lt;p&gt;而策略路由是根据&lt;strong&gt;源地址&lt;/strong&gt;，或&lt;strong&gt;源地址+目的地址&lt;/strong&gt;做转发。可以做更高级的路由控制。&lt;/p&gt;

&lt;h3 id=&quot;84-looking-ahead&quot;&gt;8.4 Looking Ahead&lt;/h3&gt;

&lt;h3 id=&quot;85-frequently-asked-questions&quot;&gt;8.5 Frequently Asked Questions&lt;/h3&gt;

&lt;p&gt;&lt;a name=&quot;chap_9&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;9-大型-as-控制管理&quot;&gt;9 大型 AS 控制管理&lt;/h2&gt;

&lt;p&gt;网络节点超过几百个之后，会带来很大的管理问题。&lt;/p&gt;

&lt;h2 id=&quot;91-路由反射器route-reflectors&quot;&gt;9.1 路由反射器（Route Reflectors）&lt;/h2&gt;

&lt;p&gt;BGP 之间通过 full-mesh 做 peering，当节点多了之后，BGP mesh 非常复杂。&lt;/p&gt;

&lt;p&gt;引入路由反射器（Route Reflector，RR）。RR 带来的好处：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;向多个 peer 发送 UPDATE 时效率更高&lt;/li&gt;
  &lt;li&gt;路由器只需要和 local RR 做 peer，大大减少 BGP session 的数量&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;只有 BGP mesh 比较大之后才推荐 RR。因为 &lt;strong&gt;RR 也是有代价的&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;增加额外计算开销&lt;/li&gt;
  &lt;li&gt;如果配置不正常会引起路由环路和路由不稳定&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;911-没有-rr-的拓扑full-mesh&quot;&gt;9.1.1 没有 RR 的拓扑：full-mesh&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/9-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9-1 Internal Peers in a Normal Full-Mesh Environment&lt;/p&gt;

&lt;p&gt;没有 RR 的情况下，同一 AS 内的 BGP speaker 之间形成一个 &lt;strong&gt;logical&lt;/strong&gt; full-mesh。
如图9-1 所示，虽然 RTA-RTC 之间没有物理链路，但仍然有一条逻辑 peer 链路。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RTB 从 RTA 收到的 UPDATE 消息并不会发送给 RTC&lt;/strong&gt;，因为：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;RTC 是内部节点（同一个 AS）&lt;/li&gt;
  &lt;li&gt;这条 UPDATE 消息也是从内部节点发来的（RTA）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因此，如果 RTA-RTC 之间没有做 peer，RTC 就收不到 RTA 的消息；所以没有 RR 的情况
下必须得用 full-mesh。&lt;/p&gt;

&lt;h4 id=&quot;912-有-rr-的拓扑&quot;&gt;9.1.2 有 RR 的拓扑&lt;/h4&gt;

&lt;p&gt;再来看有 RR 的情况，如图 9-2 所示。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/9-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9-2 Internal Peers Using a Route Reflector&lt;/p&gt;

&lt;p&gt;引入 RR 之后，其他路由器称为客户端。客户端和 RR 之间做 peer，RR 再将消息转发给其
他 IBGP 或 eBGP peers。&lt;/p&gt;

&lt;p&gt;RR 大大减少了 BGP session 数量，使得网络更具扩展性。&lt;/p&gt;

&lt;h4 id=&quot;913-路由反射原则&quot;&gt;9.1.3 路由反射原则&lt;/h4&gt;

&lt;p&gt;所有设备分为三类：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;路由反射器&lt;/li&gt;
  &lt;li&gt;路由反射器的客户端，简称客户端&lt;/li&gt;
  &lt;li&gt;非路由反射器的客户端，简称非客户端&lt;/li&gt;
&lt;/ol&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/9-3.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9-3 Route Reflection Process Components&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;路由反射原则&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从 nonclient peer 来的路由，只反射给 clients（无须反射给 nonclients 是因为
nonclients 之间有 full-mesh）&lt;/li&gt;
  &lt;li&gt;从 client peer 来的路由，反射给 clients 及 nonclients&lt;/li&gt;
  &lt;li&gt;从 eBGP peer 来的路由，反射给 clients 及 nonclients&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;RR 只用于 AS 内部，因此 AS 边界的外部路由节点（eBGP）也当作 nonclients 对待。&lt;/p&gt;

&lt;h4 id=&quot;914-rr-高可用&quot;&gt;9.1.4 RR 高可用&lt;/h4&gt;

&lt;p&gt;RR 是集中式节点，因此非常重要，需要做冗余。&lt;/p&gt;

&lt;p&gt;但是，如果本身物理拓扑就没有冗余，那 RR 做冗余也是无用的，如下图。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/9-4.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9-4 Comparison of Logical and Physical Redundancy Solutions&lt;/p&gt;

&lt;h4 id=&quot;915-rr-拓扑&quot;&gt;9.1.5 RR 拓扑&lt;/h4&gt;

&lt;p&gt;RR 拓扑主要取决于物理网络拓扑，事实上每个路由器都可以配置成 RR。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/9-5.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9-5 Complex Multiple Route Reflector Environment&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RR 不会修改路由消息的属性&lt;/strong&gt;（UPDATE attributes，例如 NEXT_HOP），但是一些实现
会允许 RR 做一些过滤工作。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/9-7.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9-7 Typical BGP Route Reflection Topology&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/internet-routing-arch/9-8.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9-8 Full-Mesh BGP Topology&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_10&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;10-设计稳定的因特网&quot;&gt;10 设计稳定的因特网&lt;/h2&gt;

&lt;h3 id=&quot;101-因特网路由的不稳定性&quot;&gt;10.1 因特网路由的不稳定性&lt;/h3&gt;

&lt;p&gt;最常见的现象：路由抖动（flapping），BGP 频繁 UPDATE 和 WITHDRAWN 路由。&lt;/p&gt;

&lt;p&gt;一些影响因特网路由稳定性的因素：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;IGP 不稳定&lt;/li&gt;
  &lt;li&gt;硬件错误&lt;/li&gt;
  &lt;li&gt;软件问题&lt;/li&gt;
  &lt;li&gt;CPU、内存等资源不足&lt;/li&gt;
  &lt;li&gt;网络升级和例行维护&lt;/li&gt;
  &lt;li&gt;人为错误&lt;/li&gt;
  &lt;li&gt;链路拥塞&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;102-bgp-stability-features&quot;&gt;10.2 BGP Stability Features&lt;/h3&gt;

&lt;h1 id=&quot;iv-internet-routing-device-configuration&quot;&gt;IV: Internet Routing Device Configuration&lt;/h1&gt;
</description>
        
          <description>&lt;h3 id=&quot;关于本文&quot;&gt;关于本文&lt;/h3&gt;

</description>
        
        <pubDate>Mon, 08 Apr 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/internet-routing-architecture-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/internet-routing-architecture-zh/</guid>
        
        
        <category>bgp</category>
        
        <category>datacenter</category>
        
      </item>
      
    
      
      <item>
        <title>[笔记] BGP in the Data Center (O'Reilly 2017)</title>
        <description>&lt;h3 id=&quot;关于本文&quot;&gt;关于本文&lt;/h3&gt;

&lt;p&gt;本文是我在读 &lt;a href=&quot;https://www.oreilly.com/library/view/bgp-in-the/9781491983416/&quot;&gt;BGP in the Data
Center&lt;/a&gt; （
O’Reilly, 2017）时的读书笔记。原书很短，只有 90 页不到，但理论和实践兼备，是现代
数据中心和 BGP 入门的很好参考。&lt;/p&gt;

&lt;p&gt;作者 Dinesh G. Dutt 是一家网络公司的首席科学家，在网络行业有 20 多年工作经验，曾
是 Cisco Fellow，是 TRILL、VxLAN 等协议的合作者（co-author）之一。&lt;/p&gt;

&lt;p&gt;BGP 原本是用于服务供应商（service provider）网络的，并不适用于数据中心，因此进入
到数据中心的 BGP 是经过改造的。本文介绍的就是&lt;strong&gt;数据中心中的&lt;/strong&gt; BGP（BGP in the
data center），这与传统BGP 还是有很大不同的。&lt;/p&gt;

&lt;p&gt;以下是笔记内容。&lt;/p&gt;

&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_1&quot;&gt;数据中心网络绪论&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;1.1 &lt;a href=&quot;#chap_1.1&quot;&gt;数据中心网络的需求&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.2 &lt;a href=&quot;#chap_1.2&quot;&gt;Clos 网络拓扑&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.3 &lt;a href=&quot;#chap_1.3&quot;&gt;Clos 网络架构&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.4 &lt;a href=&quot;#chap_1.4&quot;&gt;服务器接入模型&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.5 &lt;a href=&quot;#chap_1.5&quot;&gt;连接到外部网络&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.6 &lt;a href=&quot;#chap_1.6&quot;&gt;多租户（或 Cloud）支持&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.7 &lt;a href=&quot;#chap_1.7&quot;&gt;现代数据中心设计的运维考虑&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;1.8 &lt;a href=&quot;#chap_1.8&quot;&gt;选择路由协议&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_2&quot;&gt;BGP 是如何适配到数据中心的&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;2.1 &lt;a href=&quot;#chap_2.1&quot;&gt;几种路由协议&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.2 &lt;a href=&quot;#chap_2.2&quot;&gt;iBGP 和 eBGP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.3 &lt;a href=&quot;#chap_2.3&quot;&gt;ASN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.4 &lt;a href=&quot;#chap_2.4&quot;&gt;最优路径算法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.5 &lt;a href=&quot;#chap_2.5&quot;&gt;多路径选择&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.6 &lt;a href=&quot;#chap_2.6&quot;&gt;默认定时器导致的慢收敛&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.7 &lt;a href=&quot;#chap_2.7&quot;&gt;数据中心默认 BGP 配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2.8 &lt;a href=&quot;#chap_2.8&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_3&quot;&gt;自动化 BGP 配置&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;3.1 &lt;a href=&quot;#chap_3.1&quot;&gt;自动化配置基础&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;3.2 &lt;a href=&quot;#chap_3.2&quot;&gt;示例数据中心网络&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;3.3 &lt;a href=&quot;#chap_3.3&quot;&gt;自动化传统 BGP 的困难&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;3.4 &lt;a href=&quot;#chap_3.4&quot;&gt;路由再分发&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;3.5 &lt;a href=&quot;#chap_3.5&quot;&gt;路由策略&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;3.6 &lt;a href=&quot;#chap_3.6&quot;&gt;使用接口名作为邻居&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;3.7 &lt;a href=&quot;#chap_3.7&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_4&quot;&gt;其他 BGP 配置&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;4.1 &lt;a href=&quot;#chap_4.1&quot;&gt;接口 IP 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;remote-as&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;4.2 &lt;a href=&quot;#chap_4.2&quot;&gt;Numbered Interfaces 数量&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;4.3 &lt;a href=&quot;#chap_4.3&quot;&gt;Unnumbered Interfaces&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;4.4 &lt;a href=&quot;#chap_4.4&quot;&gt;BGP Unnumbered&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;4.5 &lt;a href=&quot;#chap_4.5&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;remote-as&lt;/code&gt; 指定 BGP session 类型&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;4.6 &lt;a href=&quot;#chap_4.6&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_5&quot;&gt;BGP 生命周期管理&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;5.1 &lt;a href=&quot;#chap_5.1&quot;&gt;查看配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;5.2 &lt;a href=&quot;#chap_5.2&quot;&gt;连接到外部网络&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;5.3 &lt;a href=&quot;#chap_5.3&quot;&gt;计划节点维护&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;5.4 &lt;a href=&quot;#chap_5.4&quot;&gt;Debug BGP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;5.5 &lt;a href=&quot;#chap_5.6&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chap_6&quot;&gt;服务器上运行 BGP&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;6.1 &lt;a href=&quot;#chap_6.1&quot;&gt;虚拟服务器的兴起&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;6.2 &lt;a href=&quot;#chap_6.2&quot;&gt;和服务器做 Peering 时的 BGP 配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;6.3 &lt;a href=&quot;#chap_6.3&quot;&gt;在服务器 BGP 软件&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;6.4 &lt;a href=&quot;#chap_6.4&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;数据中心中的&lt;/strong&gt; BGP 就像一头怪兽（a rather strange beast）。BGP 进入数据中心是
相当意外的（rather unexpected），但现在已经是数据中心路由协议（routing protocol
）的首选。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本书定位&lt;/strong&gt;：网络运维人员和工程师，有基本的网络和 BGP 知识，想知道 BGP 在数据中
心是如何应用的。
理解本书内容无需任何 BGP 高级知识，或任何特定路由平台的经验。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本书主要目的&lt;/strong&gt;：用一本书囊括数据中心部署 BGP 所需的&lt;strong&gt;理论和实践&lt;/strong&gt;（theory and
pratice）。&lt;/p&gt;

&lt;p&gt;本书使用的 BGP 软件：&lt;a href=&quot;https://frrouting.org&quot;&gt;FRRouting&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-数据中心网络绪论&quot;&gt;1 数据中心网络绪论&lt;/h2&gt;

&lt;p&gt;本章介绍在给定应用需求和预期规模的前提下，如何为现代数据中心设计网络（network
design of a modern data center network）。&lt;/p&gt;

&lt;p&gt;和十年前相比，现代数据中心规模更大，网络部署速度要求更快（秒级而不是天级）。这显
著影响了网络的设计和部署。&lt;/p&gt;

&lt;p&gt;BGP（Border Gateway Protocol）：&lt;strong&gt;边界网关协议&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;过去的几十年里，连接到互联网（公网）的系统通过 BGP 发现彼此（find one another）
。但是，它也可以用在数据中心内部。现代数据中心中使用最广泛的路由协议就是 BGP。
BGP是标准协议，有很多免费和开源（free and open source，这里 “free” 作者应该是指“免
费”，而不是“自由软件”的“自由”）的软件实现。&lt;/p&gt;

&lt;p&gt;本章试图回答以下问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;现代数据中心网络设计的目标是什么？&lt;/li&gt;
  &lt;li&gt;这些目标与其他网络（例如企业网和园区网，enterprise and campus）的设计目标有什么不同？&lt;/li&gt;
  &lt;li&gt;数据中心为什么选择 BGP 作为路由协议？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;11-数据中心网络的需求&quot;&gt;1.1 数据中心网络的需求&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;现代数据中心的演进都是由大型互联网公司的需求驱动的&lt;/strong&gt;，例如 Google 和 Amazon。&lt;/p&gt;

&lt;p&gt;核心需求：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;服务器到服务器通信越来越多（Increased server-to-server communication）&lt;/p&gt;

    &lt;p&gt;单体应用到微服务化的转变，导致南北向流量减少，东西向流量增加。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;规模（Scale）&lt;/p&gt;

    &lt;p&gt;过去，几百台服务器就已经是一个大数据中心；现在，现代数据中心一个机
 房可能就有上万台服务器。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;弹性（Resilience）&lt;/p&gt;

    &lt;p&gt;老式数据中心的设计都是&lt;strong&gt;假设网络是可靠的&lt;/strong&gt;，而现代数据中心应用都是&lt;strong&gt;假设网络
 是不可靠的&lt;/strong&gt; —— 总会由于各种原因导致网络或机器故障。弹性就是要保证发生故障时
 ，&lt;strong&gt;受影响的范围可控，尽量做到不影响用户体验&lt;/strong&gt;。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;现代数据中心网络必须满足以上三方面基本需求。&lt;/p&gt;

&lt;p&gt;多租户网络需要额外考虑：支持&lt;strong&gt;虚拟网络的快速部署和拆除&lt;/strong&gt;（rapid deployment and
teardown)。&lt;/p&gt;

&lt;p&gt;传统网络设计的扩展方式：&lt;strong&gt;scale-in&lt;/strong&gt;（垂直扩展），即通过更换性能更高的设备实现。
缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;高性能设备特别贵&lt;/li&gt;
  &lt;li&gt;这些设备大部分都是两方冗余（two-way redundancy），存在同时挂掉的风险，可用性
不是足够高&lt;/li&gt;
  &lt;li&gt;发生故障时，故障范围特别大（尤其是核心设备）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;12-clos-网络拓扑&quot;&gt;1.2 Clos 网络拓扑&lt;/h3&gt;

&lt;p&gt;大型互联网公司最后采用了一种称为 Clos 的架构。Clos 架构最初是贝尔实验室的
Charles Clos 在 1950s 为电话交换网设计的。&lt;/p&gt;

&lt;p&gt;可以实现&lt;strong&gt;无阻塞架构&lt;/strong&gt;（non-blocking architecture）：上下行带宽都充分利用。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/1-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-1 简单的两级（two-tier） Clos 网络&lt;/p&gt;

&lt;p&gt;特点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;连接的一致性&lt;/strong&gt;（uniformity of connectivity）：任意两个服务器之间都是 3 跳&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;节点都是同构的&lt;/strong&gt;（homogeneous）：服务器都是对等的，交换机/路由器也是&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;全连接&lt;/strong&gt;（full-mesh）：故障时影响面小（gracefully with failures）；总带宽高
，而且方便扩展，总带宽只受限于 Spine 的接口数量&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注意，在以上模型中，&lt;strong&gt;Spine 仅仅用于连接 Leaf，因此在这种模型中，所有的功能（
functionality）都集中在 Leaf 上&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;扩展方式：&lt;strong&gt;scale-out&lt;/strong&gt;（水平扩展）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最大服务器数量&lt;/strong&gt;（无阻塞架构下）：&lt;code class=&quot;highlighter-rouge&quot;&gt;n * m / 2&lt;/code&gt;，其中 &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;是一个 Leaf 节点的端口
数量，&lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt; 是一个Spine 节点的端口数量。&lt;/p&gt;

&lt;p&gt;典型带宽，分为接入（leaf-server）和互连（leaf-spine）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;接入 10G，互连 40G&lt;/li&gt;
  &lt;li&gt;接入 25G，互连 100G&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;受电源限制，单个机柜最大不超过 40 台服务器。&lt;/p&gt;

&lt;h4 id=&quot;三级-clos-网络&quot;&gt;三级 Clos 网络&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/1-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-2 三级（three-tier） Clos 网络&lt;/p&gt;

&lt;p&gt;一组 ToR 和 Leaf 组成一个二级 Clos，称为一个 pod 或 cluster；
pod/cluster 作为一个独立单元再和 Spine 组成一个二级 Clos。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最大服务器数量&lt;/strong&gt;：&lt;code class=&quot;highlighter-rouge&quot;&gt;n * n * n /4&lt;/code&gt;，其中 &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt; 是交换机端口数量。&lt;/p&gt;

&lt;p&gt;Clos 架构的魅力：无论从哪一级看，每个组成部分都是类似的，可以方便地替换和扩容。&lt;/p&gt;

&lt;p&gt;为了解决规模瓶颈，大型互联网公司甚至会考虑 4 级甚至 6 级 Clos 架构。&lt;/p&gt;

&lt;h4 id=&quot;clos-网络的副作用&quot;&gt;Clos 网络的副作用&lt;/h4&gt;

&lt;p&gt;由于 Spine 和 Leaf 之间是 full-mesh，网线会特别多，排线会复杂一些。&lt;/p&gt;

&lt;p&gt;设备故障影响面比较小，排障和更换设备方便（resilience）。&lt;/p&gt;

&lt;p&gt;设备都是对等的，管理比较方便。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;13-clos-network-网络架构&quot;&gt;1.3 Clos Network 网络架构&lt;/h3&gt;

&lt;p&gt;传统网络架构中，接入层和汇聚层走二层交换，因此需要运行 STP 协议消除二层环路。
如果在 Clos 网络中交换机也走二层，那可用（active）链路就会大大减少，如图 1-3 所
示：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/1-3.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-3 启用 STP 之后的网络连接&lt;/p&gt;

&lt;p&gt;如果有链路发生故障，那可用链路的效率会更低：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/1-4.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-4 启用 STP 并且一条链路发生故障之后的网络连接&lt;/p&gt;

&lt;p&gt;由此可见，&lt;strong&gt;走二层会导致非常低效和不均匀的连接&lt;/strong&gt;（highly inefficient and
nonuniform connectivity）。&lt;/p&gt;

&lt;p&gt;而另一方面，如果走三层路由，那就可以充分利用 Spine 和 Leaf 之间的 full-mesh
连接。而且路由还可以判断最短路径，或者为了达到更高整体利用率设置特定的路径。&lt;/p&gt;

&lt;p&gt;因此，第一个结论：&lt;strong&gt;对于 Spine-Leaf 网络，路由（三层）比交换（二层）更合适&lt;/strong&gt;。通
过二层连接的网络称为&lt;strong&gt;桥接网络&lt;/strong&gt;（bridged network）；通过路由连接的网络称为&lt;strong&gt;路
由网络&lt;/strong&gt;（routed network）。&lt;/p&gt;

&lt;p&gt;使用路由的另一个好处是，避免了各种厂商相关的 STP 优化方案（将多条物理链路聚合成
一条虚拟链路提高利用率）。&lt;/p&gt;

&lt;p&gt;典型的传统桥接网络需要运行：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;STP&lt;/li&gt;
  &lt;li&gt;一个单向链路检测协议（虽然现在已经合并到 STP 了）&lt;/li&gt;
  &lt;li&gt;一个 VLAN 分发协议&lt;/li&gt;
  &lt;li&gt;一个 first-hop 路由协议，例如 HSRP（Host Standby Routing Protocol） 或 VRRP（Virtual Router Redundancy Protocol）&lt;/li&gt;
  &lt;li&gt;一个路由协议，用于连接多个桥接网络&lt;/li&gt;
  &lt;li&gt;一个独立的单向链路检测协议，用于走路由的链路（routed links）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果是路由网络，那只需要：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;一个路由协议（例如 BGP）&lt;/li&gt;
  &lt;li&gt;一个单向链路检测协议&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;和服务器直连的路由器（leaf）会充当 anycast gateway（也可以称为分布式网关）&lt;/strong&gt;，
此外就不需要其他协议了。&lt;/p&gt;

&lt;p&gt;以上，就是 Clos 网络如何实现高度可扩展和弹性伸缩的。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;14-服务器接入模型server-attach-model&quot;&gt;1.4 服务器接入模型（Server Attach Model）&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;单接入&lt;/strong&gt;（single-attach）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;双接入&lt;/strong&gt;（dual-attach）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;大型互联网公司采用&lt;strong&gt;单接入方式&lt;/strong&gt;（single-attach servers），即，每个服务器只连接
到单个置顶交换机。这种设计背后的逻辑是：服务器数量足够多，由于网络问题导致单个机
柜挂掉时，影响不是很大。&lt;/p&gt;

&lt;p&gt;但是对于小型网络，乃至部分大型公司的网络，挂掉一个机柜带来的影响是不能接受的。
因此这些公司采用&lt;strong&gt;双接入&lt;/strong&gt;（dual-attach servers）方式：每个服务器连接到两个置顶
交换机。&lt;/p&gt;

&lt;p&gt;双接入方式为了提高链路利用率，会将两个链路聚合成一个虚拟链路，这个技术是厂商相关
的，因此叫法不太一样：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Cisco 叫 vPC（virtual Port Channel）&lt;/li&gt;
  &lt;li&gt;Cumulus 叫 CLAG&lt;/li&gt;
  &lt;li&gt;Arista 叫 MLAG（Multi-Chassis Link Aggregation Protocol）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这&lt;strong&gt;需要宿主机运行链路聚合控制协议（Link Aggreration Control Protocol, LACP）
以创建 bond 链路&lt;/strong&gt;。如图 1-5 所示。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/1-5.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-5 双接入方式下的链路聚合&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;15-连接到外部网络connectivity-to-the-external-world&quot;&gt;1.5 连接到外部网络（Connectivity to the External World）&lt;/h3&gt;

&lt;p&gt;对于&lt;strong&gt;中型或大型网络&lt;/strong&gt;，&lt;strong&gt;通过 border leaf&lt;/strong&gt; 连接到外网。&lt;/p&gt;

&lt;p&gt;主要好处：将数据中心的网络和外部网络隔开（isolate）。数据中心内的路由协议无需和
外部交互（interact），更加稳定和安全。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/1-6.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-6 通过 border leaf 将一个 Clos 网络连接到外部网络&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小型数据中心&lt;/strong&gt;出于成本考虑，不会部署单独的 border leaf 节点，而是&lt;strong&gt;通过 Spine&lt;/strong&gt; 连接到
外部网络，如图 1-7 所示。需要注意：这种方案中所有 Spine 都需要连接到外部网络，而
不是一部分 Spine。这非常重要，因为 &lt;strong&gt;Clos 网络中所有 Spine 都是对等的&lt;/strong&gt;。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/1-7.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-7 通过 spine 将一个 Clos 网络连接到外部网络&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.6&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;16-多租户或-cloud支持&quot;&gt;1.6 多租户（或 Cloud）支持&lt;/h3&gt;

&lt;p&gt;Clos 拓扑也适用于云计算网络，不管是公有云还是私有云。&lt;/p&gt;

&lt;p&gt;云计算架构的额外需求：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;敏捷性（Agility）：能快速创建/删除虚拟网络&lt;/li&gt;
  &lt;li&gt;隔离性（Isolation）：租户之间互相不可见&lt;/li&gt;
  &lt;li&gt;规模（Scale）：能够支持大量的租户&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.7&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;17-现代数据中心设计的运维考虑&quot;&gt;1.7 现代数据中心设计的运维考虑&lt;/h3&gt;

&lt;p&gt;数据中心的设计会影响到数据中心的运维。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;自动化是最基本的要求&lt;/strong&gt;（Automation is nothing less than a requirement for
basic survial）。在设计的时候要考虑能使自动化运维简单、可重复（simple and
repeatable）。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_1.8&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;18-选择路由协议choice-of-routing-protocol&quot;&gt;1.8 选择路由协议（Choice of Routing Protocol）&lt;/h3&gt;

&lt;p&gt;对企业网（enterprise network），两种协议比较合适：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;OSPF（Open Shortest Path First）&lt;/li&gt;
  &lt;li&gt;IS-IS（Intermediate System to Intermediate System）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;它们都设计用于企业网内部，大部分企业网管理员对此应该很熟悉。&lt;/p&gt;

&lt;p&gt;但是，&lt;strong&gt;OSPF 不支持多协议&lt;/strong&gt;（例如对 IPv4 和 IPv6 需要运行两个独立协议），因此并没有
被大型互联网厂商采用。&lt;/p&gt;

&lt;p&gt;IS-IS 支持 IPv4/IPv6，但是可选的实现比较少。而且，一些管理员认为，IS-IS 这样的链
路状态（link-state）协议不适用于 Clos 这样的富连接（richly connected）网络。&lt;/p&gt;

&lt;p&gt;BGP 的特点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;成熟&lt;/li&gt;
  &lt;li&gt;支撑着互联网（powers the internet）&lt;/li&gt;
  &lt;li&gt;容易理解（fundamentally simple to understand），虽然名声可能不佳（despite its
reputation）&lt;/li&gt;
  &lt;li&gt;实现很多，包括很多开源实现&lt;/li&gt;
  &lt;li&gt;支持多协议（例如 IPv4/IPv6，MPLS）和 VPN（内置）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;只需对 BGP 做一些改造，就可以将它高效地应用中数据中心中。微软的 Azure 团队是最早
对 BGP 进行改造用于数据中心的。现在，我接触的大部分客户都是部署 BGP。&lt;/p&gt;

&lt;p&gt;在下一章中，我们将看到人们&lt;strong&gt;对传统 BGP 进行了哪些改造&lt;/strong&gt;，然后将它应用到数据中心的。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-bgp-是如何适配到数据中心的&quot;&gt;2 BGP 是如何适配到数据中心的&lt;/h2&gt;

&lt;p&gt;在 BGP 用于数据中心之前，它主要用于&lt;strong&gt;服务提供商网络&lt;/strong&gt;（service provider network）。
这导致的一个问题就是，数据中心不能运行 BGP，不然会和底层供应商的网络有冲突。如
果你是网络管理和运维人员，那意识到这一点非常重要。&lt;/p&gt;

&lt;p&gt;不同网络场景：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据中心：高密度连接（dense connectivity）&lt;/li&gt;
  &lt;li&gt;服务提供商（连接不同域）：相对低密度连接（relatively sparse connectivity）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，服务提供商的网络首先是考虑可靠性（stability），其次才是（路由等）变化的快
速通知（rapid notification of changes）。因此，BGP 发送通知的实时性比较低。而在
数据中心中，管理员更希望&lt;strong&gt;路由更新（routing updates）越快越好&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;另外，由于 BGP 自身的设计、行为，以及它作为路径矢量协议（path-verctor protocol）
的特性，单个链路挂掉会导致节点之间发送大量 BGP 消息。&lt;/p&gt;

&lt;p&gt;第三个例子，BGP 从多个 ASN 收到一条 prefix（路由网段前缀）之后，最
终只会生成一条最优路径。而在数据中心中，我们希望生成多条路径。&lt;/p&gt;

&lt;p&gt;为适配数据中心而对 BGP 进行的改造，见 &lt;a href=&quot;&quot;&gt;FRC 7938&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;本章描述这些改动，以及背后的考虑（rationale for the change）。&lt;strong&gt;这里再次强调，数
据中心使用的 BGP 和传统的 BGP 并不一样，如果不理解这一点，管理员很容易误操作造成
网络故障&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;21-有几路由协议&quot;&gt;2.1 有几路由协议&lt;/h3&gt;

&lt;p&gt;传统 BGP 从 OSPF、IS-IS、EIGRP（Enhanced Interior Gateway Routing Protocol） 等
协议接收路由通告，这些称为&lt;strong&gt;内部路由协议&lt;/strong&gt;（internal routing protocols），用于控制
企业内的路由。无怪乎很多人当时认为，要在数据中心中落地 BGP，还需要另一个协议。
但实际上，&lt;strong&gt;在数据中心中 BGP 就是（特定的）内部路由协议，不需要再运行另一个协议
了&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;22-ibgp-和-ebgp&quot;&gt;2.2 iBGP 和 eBGP&lt;/h3&gt;

&lt;p&gt;数据中心内部是该使用内部网关协议（iBGP）还是外部网关协议（eBGP）？&lt;strong&gt;很多人觉得应
该是 iBGP，因为在数据中心内部，但其实不是&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;数据中心中 eBPG 是使用最广泛的&lt;/strong&gt;。原因；&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;主要原因是 eBGP 比 iBGP 更易理解和部署&lt;/p&gt;

    &lt;p&gt;iBGP 的最优路径选择算法很复杂，而且存在一些限制，使用、配置、管理复杂。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;eBGP 的实现比 iBGP 多，选择面比较大&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;23-asn-编号&quot;&gt;2.3 ASN 编号&lt;/h3&gt;

&lt;p&gt;每个 BGP 节点都有一个 ASN（Autonomous System Number）。ASN 用于&lt;strong&gt;识别路由环境、
判断最优路径、关联路由策略&lt;/strong&gt;等等。&lt;/p&gt;

&lt;p&gt;ASN 有两个版本：老版用 2 个字节表示，新版用 4 个字节表示。&lt;/p&gt;

&lt;p&gt;数据中心 BGP 中 ASN 的分配方式和公网 BGP ASN 的分配方式不同。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;公网的 BGP 使用 well-known ASN，但数据中心中使用的一般都是私有 ASN，因为一般不需
要和公网做 peer&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&quot;私有-asn&quot;&gt;私有 ASN&lt;/h4&gt;

&lt;p&gt;私有 ASN 和 私有网段类似。&lt;/p&gt;

&lt;p&gt;但注意：&lt;strong&gt;如果管理员真要用公网 ASN，那也是没人能阻止的&lt;/strong&gt;。有两个原因不建议这样做：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;造成管理的混乱，包括人和工具&lt;/li&gt;
  &lt;li&gt;会将内网信息泄露到公网，造成极大的安全问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;私有 ASN 数量&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;老版本（2 字节）：大概 1023 个（64512~65534)&lt;/li&gt;
  &lt;li&gt;新版本（4 字节）：大概 95 million（4200000000~4294967294）&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;path-hunting-问题&quot;&gt;Path Hunting 问题&lt;/h4&gt;

&lt;p&gt;有多种分配 ASN 的方式。&lt;/p&gt;

&lt;p&gt;如果采用每个节点一个 ASN 的方案，那会存在一个 count-to-infinity 问题。简单说就是
：每个节点不知道其他节点的物理链路状态（physical link state），因此无法判断一条
路由是真的不通了（节点挂掉）还是通过其他路径还是可达的。&lt;/p&gt;

&lt;p&gt;当一个节点挂到后，其他节点陆续撤回（withdraw）可达路由时，导致网络内大量的 BGP消
息。这个问题称为 path hunting。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/2-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 2-1 一个简单拓扑，解释 path hunting&lt;/p&gt;

&lt;h4 id=&quot;asn-numbering-model&quot;&gt;ASN Numbering Model&lt;/h4&gt;

&lt;p&gt;为了避免 path hunting 问题，&lt;strong&gt;Clos 网络内的 ASN 编号模型&lt;/strong&gt;如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;每个 ToR 都有自己的 ASN&lt;/li&gt;
  &lt;li&gt;pod 边缘的 leaf 有自己的 ASN，但同一个 pod 内的 leaf，共用同一个 ASN&lt;/li&gt;
  &lt;li&gt;pod 之间的 spine，共享一个 ASN&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;图 2-2 是一个三级 Clos 的例子：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/2-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 2-2 Clos 拓扑 ASN 编号模型示例&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这种编号模型是如何解决 path hunting 问题的&lt;/strong&gt;：以图 2-1 为例，如果 R2 和 R3 有
相同的 ASN，那 R1 收到 R2 的一条到 10.1.1.1 的消息后，再收到 R3 来的到 10.1.1.1
消息时（检测到有环路），就会拒绝后者。当 R4 挂掉时，消息回撤会很简单。&lt;/p&gt;

&lt;p&gt;这种编号模型的缺点：&lt;strong&gt;无法做路由聚合或摘要&lt;/strong&gt;（route aggregation or summarization
）。还是拿图 2-1 为例，如果 R2 和 R3 通过直连的服务器总共收集到了 &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.1.2/32 ~
10.1.1.250/32&lt;/code&gt; 的可达消息。如果 R2 和 R3 做路由聚合，那只需要向 R1 通告一条
&lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.1.0/24&lt;/code&gt; 可达消息，而不用通告 250 次，每次一个 IP。在这种情况下，如果 R2-R4
链路挂了，那 R1 仍然认为&lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.1.0/24&lt;/code&gt; 到 R4 仍然是可达的，因为可以通过&lt;code class=&quot;highlighter-rouge&quot;&gt;R1-R3-R4&lt;/code&gt;
，但实际上有些 IP 是只能通过 R2-R4 才通的。也即路由聚合在这种情况下带来了问题。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;24-最优路径算法&quot;&gt;2.4 最优路径算法&lt;/h3&gt;

&lt;p&gt;给定一个节点的 prefix，BGP 通过算法判断到这个 node 的最佳路径。&lt;/p&gt;

&lt;p&gt;UPDATE 消息会触发最优路径计算过程。可以对 UPDATE 消息做缓存，批量处理，具体取决
于不同 BGP 的实现。&lt;/p&gt;

&lt;p&gt;最优路径算法中有 8 个参数，但和数据中心相关的只有一个：&lt;code class=&quot;highlighter-rouge&quot;&gt;AS_PATH&lt;/code&gt;。
可以用下面这句话记这八个参数：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Wise Lip Lovers Apply Oral Mediacation Every Night.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;每个字段的意思见图 2-3。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/2-3.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 2-3 BGP 最优路径选择标准&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;25-多路径选择&quot;&gt;2.5 多路径选择&lt;/h3&gt;

&lt;p&gt;对于 Clos 这种密集连接型网络，&lt;strong&gt;路由多路径&lt;/strong&gt;（route multi-pahting）是构建健壮、
可扩展网络的基本要求。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BGP 支持多路径，包括对等（equal cost）和非对等（unequal cost）多路径&lt;/strong&gt;。但支持
程度取决于具体实现。&lt;/p&gt;

&lt;p&gt;两条路由相同的判断标准：以上八个条件都相同。其中，AS_PATH 字段一定要 ASN
相同才算相同，只是跳数相同不行。这将多路径分为了两种部署方式。&lt;/p&gt;

&lt;p&gt;第一种方式，服务器是双接入的（直连两个 ToR），如图 2-4 所示。在这种情况下，Spine
会收到两条到服务器的路径，分别经过两个 ToR。由于两条 path 的 ASN 不一样，Spine
认为这两个 path 不同（unequal），因此最终会二选一。&lt;/p&gt;

&lt;p&gt;第二种方式，服务器内起 VM 或容器，并且在不同服务器内有多个实例，所有实例有相同的
虚 IP （virutal IP）。由于不同服务器连接到了不同 ToR，因此 Spine 会收到多条到虚
IP 的路径，所有路径的跳数相同，但每个路径上的 ASN 不同，因此 Spine 也将它们当作
unequal path 处理。&lt;/p&gt;

&lt;p&gt;要解决以上问题有多种方式，最简单的方式：配置最优路径算法，认为跳数相同 AS_PATH
就算相同，不管 ASN 是否相同。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/2-4.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 2-4 一个简单拓扑，解释 path hunting&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.6&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;26-默认定时器导致的慢收敛&quot;&gt;2.6 默认定时器导致的慢收敛&lt;/h3&gt;

&lt;p&gt;简单来说，BGP 中的几个定时器控制 peer 之间通信的速度。对于 BGP，这些参数的默认值
都是针对&lt;strong&gt;服务提供商环境&lt;/strong&gt;优化的，其中&lt;strong&gt;稳定性的优先级高于快速收敛&lt;/strong&gt;。而数据中心
则相反，快速收敛的优先级更高。&lt;/p&gt;

&lt;p&gt;当一个节点挂掉，或挂掉之后恢复时，有四个定时器影响 BGP 的收敛速度。对这些参数进
行调优，可以使得 BGP 达到内部路由协议（例如 OSFP）的性能。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Advertisement Interval&lt;/li&gt;
  &lt;li&gt;Keepalive and Hold Timers&lt;/li&gt;
  &lt;li&gt;Connect Timer&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;advertisement-interval&quot;&gt;Advertisement Interval&lt;/h4&gt;

&lt;p&gt;发布路由通告的间隔。在这个间隔内的事件会被缓存，然后时间到了一起发送。&lt;/p&gt;

&lt;p&gt;默认：&lt;strong&gt;eBGP 是 30s，iBGP 是 0s&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于密集连接型的数据中心来说，30s 显然太长了，&lt;strong&gt;0s 比较合适&lt;/strong&gt;。这会使得 eBGP 的收敛
速度达到 OSFP 这种 IGP 的水平。&lt;/p&gt;

&lt;h4 id=&quot;keepalive-and-hold-timers&quot;&gt;Keepalive and Hold Timers&lt;/h4&gt;

&lt;p&gt;每个节点会向它的 peer 发送心跳消息。如果一段时间内（称为 hold time）没收到 peer
的心跳，就会清除所有从这个 peer 收到的消息。&lt;/p&gt;

&lt;p&gt;默认：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Keepalive: 60s&lt;/li&gt;
  &lt;li&gt;Hold timer: 180s&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这表示每分钟发一个心跳，如果三分钟之内一个心跳都没收到，就认为 peer 挂了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;数据中心中的三分钟太长了，足以让人过完一生&lt;/strong&gt;（Inside the data center, three
minutes is a lifetime）。典型配置：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Keepalive: 3s&lt;/li&gt;
  &lt;li&gt;Hold timer: 9s&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;connect-timer&quot;&gt;Connect Timer&lt;/h4&gt;

&lt;p&gt;节点和 peer 建立连接失败后，再次尝试建立连接之前需要等待的时长。&lt;/p&gt;

&lt;p&gt;默认：60s。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.7&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;27-数据中心默认-bgp-配置&quot;&gt;2.7 数据中心默认 BGP 配置&lt;/h3&gt;

&lt;p&gt;很多 BGP 实现的默认配置都是针对服务提供商网络调优的，而不是针对数据中心。&lt;/p&gt;

&lt;p&gt;建议：&lt;strong&gt;显示配置用到的参数&lt;/strong&gt;（即使某些配置和默认值相同），这样配置一目了然，运维和排障都比较方便。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;下面是 FRRouting BGP 的默认配置，我认为是数据中心 BGP 的最优实践。在我参与过的
几乎所有生产环境数据中心都使用的这个配置&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Multipath enabled for  &lt;code class=&quot;highlighter-rouge&quot;&gt;eBGP&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;iBGP&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Advertisement interval: &lt;code class=&quot;highlighter-rouge&quot;&gt;0s&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Keepalive and Hold Timers: &lt;code class=&quot;highlighter-rouge&quot;&gt;3s&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;9s&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Logging adjacency changes enabled&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;chap_2.8&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;28-总结&quot;&gt;2.8 总结&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;数据中心网络默认部署模型：eBGP&lt;/li&gt;
  &lt;li&gt;ASN 编号模型&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接下来的两章将会把本章学到的知识用到真实 Clos 环境。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-自动化-bgp-配置&quot;&gt;3 自动化 BGP 配置&lt;/h2&gt;

&lt;p&gt;运维口头禅：&lt;strong&gt;要么自动化，要么去死&lt;/strong&gt;（automate or die）。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_3.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;31-自动化配置基础&quot;&gt;3.1 自动化配置基础&lt;/h3&gt;

&lt;p&gt;只要存在模式（pattern），就有可能实现自动化（Automation is possible when there
are patterns）。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_3.2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;32-示例数据中心网络&quot;&gt;3.2 示例数据中心网络&lt;/h3&gt;

&lt;p&gt;本书剩余部分将使用图 3-1 所示的拓扑，它代表了当前大部分数据中心网络的拓扑。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/3-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 3-1 示例数据中心网络&lt;/p&gt;

&lt;p&gt;接下来涉及以下节点的配置：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;leaf 节点：leaf01 ~ leaf04&lt;/li&gt;
  &lt;li&gt;spine 节点：spine01 ~ spine04&lt;/li&gt;
  &lt;li&gt;border leaf 节点：exit01 ~ exit02&lt;/li&gt;
  &lt;li&gt;服务器：server01 ~ server04&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了服务器之外，其他所有节点都是路由器，路由协议是 BGP。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A quick reminder: 我们使用的是 Clos 拓扑，因此 Spine 和 Leaf 节点都是路由器。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a name=&quot;chap_3.3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;33-自动化传统-bgp-的困难&quot;&gt;3.3 自动化传统 BGP 的困难&lt;/h3&gt;

&lt;p&gt;配置 3-1 网络：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;router bgp 65000&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;配置 ASN，并开始了一个 BGP 配置 block（对 FRR）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bgp router-id 10.0.254.1&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;每个节点要有一个唯一的 router-id。一种比较好的方式是，选择这个节点的 loopback
IP 作为 router-id。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;neighbor peer-group ISL&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在 FRR中，定义配置模板。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;neighbor ISL remote-as 65500&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;配置对端 ASN。传统 BGP 配置需要这一项。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;neighbor 169.254.1.0 peer-group ISL&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;使用配置模板 ISL 中的参数，和指定 IP 建立连接。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;address-family ipv4 unicast&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;BGP 支持多协议，因此需要显式指定希望的路由协议，此处为 ipv4 unicast。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;neighbor ISL activate&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;启用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;network 10.0.254.1/32&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;对外通告本节点到 10.0.254.1/32 的路由是可达的。这首先需要确保这条路由在节点的
路由表中是存在的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;maximum-paths 64&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;允许使用多路径。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;leaf-节点核心配置&quot;&gt;Leaf 节点核心配置&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// leaf01’s BGP configuration
log file /var/log/frr/frr.log

router bgp 65000
  bgp router-id 10.0.254.1
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL remote-as 65500
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor 169.254.1.0 peer-group ISL
  neighbor 169.254.1.64 peer-group ISL
  address-family ipv4 unicast
    neighbor ISL activate
    network 10.0.254.1/32
    network 10.1.1.0/26
    maximum-paths 64
exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// leaf02’s BGP configuration
log file /var/log/frr/frr.log

router bgp 65001
  bgp router-id 10.0.254.2
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL remote-as 65500
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor 169.254.1.0 peer-group ISL
  neighbor 169.254.1.64 peer-group ISL
  address-family ipv4 unicast
    neighbor ISL activate
    network 10.0.254.1/32
    network 10.1.1.0/26
    maximum-paths 64
exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;spine-节点核心配置&quot;&gt;Spine 节点核心配置&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// spine01’s BGP configuration
log file /var/log/frr/frr.log

router bgp 65534
  bgp router-id 10.0.254.254
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor 169.254.1.1 remote-as 65000
  neighbor 169.254.1.1 peer-group ISL
  neighbor 169.254.1.3 remote-as 65001
  neighbor 169.254.1.3 peer-group ISL
  neighbor 169.254.1.5 remote-as 65002
  neighbor 169.254.1.5 peer-group ISL
  neighbor 169.254.1.7 remote-as 65003
  neighbor 169.254.1.7 peer-group ISL
  bgp bestpath as-path multipath-relax
  address-family ipv4 unicast
    neighbor ISL activate
    network 10.0.254.254/32
    maximum-paths 64
exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// spine02’s BGP configuration
log file /var/log/frr/frr.log

router bgp 65534
  bgp router-id 10.0.254.253
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor 169.254.1.1 remote-as 65000
  neighbor 169.254.1.1 peer-group ISL
  neighbor 169.254.1.3 remote-as 65001
  neighbor 169.254.1.3 peer-group ISL
  neighbor 169.254.1.5 remote-as 65002
  neighbor 169.254.1.5 peer-group ISL
  neighbor 169.254.1.7 remote-as 65003
  neighbor 169.254.1.7 peer-group ISL
  bgp bestpath as-path multipath-relax
  address-family ipv4 unicast
    neighbor ISL activate
    network 10.0.254.254/32
    maximum-paths 64
exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;总结自动化会遇到的问题：配置中使用 IP 地址的话，会有很多地方重复；新加或修改 IP
地址时很多地方都要改。&lt;/p&gt;

&lt;p&gt;如何解决这个问题？看下面几个工具。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_3.4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;34-路由再分发redistributes-routes&quot;&gt;3.4 路由再分发（Redistributes Routes）&lt;/h3&gt;

&lt;p&gt;将一种协议收到的路由以另一种协议再发送出去，称为&lt;strong&gt;路由再分发&lt;/strong&gt;（redistributing routes）
。格式：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;resitribute &amp;lt;protocol&amp;gt; route-map &amp;lt;route-map-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;protocol&amp;gt;&lt;/code&gt; 支持：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;static&lt;/code&gt;：通告（announce）静态配置的路由&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;connected&lt;/code&gt;：通告和接口地址（interface address）相关联的路由&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel&lt;/code&gt;：只适用于 Linux。通过路由套件（FRRouting、bird、quagga等）配置的路由
，或通过 iproute2 等工具直接配置在内核的路由&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ospf&lt;/code&gt;：通过 OSPF 学习到的路由&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bgp&lt;/code&gt;：通过 BGP 学习到的路由&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rip&lt;/code&gt;：通过 RIP 学习到的路由&lt;/li&gt;
  &lt;li&gt;others, e.g. IS-IS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，以上 &lt;code class=&quot;highlighter-rouge&quot;&gt;network &amp;lt;IP&amp;gt;&lt;/code&gt; 配置就可以简化成 &lt;code class=&quot;highlighter-rouge&quot;&gt;redistribute connected&lt;/code&gt;，去掉了
hardcode IP。Leaf 节点的配置变成：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;log file /var/log/frr/frr.log
router bgp 65000
  bgp router-id 10.0.254.1
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL remote-as 65500
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor 169.254.1.0 peer-group ISL
  neighbor 169.254.1.64 peer-group ISL
  address-family ipv4 unicast
    neighbor ISL activate
    redistribute connected
    maximum-paths 64
exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;但是，&lt;code class=&quot;highlighter-rouge&quot;&gt;redistribute&lt;/code&gt; 方式也有潜在的问题。&lt;strong&gt;如果接口上的 IP 配错了会导致错误的路
由通告&lt;/strong&gt;，例如如果接口配置了 8.8.8.8/32，也就是默认 DNS 地址，那所有的 DNS 请求
都会打到这个接口。&lt;/p&gt;

&lt;p&gt;解决这个问题需要用到&lt;strong&gt;路由策略（routing policy）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_3.5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;35-路由策略&quot;&gt;3.5 路由策略&lt;/h3&gt;

&lt;p&gt;用最简单的话来说，路由策略就是规定哪些路由通告可以接受，哪些需要拒绝。&lt;/p&gt;

&lt;p&gt;例如，禁止通告上面提到的 &lt;code class=&quot;highlighter-rouge&quot;&gt;8.8.8.8&lt;/code&gt; 问题：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;prefix equals &lt;span class=&quot;s1&quot;&gt;'8.8.8.8/32'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then &lt;/span&gt;reject &lt;span class=&quot;k&quot;&gt;else &lt;/span&gt;accept
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;策略可以写成函数，支持传递参数，例如只接受本地路由：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ACCEPT_DC_LOCAL&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;prefix&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;prefix belongs to 10.1.0.0/16 &lt;span class=&quot;k&quot;&gt;then &lt;/span&gt;accept
    &lt;span class=&quot;k&quot;&gt;else if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;10.0.254.0/24 contains prefix and
            subnet equals 32&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;accept
    &lt;span class=&quot;k&quot;&gt;else &lt;/span&gt;reject
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：建议所有变量使用小写，因为我见过几乎所有网络配置都是这样的，不要使用
camelCase 等其他格式。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;route-maps&quot;&gt;Route-Maps&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt; 是实现路由策略的常见方式。Cisco IOS、NXOS，以及开源的 FRRouting、
Arista 等等都支持 &lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt;。&lt;a href=&quot;&quot;&gt;BIRD&lt;/a&gt;软件走的更远，支持一种简单的领域特定语言
（DSL）。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt;格式：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;route-map NAME &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;permit|deny&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;sequence_number]
  match classifier
  &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;action
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中的 &lt;code class=&quot;highlighter-rouge&quot;&gt;sequence_number&lt;/code&gt; 规定了在 &lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt; 内 clause 的匹配优先级。&lt;/p&gt;

&lt;p&gt;以下的策略：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;route-map EXCEPT_ISL_ETH0 deny 10
  match interface swp51
route-map EXCEPT_ISL_ETH0 deny 20
  match interface swp52
route-map EXCEPT_ISL_ETH0 deny 30
  match interface eth0
route-map EXCEPT_ISL_ETH0 permit 40
  redistribute connected route-map EXCEPT_ISL_ETH0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;和以下为代码是等价的：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;EXCEPT_ISL_ETH0&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;interface&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;interface is not swp51 and
  interface is not swp52 and
  interface is not eth0 &lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;redistribute connected
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;route-maps-对-bgp-处理的影响&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt; 对 BGP 处理的影响&lt;/h5&gt;

&lt;p&gt;BGP 是路径矢量协议，因此它在&lt;strong&gt;运行完最优路径算法之后，才会通告路由更新&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt; 会应用到每个收到和发出的包。&lt;/p&gt;

&lt;p&gt;如果 BGP 有大量的邻居，同时有大量的和邻居相关的 &lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt;，&lt;strong&gt;最优路径计算过程
将非常慢&lt;/strong&gt;，不仅消耗大量 CPU 资源，而且&lt;strong&gt;使得路由通告变慢，即路由收敛变慢&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;解决这个问题的一种方式是使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;peer-group&lt;/code&gt;。将有相同路由策略的邻居放到一个 group
。一般都是由实现完成，不需要手动配置。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_3.6&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;36-使用接口名作为邻居&quot;&gt;3.6 使用接口名作为邻居&lt;/h3&gt;

&lt;p&gt;FRRouting 的一个特性，可以自动推断出接口的 IP 地址，因此策略中可以指定端口而不是
IP。&lt;/p&gt;

&lt;p&gt;Leaf 节点：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// leaf01’s BGP configuration
log file /var/log/frr/frr.log

ip prefix-list DC_LOCAL_SUBNET 5 permit 10.1.0.0/16 le 26
ip prefix-list DC_LOCAL_SUBNET 10 permit 10.0.254.0/24 le 32
route-map ACCEPT_DC_LOCAL permit 10
  match ip-address DC_LOCAL_SUBNET

router bgp 65000
  bgp router-id 10.0.254.1
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL remote-as 65500
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor swp51 peer-group ISL
  neighbor swp52 peer-group ISL
  address-family ipv4 unicast
    neighbor ISL activate
    redistribute connected route-map DC_LOCAL
    maximum-paths 64
  exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// leaf02’s BGP configuration
log file /var/log/frr/frr.log

ip prefix-list DC_LOCAL_SUBNET 5 permit 10.1.0.0/16 le 26
ip prefix-list DC_LOCAL_SUBNET 10 permit 10.0.254.0/24 le 32
route-map ACCEPT_DC_LOCAL permit 10
  match ip-address DC_LOCAL_SUBNET

router bgp 65001
  bgp router-id 10.0.254.2
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL remote-as 65500
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor swp51 peer-group ISL
  neighbor swp52 peer-group ISL
  address-family ipv4 unicast
    neighbor ISL activate
    redistribute connected route-map DC_LOCAL
    maximum-paths 64
  exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Spine 节点：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;log file /var/log/frr/frr.log

ip prefix-list ACCRT 5 permit 10.1.0.0/16 le 26
ip prefix-list ACCRT 10 permit 10.0.254.0/24 le 32
route-map DC_LOCAL permit 10
  match ip-address ACCRT

router bgp 65500
  bgp router-id 10.0.254.254
  bgp log-neighbor-changes
  bgp no default ipv4-unicast
  timers bgp 3 9
  neighbor peer-group ISL
  neighbor ISL advertisement-interval 0
  neighbor ISL timers connect 5
  neighbor swp1 remote-as 65000
  neighbor swp1 peer-group ISL
  neighbor swp2 remote-as 65001
  neighbor swp2 peer-group ISL
  neighbor swp3 remote-as 65002
  neighbor swp3 peer-group ISL
  neighbor swp4 remote-as 65003
  neighbor swp4 peer-group ISL
  bgp bestpath as-path multipath-relax
  address-family ipv4 unicast
    neighbor ISL activate
    redistribute connected route-map DC_LOCAL
    maximum-paths 64
  exit-address-family
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a name=&quot;chap_3.7&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;37-总结&quot;&gt;3.7 总结&lt;/h3&gt;

&lt;p&gt;将配置模板化，避免具体 IP：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;redistribute connected&lt;/code&gt; 替换 &lt;code class=&quot;highlighter-rouge&quot;&gt;network &amp;lt;IP&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;route-maps&lt;/code&gt; 安全策略&lt;/li&gt;
  &lt;li&gt;使用接口名而不是接口上的 IP&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但以上还不够通用，下一章继续。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-其他-bgp-配置&quot;&gt;4 其他 BGP 配置&lt;/h2&gt;

&lt;p&gt;本章将展示如何通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;remote-as&lt;/code&gt; 彻底去掉配置中的接口的 IP 地址，这将使得 BGP 的配
置非常：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;同构（homogeneous）&lt;/li&gt;
  &lt;li&gt;无重复（duplication-free）（即不会出现大段大段类似的配置）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;非常便于自动化。&lt;/p&gt;

&lt;p&gt;要实现这个目标，首先需要理解一个&lt;strong&gt;和路由同样古老的概念：unnumbered interfaces&lt;/strong&gt;
，以及我们如何将它适配到 BGP。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Numbered Interface&lt;/strong&gt;：配置了 IP 地址的接口&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Unnumbered Interface&lt;/strong&gt;：没有配置 IP 地址的接口&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;chap_4.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;41-接口-ip-和-remote-as&quot;&gt;4.1 接口 IP 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;remote-as&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;BGP 基于 TCP/IP 协议，因此需要一个 IP 地址才能建立连接。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在没有为（本地）接口分配IP 地址的情况下，如何确定远端节点的地址呢&lt;/strong&gt;？要回答这
个问题，需要理解一个稍微有点冷门的 RFC 协议，以及 IPv6 提供的无状态配置工具（
stateless configuration tools）。同时，这也涉及到了路由问题的核心（real heart of
routing）。&lt;/p&gt;

&lt;p&gt;第二个问题是，每个 BGP 配置都需要知道对端 ASN。但依赖这个 ASN 只是为了&lt;strong&gt;以此判断
session 是被 iBGP 还是 eBGP 规则管理&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_4.2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;42-numbered-interfaces-数量&quot;&gt;4.2 Numbered Interfaces 数量&lt;/h3&gt;

&lt;p&gt;是否真需要给每个接口配置一个 IP 地址？&lt;/p&gt;

&lt;p&gt;考虑一个简单的两级 Clos：4 个 spine，32 个 leaf，这种规模的网络很常见。对于这个网
络，需要 4 * 32 * 2 = 256 个 IP 地址。如果 leaf 数量变成 96 —— 这种规模也很常见
—— 那总 IP 数量就是 4 * 96 * 2 = 768 个。如果 spine 数量增加到 16 个，那 IP 数量
就变成 3072 个。&lt;/p&gt;

&lt;p&gt;可以看到，这种方式下，&lt;strong&gt;所需的 IP 数量随着 spine 和 leaf 数量及接口数量的增加而
急剧增加&lt;/strong&gt;。而这些 IP 除了 建立 BGP session 之外没有任何其他用途。为什么不想办法
干掉它们呢？&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;关于 Numbered Interfaces 的哲学思考（Philosophical Aside）&lt;/p&gt;

  &lt;p&gt;在传统三层网络中，为每个可寻址的接口（addressable interface endpoint）分配一个
IP 地址是很常见的操作。但这也引出一个问题：这些 IP 地址到底是属于一个接口，还
是这台 node？&lt;/p&gt;

  &lt;p&gt;与此相关的一个更实际的问题是：如果一台 node 收到一个 ARP 请求，请求的 IP 是
node 的另外一个接口上的 IP，而并不是接收到 ARP 包的这个接口的 IP，那 node 需要
回 ARP 应答吗？
路由器的回答是 NO。如果想让路由器支持，必须打开“ARP 代理”（proxy-arp）功能。
Linux 的回答是 YES，它这样设计是为了使通信范围尽量大。&lt;/p&gt;

  &lt;p&gt;ICMP 的设计进一步强化了接口必须有 IP 地址的思想。数据包转发失败的时候，ICMP 只
汇报有问题的 endpoint 的 IP 地址。它并不会报告其他信息，比如 endpoint 的域名（
DNS name）。这（打印 IP 地址）有什么帮助？traceroute 可以据此判断出哪台 node
的哪个接口出了问题。&lt;/p&gt;

  &lt;p&gt;最后，给一根网线两端的接口配置同一网段的两个 IP 地址，是穷人验证网线是否工
作正常的方式。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a name=&quot;chap_4.3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;43-unnumbered-interfaces&quot;&gt;4.3 Unnumbered Interfaces&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Unnumbered Interface&lt;/strong&gt;：没有配置 IP 地址的接口。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意，这种情况下，接口并不是没有 IP 地址，而是从 node 的其他接口借 IP 地址来用&lt;/strong&gt;。
但是，如果被借的那个接口挂了，这个 IP 自然也就不可用了。因此，为了保证借来的 IP 永
远可用，&lt;strong&gt;被借的接口便永远不能挂，这个接口就是：loopback interface&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;路由器能够在 unnumbered interface 上应答 ARP，因为接口可以借 IP。ICMP 和
traceroute 也能正常工作。那么，&lt;strong&gt;这样不就无法区分出一个包是从哪个接口进入
路由器的吗&lt;/strong&gt;？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Clos 网络的任意两个 node 之间只有一条链路&lt;/strong&gt;，也即，&lt;strong&gt;任何两个 node 之间都只有唯一的
一对接口。因此不会出现上面提到的问题&lt;/strong&gt;。如果有多条链路，的确会无法区分从哪个接口
进入路由器，但是多条链路的情况在 Clos 网络中是非常罕见的，原因在第一章分析过。&lt;/p&gt;

&lt;p&gt;那么，路由协议是怎么处理 unnumbered interface 的呢？OSPF（运行在 IP 协议之上）可
以正常工作，其 RFC 里面描述了这方面的设计。大部分厂商的实现可能不支持，但
FRRouting 支持。Unnumbered OSPF 已经在很多生产环境部署。IS-IS，不依赖 IP 协议，
也可以在 unnumbered interface 场景下正常工作。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_4.4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;44-bgp-unnumbered&quot;&gt;4.4 BGP Unnumbered&lt;/h3&gt;

&lt;p&gt;BGP 到底是如何在接口没有 IP 的情况下正常工作的呢？&lt;/p&gt;

&lt;p&gt;在路由协议的世界里有一个“鸡生蛋蛋生鸡”问题。&lt;strong&gt;如果路由协议是用来通告路由可达信息的
，那么它本身是如何知道对端的可达信息的呢？&lt;/strong&gt;一些协议通过引入一个链路特定的组播地
址（link-specific multicast address）来解决（组播会限制在链路层）。BGP 不能这样
做，因为它依赖 TCP，而 TCP 需要的是单播而不是组播包。&lt;strong&gt;BGP 的解决方式是：连接路
由器的接口使用一个共享的子网&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;同子网的接口之间通信只需要二层，不需要三层。子网之内的路由称为 connected route
，因为子网内都是在链路层直接可达的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;回到 BGP peer 如何管理通信的问题，传统 eBGP 就是通过 connected route 发现邻居的
，无需其他配置。&lt;/p&gt;

&lt;p&gt;那么，我们如何在没有用户配置，以及接口没有配置 IP 地址的情况下，发现对端的 IP 地
址的呢？&lt;/p&gt;

&lt;p&gt;这就涉及到了 IPv6，以及一个有点晦涩的标准，&lt;a href=&quot;https://tools.ietf.org/html/rfc5549&quot;&gt;RFC
5549&lt;/a&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IPv6：开启 LLA 和 RA（无需部署 IPv6 网络就可以用）&lt;/li&gt;
  &lt;li&gt;RFC 5549：描述了下一跳为 IPv6 地址的 IPv4 路由&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ipv6-router-advertisement&quot;&gt;IPv6 Router Advertisement&lt;/h4&gt;

&lt;p&gt;IPv6 的架构设计是：无需显式配置，网络就可以尽量正常地工作。因此，IPv6 网络中的每个 link
都会自动分配一个 IP 地址，并且是（在链路层）是唯一的，一般是根据 MAC 地址算出来
的。这个地址叫&lt;strong&gt;链路本地地址&lt;/strong&gt;（Link Local Address，LLA）。LLA 只能被直连的邻居
访问，并且必须是通过这个 LLA 接口（即不支持 ARP 代理之类的）。&lt;/p&gt;

&lt;p&gt;为了使得服务器可以自动发现路由器邻居（neighboring routers），引入了一个新的&lt;strong&gt;链路
层协议&lt;/strong&gt;，称为&lt;strong&gt;路由器通告&lt;/strong&gt;（Router Advertisement，RA）。启用后，RA 会定期通告接
口的 IPv6 地址，包括 LLA。因此各节点就可以自动发现其他节点的 IPv6 地址了。&lt;/p&gt;

&lt;p&gt;现在，服务器和路由器都已经广泛支持 LLA 和 RA。&lt;/p&gt;

&lt;p&gt;另外需要注意的是，&lt;strong&gt;使用 IPv6 LLA 并不需要部署 IPv6 网络；这种方案也并不涉及任何隧
道协议。IPv6 LLA 只是用于 BGP 创建连接。只需要开启 LLA 和 RA 功能即可&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&quot;rfc-5594&quot;&gt;RFC 5594&lt;/h4&gt;

&lt;p&gt;LLA 和 RA 解决了 peer IP 的自动发现和 BGP 连接的建立，但是没有说明节点如何才能到
达 RA 里的路由。
在 BGP 中，这是通过 RA 里面的 NEXTHOP 属性实现的。&lt;strong&gt;如果 IPv4 路由可以使用 IPv6 地
址作为下一跳&lt;/strong&gt;，那 unnumbered interface 的目标就能够实现。&lt;/p&gt;

&lt;p&gt;BGP 支持多协议，单个连接上允许多种协议族的路由通告与撤回。因此，BGP IPv4 UPDATE
消息可以通过 IPv6 TCP 连接发送，反之亦然。这种方式也不需要任何的隧道技术。&lt;/p&gt;

&lt;p&gt;BGP UPDATE 消息说，NEXTHOP 的协议必须与路由通告消息本身所使用的协议相同，即，
IPv4 路由只能通告 IPv4 下一跳，IPv6 路由只能通告 IPv6 下一跳。如果接口上没有
IPv4 地址，那 IPv4 下一跳是哪里呢？这就进入了 RFC 5549。&lt;/p&gt;

&lt;p&gt;RFC 5549 解决的问题是：&lt;strong&gt;通过纯 IPv6 网络通告 IPv4 路由，并路由 IPv4 包&lt;/strong&gt;（
advertisement of an IPv4 route and routing of an IPv4 packet over a pure IPv6
network）。即，它提供了一种&lt;strong&gt;下一跳是 IPv6 地址的 IPv4 路由&lt;/strong&gt;（carray IPv4 routes
with an IPv6 nexthop）。&lt;/p&gt;

&lt;p&gt;原理上来说这其实很好理解，因为二层网络中下一跳 IP 只是用来获
取对端的 MAC 地址（IPv4 ARP，IPV6 ND）。因此只要有同一接口上的任意一个地址（不管
是 IPv4 还是 IPv6），就可以获取到对端MAC，然后就可以将包发送到下一跳。&lt;/p&gt;

&lt;h4 id=&quot;基于-rfc-5549-实现转发&quot;&gt;基于 RFC 5549 实现转发&lt;/h4&gt;

&lt;p&gt;BGP 网络自动初始化过程：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/4-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4-1 BGP unnumbered packet timeline sequence&lt;/p&gt;

&lt;p&gt;在 FRRouting 中，BGP 会将最优路由发送到一个叫&lt;strong&gt;路由信息数据库&lt;/strong&gt;（Routing
Information Base，RIB）的进程（在FRRouting 中这个进程是 zebra）。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;RIB 存储所有协议类型的路由，如果到同一路由有多条路径，RIB 会选择距离最短的一条
。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们假设收到一条路由通告，路由为 &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.1.0/24&lt;/code&gt;。通过消息中的 NEXTHOP 可以拿到对
端的 MAC 地址。接下来RIB 会在路由表里将下一跳设为一个保留的（或看起来非法的）
IPv4 地址 169.254.0.1，然后在 ARP表里将这个 IP 地址对应的 MAC 地址设为对端接口的
MAC 地址。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ROUTE: 10.1.1.0/24 via 169.254.0.1 dev swp1
ARP: 169.254.0.1 dev swp1 lladdr 00:00:01:02:03:04 PERMANENT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;至此，就可以正常转发到这个 IPv4 网段的路由了（虽然路由器两端的接口都没有配置
IPv4 地址）。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果一段时间内没有收到这条路由的通告，就认为这条路由失效了，会删去上面的两行配置
。&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;BGP unnumbered 通过接口的 IPv6 LLA 和 peer 建立 BGP session&lt;/li&gt;
  &lt;li&gt;IPv6 LLA 通过 RA 实现自动邻居发现&lt;/li&gt;
  &lt;li&gt;RA 不仅包括 LLA 信息，还包括 MAC 信息&lt;/li&gt;
  &lt;li&gt;BGP 通过 RFC 5549 实现 IPv4 routes over an IPv6 nexthop（IPv6 LLA）&lt;/li&gt;
  &lt;li&gt;RIB 进程在 ARP 表里添加一条静态表项：MAC 地址为 RA 消息中的 MAC 地址，IP 为 一个保留的 IPv4 地址 169.254.0.1（其实是 IPv4 的 LLA）&lt;/li&gt;
  &lt;li&gt;BGP 将下一跳是 IPv6 LLA 的 IPv4 路由交给 RIB&lt;/li&gt;
  &lt;li&gt;RIB 将 nexthop 改为 169.254.0.1，然后添加到路由表&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;bgp-capability-to-negotiate-rfc-5549-use&quot;&gt;BGP Capability to Negotiate RFC 5549 Use&lt;/h4&gt;

&lt;p&gt;以 IPv6 作为下一跳的 IPv4 路由毕竟还是和通常的不太一样，因此 RFC 5549 定义了一个
新的能力，叫 &lt;strong&gt;extended nexthop&lt;/strong&gt;，然后通过 peering session 进行协商，以判断两边
的 BGP 能力。&lt;/p&gt;

&lt;h5 id=&quot;互操作性&quot;&gt;互操作性&lt;/h5&gt;

&lt;p&gt;每个 eBGP peer 在发送路由通告之前，都会将 NEXTHOP 设为自己的 IP 地址。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/4-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4-2 基于 RFC 5549 的互操作&lt;/p&gt;

&lt;p&gt;图 4-2，假设路由器 B 和 D 支持 RFC 5549，A 和 C 不支持。由于 A 和 C 不支持，因此
B 和 A 之间的接口以及 B 和 C 之间的接口，都需要配置 IPv4 IP 地址。&lt;/p&gt;

&lt;p&gt;当 A 通告到 &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.1.0/24&lt;/code&gt; 可达时，nexthop 地址必须填它自己的 IPv4 地址。当 B 收
到这个消息，进一步通告给 D 和 C 时，分两种情况：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;通告给 D 时：nexthop 设置为 B 的 IPv6 LLA&lt;/li&gt;
  &lt;li&gt;通告给 C 时：nexthop 设置为 B 的 IPv4 地址&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;反向的类似。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_4.5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;45-remote-as-指定-bgp-session-类型&quot;&gt;4.5 &lt;code class=&quot;highlighter-rouge&quot;&gt;remote-as&lt;/code&gt; 指定 BGP session 类型&lt;/h3&gt;

&lt;p&gt;以上配置消除了显示配置 IP 地址。接下来看如何通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;remote-as&lt;/code&gt; 配置 ASN。&lt;/p&gt;

&lt;p&gt;配置 ASN 有两个主要目的：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;安全考虑：多个管理域（administrative domain）互连，如果连错了，会有很大的安全
问题&lt;/li&gt;
  &lt;li&gt;判断 BGP session 到底是 iGBP 还是 eBGP&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在数据中心内不存在跨管理域的问题，因此安全不是 ASN 的主要目的。因此，数据中心中
ASN 的主要目的就是判断 iBGP 还是 eBGP 控制着 session。&lt;/p&gt;

&lt;p&gt;判断方法：&lt;strong&gt;从 BGP OPEN 消息中的 ASN 判断&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_4.6&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;46-总结&quot;&gt;4.6 总结&lt;/h3&gt;

&lt;p&gt;通过避免接口的 IP 地址，以及通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;remote-as&lt;/code&gt; 指定 ASN 的类型（iBGP or eBGP），配
置可以简化成下面这样。可以看到，除了 &lt;code class=&quot;highlighter-rouge&quot;&gt;router bgp &amp;lt;id&amp;gt;&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;bgp router-id &amp;lt;ip&amp;gt;&lt;/code&gt;
这两行需要单独配置之外，其他所有配置都是一样的，不管是对 Spine 还是 Leaf 节点。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// leaf01 configuration

log file /var/log/frr/frr.log

ip prefix-list DC_LOCAL_SUBNET 5 permit 10.1.0.0/16 le 26
ip prefix-list DC_LOCAL_SUBNET 10 permit 10.0.254.0/24 le 32
route-map ACCEPT_DC_LOCAL permit 10
  match ip-address DC_LOCAL_SUBNET

router bgp 65000
  bgp router-id 10.0.254.1
  neighbor peer-group ISL
  neighbor ISL remote-as external
  neighbor swp51 interface peer-group ISL
  neighbor swp52 interface peer-group ISL
  address-family ipv4 unicast
    neighbor ISL activate
    redistribute connected route-map ACCEPT_DC_LOCAL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// spine01 configuration

log file /var/log/frr/frr.log

ip prefix-list DC_LOCAL_SUBNET 5 permit 10.1.0.0/16 le 26
ip prefix-list DC_LOCAL_SUBNET 10 permit 10.0.254.0/24 le 32
route-map ACCEPT_DC_LOCAL permit 10
  match ip-address DC_LOCAL_SUBNET

router bgp 65534
  bgp router-id 10.0.254.254
  neighbor peer-group ISL
  neighbor ISL remote-as external
  neighbor swp1 interface peer-group ISL
  neighbor swp2 interface peer-group ISL
  neighbor swp3 interface peer-group ISL
  neighbor swp4 interface peer-group ISL
  address-family ipv4 unicast
    neighbor ISL activate
    redistribute connected route-map ACCEPT_DC_LOCAL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这种配置，很适合用 ansible 之类的工具在多台节点上推了。&lt;/p&gt;

&lt;p&gt;下一章：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;查看配置&lt;/li&gt;
  &lt;li&gt;管理 BGP&lt;/li&gt;
  &lt;li&gt;配置 BGP 连接到外部网络&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a name=&quot;chap_5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-bgp-生命周期管理&quot;&gt;5 BGP 生命周期管理&lt;/h2&gt;

&lt;p&gt;如何 BGP 配置之后，行为和预期的不一致，怎么排查？本章回答这些问题。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_5.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;51-查看配置&quot;&gt;5.1 查看配置&lt;/h3&gt;

&lt;h4 id=&quot;查看-bgp-session-信息&quot;&gt;查看 BGP session 信息&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;show ip bgp summary&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;show ip bgp ipv4 unicast summary&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;show ip bgp ipv6 unicast summary&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;show ip bgp neighbors &amp;lt;neibhor_name&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/5-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-1 查看 BGP 网络信息&lt;/p&gt;

&lt;h4 id=&quot;查看当前路由&quot;&gt;查看当前路由&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;show ip gbp&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;show bgp ipv4 unicast&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;show ip gbp &amp;lt;prefix&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/5-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-2 查看 BGP 路由信息&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/5-3.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-3 查看 BGP 路由详细信息&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_5.2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;52-连接到外部网络&quot;&gt;5.2 连接到外部网络&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/5-4.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-4 查看 BGP neighbor 详细信息&lt;/p&gt;

&lt;p&gt;如图 5-4，两个 border leaf 节点 &lt;code class=&quot;highlighter-rouge&quot;&gt;exit01&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;exit02&lt;/code&gt; 将数据中心网络连接到互联网
。Border leaf 的两个作用：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;去掉私有 ASN（stripping off the private ASNs）&lt;/li&gt;
  &lt;li&gt;可能会对数据中心内部路由做聚合，然后将聚合后的路由通告给边界路由器&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;去私有 ASN：&lt;code class=&quot;highlighter-rouge&quot;&gt;neigbor &amp;lt;neibhor_name&amp;gt; remove-private-AS all&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;聚合路由：&lt;code class=&quot;highlighter-rouge&quot;&gt;aggregate-address &amp;lt;summary-route&amp;gt; summary-only&lt;/code&gt;，其中
&lt;code class=&quot;highlighter-rouge&quot;&gt;summary-only&lt;/code&gt; 关键字表示，禁止通告单条路由（individual routes），如果没有指定
这个选项，聚合之后的路由和原始路由都会通告出去。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;chap_5.3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;53-计划节点维护&quot;&gt;5.3 计划节点维护&lt;/h3&gt;

&lt;p&gt;例如，如果计划对 spine01 进行升级，那要通知其他 peer 在计算最优路径时，要绕开
spine01。&lt;/p&gt;

&lt;p&gt;第一章介绍过，现代数据中心都会有两个以上 Spine，中型到大型企业网一般都是 4 个
。如果是 4 个 spine，那维护一台时，网络仍然能提供 75% 的容量；如果是两台 spine，
那维护一台时，只能提供 50% 的容量。&lt;/p&gt;

&lt;p&gt;如果服务器是双接入的（直连两个 ToR），那只有 50% 的链路利用率。大型互联网公司解
决这个问题的办法是：&lt;strong&gt;改用单接入（single-attach），庞大的机柜数量使得挂掉单个机柜
带来的影响足够小&lt;/strong&gt;。另外还采用 16 或 32 spine，这样单个 spine 挂掉，只影响 1/16
或 1/32 的交换机间流量。&lt;/p&gt;

&lt;p&gt;最常用的手段：&lt;strong&gt;将 node 的 ASN（重复）加在自己的路由通告里面，这样它的
AS_PATH 跳数就会比其他的路径要多，导致最优路径选择的时候，不会经过这个 node&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;例如，要对 spine02 进行维护：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;route-map SCHED_MAINT permit 10
  &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;as-path prepend 65000 65000

neighbor ISL route-map SCHED_MAINT out
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;路由收敛之后，最优路径就会绕开 spine02：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/5-5.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5-5 最优路由绕开了 spine02&lt;/p&gt;

&lt;p&gt;这种方式是比较通用的；另外也有一些其他方式完成类似功能，但不是所有实现都支持。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_5.4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;54-debug-bgp&quot;&gt;5.4 Debug BGP&lt;/h3&gt;

&lt;p&gt;打开 debug 开关，查看日志等。因实现而异。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_5.5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;55-总结&quot;&gt;5.5 总结&lt;/h3&gt;

&lt;p&gt;&lt;a name=&quot;chap_5&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;6-服务器上运行-bgp&quot;&gt;6 服务器上运行 BGP&lt;/h2&gt;

&lt;p&gt;现代数据中心颠覆了我们以往对计算和网络的所有认知。不管是 NoSQL 数据库、新
应用架构或微服务的出现，还是 Clos 网络用路由代替桥接做底层通信的方式，都为
以前既成的设计思想画上了句号。而这也影响了防火墙和负载均衡器等服务的部署。&lt;/p&gt;

&lt;p&gt;本章将看到&lt;strong&gt;一种新网络模型&lt;/strong&gt;：&lt;strong&gt;路由过程如何（从硬件交换设备）进入到了服务器内部&lt;/strong&gt;，
以及我们如何对服务器做 BGP 配置以使它们和 ToR 或 leaf 通信。&lt;/p&gt;

&lt;p&gt;传统来说，网络管理员的管理边界是 ToR，服务器内部的配置和管理由服务器管理员负责。
而在现代数据中心中，两种管理员已经开始合并为一种管理员，或者至少，网络管理员的管
理边界以及深入到了服务器内部。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_6.1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;61-虚拟服务器的兴起&quot;&gt;6.1 虚拟服务器的兴起&lt;/h3&gt;

&lt;p&gt;传统数据中心中，&lt;strong&gt;桥接和路由的边界&lt;/strong&gt;，以及 &lt;strong&gt;L2-L3 网关&lt;/strong&gt;，都是部署防火
墙和负载均衡器的地方。这些物理边界和传统的客户端/服务器模型边界也是比较匹配的。&lt;/p&gt;

&lt;p&gt;Clos 网络打破了这些自然边界，使得以上部署模型都失效了。&lt;/p&gt;

&lt;p&gt;新的数据中心中，服务都是跑在物理服务器内的虚拟机内，或者是没有虚拟化的物理
服务器。这些虚拟机都能够快速的创建和删除，随着应用流量而扩缩容。&lt;/p&gt;

&lt;h4 id=&quot;anycast-地址&quot;&gt;Anycast 地址&lt;/h4&gt;

&lt;p&gt;虚拟机会出现在数据中心的任意服务器内，因此 IP 不再会固定到单个机柜或路由器，多个
机柜可能会通告同一个 IP。通过路由的 ECMP 转发功能，包会被转发到最近的一个节点。
这种被多个实例同时通告的 IP 称为&lt;strong&gt;任播&lt;/strong&gt;（Anycast） IP 地址。
它们属于单播（unicast）IP 地址，因此他们的目标是单个终点（作为对比，组播和广播的
目标是多个终点），但是，这个终点是路由过程（routing）决定的，从多个提供相关服务
的实例中选择一个。&lt;/p&gt;

&lt;p&gt;ToR 如何发现或通告（discover or advertise）anycast IP？&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_6.2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;62-交换机和服务器做-bgp-peering-的模型&quot;&gt;6.2 交换机和服务器做 BGP Peering 的模型&lt;/h3&gt;

&lt;p&gt;置顶交换机和服务器做 BGP Peering 有两种模型：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;BGP unnumbered model，第 4 章介绍过了&lt;/li&gt;
  &lt;li&gt;依赖 BGP 的一种称为动态邻居（dynamic neighbors）的特性&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接下来比较两种模型的异同。&lt;/p&gt;

&lt;p&gt;两者相同的地方：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ASN 分配&lt;/li&gt;
  &lt;li&gt;路由交换模型&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;asn-分配&quot;&gt;ASN 分配&lt;/h4&gt;

&lt;p&gt;最常见的部署方式：所有服务器共用一个 ASN。&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;配置和自动化简单&lt;/li&gt;
  &lt;li&gt;从服务器识别和过滤路由简单&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果不仅仅是通过到达服务器的默认路由（more than the default route to the host
），那服务器上的配置会变得复杂&lt;/li&gt;
  &lt;li&gt;跟踪哪个服务器通告出的路由比较困难，因为所有的服务器使用相同的 ASN&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第二种方案：&lt;strong&gt;直连相同 ToR 的服务器共用同一个 ASN&lt;/strong&gt;，不同 ToR 下面的服务器使用不同
的 ASN。相当于每个机柜一个 ASN。&lt;/p&gt;

&lt;p&gt;优点：&lt;strong&gt;服务器变成了新的 Clos 层&lt;/strong&gt;（服务器和置顶交换机 full-mesh，确实是 Clos 架构的新的一层）。&lt;/p&gt;

&lt;p&gt;缺点：和上面第一种方案缺点类似，不过现在每个 ASN 的范围缩小到了一个机柜。&lt;/p&gt;

&lt;p&gt;第三种方案：每个服务器一个 ASN。我知道确实有一些人这样做，但是我觉得这样粒度细过
头了（overkill）。&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;完美映射到 Clos 网络模型，每个服务器都变成一个网络节点&lt;/li&gt;
  &lt;li&gt;很容易判断路由是从哪个服务器通告出来的&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ASN 数量和服务器数量一样多，考虑到服务器的数量成千上万，ASN 管理和维护会是一个潜在问题&lt;/li&gt;
  &lt;li&gt;由于 ASN 数量非常多，必须得使用四字节 ASN 版本，可能和其他两字节 BGP 存在兼容性问题&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;路由交换模型&quot;&gt;路由交换模型&lt;/h4&gt;

&lt;p&gt;现在在网络层面，服务器也是一个路由器，和 leaf、spine 并没有区别，因此必须做好安全
控制。&lt;/p&gt;

&lt;p&gt;第一，&lt;strong&gt;对服务器通告的路由，ToR 要能确定接受哪些，拒绝哪些&lt;/strong&gt;。
例如：如果服务器通告了一个错误或非法路由，就会将部分流量引导到错误的地方。&lt;/p&gt;

&lt;p&gt;第二，&lt;strong&gt;确保 ToR 不要将服务器当作（可以转发大量网络流量的）中间节点&lt;/strong&gt;，服务器扛
不住这种硬件网络级别的流量。&lt;/p&gt;

&lt;p&gt;第三，&lt;strong&gt;和服务器直连的路由器只通告默认路由，这样做是为
了避免路由器将太多路由通告到服务器，撑爆服务器的路由表&lt;/strong&gt;，或影响最佳路由决策等等。&lt;/p&gt;

&lt;p&gt;要满足以上条件，就需要用到我们第 3 章介绍的路由策略（routing policies）。例如，
下面是实现以上需求的路由策略：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ip prefix-list ANYCAST_VIP &lt;span class=&quot;nb&quot;&gt;seq &lt;/span&gt;5 permit 10.1.1.1/32
ip prefix-list ANYCAST_VIP &lt;span class=&quot;nb&quot;&gt;seq &lt;/span&gt;10 permit 20.5.10.110/32

ip prefix-list DEFONLY &lt;span class=&quot;nb&quot;&gt;seq &lt;/span&gt;5 permit 0.0.0.0/0

route-map ACCEPT_ONLY_ANYCAST permit 10
  match ip address prefix-list ANYCAST_VIP

route-map ADVERTISE_DEFONLY permit 10
  match ip address prefix-list DEFONLY

neighbor server route-map ACCEPT_ONLY_ANYCAST &lt;span class=&quot;k&quot;&gt;in
&lt;/span&gt;neighbor server route-map ADVERTISE_DEFONLY out
neighbor server default-originate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;neighbor server route-map ACCEPT_ONLY_ANYCAST in&lt;/code&gt; 实现了：从 server 来的路由通告，只接受 &lt;code class=&quot;highlighter-rouge&quot;&gt;ANYCAST_VIP&lt;/code&gt;里面有的 anycast IP&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;neighbor server route-map ADVERTISE_DEFONLY out&lt;/code&gt; 实现了：只对 server 通告默认路由&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;chap_6.3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;63-边界服务器-bgp-peering-方案&quot;&gt;6.3 边界服务器 BGP Peering 方案&lt;/h3&gt;

&lt;p&gt;部署&lt;strong&gt;防火墙和负载均衡器&lt;/strong&gt;的 BGP 模型。有两种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;动态邻居（dynamic neighbors）&lt;/li&gt;
  &lt;li&gt;BGP unnumbered&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;动态邻居&quot;&gt;动态邻居&lt;/h4&gt;

&lt;p&gt;BGP 默认监听所有 IP 过来的 TCP 连接请求。动态邻居是 BGP 的一个特性，可以指定&lt;strong&gt;只监听特
定网段过来的连接请求&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;例如，一个机柜里的服务器一般都是同一网段。假设为 &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.0.0/26&lt;/code&gt;。那对 ToR 做以下
配置，它就只会接受 &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.0.0/26&lt;/code&gt; 网段的过来的、ASN 是 65530 的 peer 的建立连
接请求。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;neighbor servers peer-group
neighbor servers remote-as 65530
bgp listen range 10.1.0.0/26 peer-group servers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;同理，对服务器做如下配置，可以限制它只和 ToR 建立连接：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;neighbor ISL peer-group
neighbor ISL remote-as external
neighbor 10.1.0.1 peer-group ISL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;但是，动态邻居特性目前不支持针对接口做配置，例如不支持 &lt;code class=&quot;highlighter-rouge&quot;&gt;bgp listen interface
vlan10 peer-group servers&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;可以限制动态邻居的数量：&lt;code class=&quot;highlighter-rouge&quot;&gt;neighbor listen limit &amp;lt;limit number&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;主要优点：和单接入服务器模型非常匹配，并且服务器要是通过 PXE（Preboot Execution
Environment）启动的。如图 6-1。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/6-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-1 BGP 动态邻居模型&lt;/p&gt;

&lt;h4 id=&quot;bgp-unnumbered&quot;&gt;BGP Unnumbered&lt;/h4&gt;

&lt;p&gt;路由器和服务器之间也支持 BGP unnumbered，和第四章介绍的路由器之间的 unnumbered
类似。这种方式的拓扑如图 6-2：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/bgp-in-data-center/6-2.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6-2 BGP unnumbered 模型&lt;/p&gt;

&lt;p&gt;动态邻居模型基于共享子网，而 unnumbered 模型不需要共享子网。和路由器类似，服务器
的 IP 地址和接口是没有关系的，一般配置为 loopback 地址。每个服务器可以分配一个
/32 地址。因为通告 IPv6 LLA 和路由器做 peer，因此无需共享的子网。&lt;/p&gt;

&lt;p&gt;ToR 配置：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;neighbor peer-group servers
neighbor servers remote-as external
neighbor swp1 peer-group servers
neighbor swp2 peer-group servers
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;服务器配置：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;neighbor eth0 remote-as external
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;纯路由网络（服务器和置顶交换机也是路由），完全去掉了桥接&lt;/li&gt;
  &lt;li&gt;单接入服务器、双接入服务器都支持，却不需要运行任何厂商相关的 multinode LACP&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;不支持 DHCPv4 或 PXE，因为 PXE-boot 过程中没有路由协议栈，而交换机不知道如何
转发包到特定的服务器&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;有办法解决这个问题，但这超出了本身讨论的范围。&lt;/p&gt;

&lt;h4 id=&quot;服务器上可用的路由软件&quot;&gt;服务器上可用的路由软件&lt;/h4&gt;

&lt;p&gt;如果你是网络设计的老兵，你会意识到服务器上跑的 BGP 其实只是一个 GBP speaker，不
需要最优路径计算、将路由添加到路由表等全套 BGP 功能。大型互联网公司意识到了这一
点，因此他们会运行一些能作为 BGP speaker 的软件，例如 &lt;a href=&quot;&quot;&gt;ExaBGP&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;更注重全功能的软件有 &lt;a href=&quot;https://bird.network.cz/&quot;&gt;FRRouting&lt;/a&gt;  和
&lt;a href=&quot;https://bird.network.cz/&quot;&gt;BIRD&lt;/a&gt;。FRRouting 对 BGP unnumbered 和动态邻居两种模型
都支持。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;chap_6.4&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;64-总结&quot;&gt;6.4 总结&lt;/h3&gt;

&lt;p&gt;本章展示了如何将 BGP 扩展到服务器内部。&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;关于本文&quot;&gt;关于本文&lt;/h3&gt;

</description>
        
        <pubDate>Mon, 01 Apr 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/bgp-in-data-center-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/bgp-in-data-center-zh/</guid>
        
        
        <category>bgp</category>
        
        <category>datacenter</category>
        
      </item>
      
    
      
      <item>
        <title>[译] 你是一名软件架构师吗？</title>
        <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

&lt;p&gt;本文翻译自 2019 年的一篇英文博客 &lt;a href=&quot;https://www.infoq.com/articles/brown-are-you-a-software-architect&quot;&gt;Are You A Software Architect?&lt;/a&gt;
。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下是译文。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;软件开发（software development）和软件架构（software
architecture）之间有一条微妙的线。有人会说，这条线根本不存在，架构只是开发者设计
过程的简单延伸（an extension of the design process）。另外一部分人则说，这是一条
巨大的鸿沟（a massive gaping chasm），只有少数出类拔萃的开发者才能跨越，这些开发
者都认为你必须不断地向上抽象（always abstract your abstractions），而避免陷入令
人生厌的实现细节的泥沼。如果以务实的（pragmatic）眼光看，那这两者之间必定存在某
个平衡点，但这接着也提出了问题：&lt;strong&gt;你如何从开发者变成架构师？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将软件架构从软件设计和开发中区分开来的关键因素包括：规模的上升、抽象层次的上升，
以及做出正确的设计决策带来的影响的上升等等。软件架构就在于能有一个全局视角（
holistic view）、能看到更大的图，以理解软件系统作为一个整体是如何工作的。
这些因素对区分软件开发和软件架构也许有帮助，但还是无法解释一些人如何从开发转到了
架构。进一步地，它无助于识别哪些人将会成为出色的架构师、如果你是 HR 你如何寻找这
些人，以及&lt;strong&gt;你是否是一个架构师&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;经验experience&quot;&gt;经验（Experience）&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;经验是一个很好的衡量指标，但你应该看地更深&lt;/strong&gt;（&lt;strong&gt;Experience is a good gauge but
you need to look deeper&lt;/strong&gt;）。&lt;/p&gt;

&lt;p&gt;没有人是在一夜之间或一次升职就成为软件架构师的。&lt;strong&gt;架构师是一个角色（role），而非
级别（rank）&lt;/strong&gt;。它是一个演进的过程，在这个过程中你会不断增长承担这个角色所需的经
验与自信。&lt;/p&gt;

&lt;p&gt;架构师身上有许多不同的品质，而他们过去的经验通常是他们承担这个角色所需能力的一种
很好的度量（gauge）。架构师的角色包括很多方面，因此你需要在更深层次地去看，理解他们
在不同方面展现出来的参与度、影响力、领导力和责任。&lt;/p&gt;

&lt;p&gt;宽泛地说，大部分项目的软件架构过程可以分成两个阶段：&lt;strong&gt;定义阶段&lt;/strong&gt;和&lt;strong&gt;交付阶段&lt;/strong&gt;（
the architecture is defined and then it’s delivered）。&lt;/p&gt;

&lt;h2 id=&quot;软件架构的定义definition&quot;&gt;软件架构的定义（definition）&lt;/h2&gt;

&lt;p&gt;架构的定义过程似乎相当直接：&lt;strong&gt;确定需求，然后设计一个满足这些需求的系统&lt;/strong&gt;。但实际
中并没有这样简单，随着你的参与程度（how engaged you are）和你对待自己角色的认真程
度（how seriously you view your role）的不同，软件架构的角色也有很大变化。如下图
所示，角色的架构定义部分可以进一步分解为几个子部分。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/role-definition.png&quot; width=&quot;40%&quot; height=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-非功能non-functional需求的管理&quot;&gt;1 非功能（non-functional）需求的管理&lt;/h3&gt;

&lt;p&gt;软件项目经常将注意力放在用户的&lt;strong&gt;功能需求&lt;/strong&gt;（features）上，而很少问用户有什么
&lt;strong&gt;非功能需求&lt;/strong&gt;（或系统性能）。有时需求方会告诉我们说“系统必须足够快”，但这种
表述太主观了。要满足非功能需求，那这些需要必须是&lt;strong&gt;具体的、可测量的、可实现
的以及可测试的&lt;/strong&gt;（specific，measurable，achievable and testable）。&lt;/p&gt;

&lt;p&gt;大部分非功能需求本质上是技术性的，而且通常对软件架构有很大影响。&lt;strong&gt;理解非功能需求
是架构师角色的核心能力之一&lt;/strong&gt;，但是，&lt;strong&gt;试图理解这些需求&lt;/strong&gt;和&lt;strong&gt;质疑这些需求&lt;/strong&gt;（是否
合理）还是有区别的。毕竟，你见过多少真正需要 7x24 小时运行的系统？&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-definition-1.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-架构定义architecture-definition&quot;&gt;2 架构定义（architecture definition）&lt;/h3&gt;

&lt;p&gt;弄清了非功能需求后，下一步就要思考如何定义架构，解决需求方提出的问题。
&lt;strong&gt;我们可以说每个软件系统都有架构，但是，不是每个软件系统都有定义出来的架构&lt;/strong&gt;（
defined architecture）。这才是关键点。&lt;/p&gt;

&lt;p&gt;软件定义过程需要思考如何在给定的限制下满足提出的需求，进而解决问题。架构定义过
程是在项目的技术方面引入结构、规范、原则和领导力的过程。定义架构是你作为软件架
构师的工作，但是，从头设计一个软件系统和扩展一个已有系统还是有很大差别的。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-definition-2.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-技术选择technology-selection&quot;&gt;3 技术选择（technology selection）&lt;/h3&gt;

&lt;p&gt;技术选择通常是一个愉快的过程，但是，当考虑到成本、授权、供应商关系、技术策略
、兼容性、互操作性、支持、部署、升级策略、终端用户环境等等问题时，挑战也是很大的。
这些因素综合起来，经常把一个简单的选择某些东西（例如一个功能丰富的客户端）的任
务变成一个十足的噩梦。&lt;/p&gt;

&lt;p&gt;接下来还有另一个问题：这些技术能否工作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;技术选择是管理风险的过程&lt;/strong&gt;（technology selection is all about managing
risk）；在高复杂度或不确定性的地方减少风险，在可能带来收益的地方允许引进风险。技
术决策需要考虑所有的因素，并需要评审和评估。这包括软件项目的主要组成模块，以及开
发过程会用到的库和框架。如果你在定义架构，那你需要确信自己的技术选择是正确的。同
样地，为一个新系统评估技术和向现有系统添加技术是有很大区别的。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-definition-3.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-架构评估architecture-evaluation&quot;&gt;4 架构评估（architecture evaluation）&lt;/h3&gt;

&lt;p&gt;如果是你设计软件，你需要问自己：我的架构能否工作？&lt;/p&gt;

&lt;p&gt;对于我来说，如下的架构就算是工作的：满足非功能需求；为其他部分的代码提供了必要的
基础（provides the necessary foundation for the rest of the code）；为解决底层的
业务问题提供了一个平台。&lt;/p&gt;

&lt;p&gt;软件最大的问题之一就是它的复杂和抽象，这使得很难从UML 图或代码去联想出（visualize）
软件的运行时特点。在软件开发的过程中，我们会采用多种测试技术，以确保交付的系统在
上线之后能正常工作。为什么不对架构设计采用同样的方式呢？如果你可以测试你的架构，
那你就可以证明它能工作。这项工作做的越早，就越可以减少项目失败的风险，而不用简单
的寄希望于它能正常工作。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-definition-4.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5-架构合作architecture-collaboration&quot;&gt;5 架构合作（architecture collaboration）&lt;/h3&gt;

&lt;p&gt;与世隔绝的软件系统很少见，大部分软件系统都是需要人去理解它的。开发人员需要理解它
，并按照架构实现它；需求方出于安全、数据库、运维、支持等角度，也可能对它的实现感
兴趣。要使软件成功，你需要与这些需求方紧密合作，保证架构能够和环境成功集成。不幸
的是，架构合作在开发组内都很少发生，更遑论外部的需求方了。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-definition-5.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;软件架构的交付delivery&quot;&gt;软件架构的交付（delivery）&lt;/h2&gt;

&lt;p&gt;架构交付的部分也是类似，软件架构的角色会随着参与度（level of engagement）的不同
而不同。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/role-delivery.png&quot; width=&quot;40%&quot; height=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-把控更大的图ownership-of-the-bigger-picture&quot;&gt;1 把控更大的图（ownership of the bigger picture）&lt;/h3&gt;

&lt;p&gt;要确保架构成功落地，必须得有人在软件开发的整个生命周期内把握整张大图、向大家描绘
前景（sells the vision）。如有必要，要跟随项目一起演进，承担将它成功交付的责任
。如果你定义了一个架构，那始终保持对架构的参与和演进是很有意义的，而不是将它交给
“实现团队”（implementation team）。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-delivery-1.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-领导力leadership&quot;&gt;2 领导力（leadership）&lt;/h3&gt;

&lt;p&gt;把控大图是技术领导力的一部分，但软件项目的交付期间，还有其它一些事情要做。包括：
向大家介绍责任（的重要性）、提供技术规范、做技术决策，以及具备做这种决策的权威。&lt;/p&gt;

&lt;p&gt;作为架构师，你需要承担技术领导力，以保证所有的事情都考虑到了，而且团队走在正确的
道路上。软件架构师的位置天然就是关于领导力的，这虽然听起来显而易见，但很多团队中
架构师可能认为成功的交付并不是一个他们需要考虑的问题，因而并不具备所需的技术领导
力。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-delivery-2.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-培训团队和指导下属coaching-and-mentoring&quot;&gt;3 培训团队和指导下属（coaching and mentoring）&lt;/h3&gt;

&lt;p&gt;培训团队和指导下属是大部分软件开发项目中容易被忽视的一项活动，导致的后果就是，一
些团队成员并没有得到他们应该得到的帮助。虽然技术领导力是关于对项目整体进行掌舵（
steering），但也有一些时候个人需要帮助。而且，培训团队和指导下属提供了一种增强队
员技能和提升他们职业生涯的方式。&lt;/p&gt;

&lt;p&gt;这是架构师职责的一部分（this is something that should fall squarely within the
remit of the software architect），而且很显然，给你的团队培训架构和设计技能与
助他们解决代码问题之间还是有明显区别的。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-delivery-3.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-质量保障quality-assurance&quot;&gt;4 质量保障（quality assurance）&lt;/h3&gt;

&lt;p&gt;如果交付工作做的太差的话，那即使有世界上最好的架构和最强的领导力，项目仍然会失败。&lt;/p&gt;

&lt;p&gt;质量保障是架构师角色中的很大一部分，但它远非仅仅是 code
review。例如，你需要有基准的性能指标，这意味着需要引入标准和工作惯例（standards
and working
practices）。从软件开发的角度讲，这包括：编码标准、设计原则，以及源代码分析工具
等等。我们可以肯定地说，大部分项目的质量保障做的并不够，因此你需要辨别出哪些是重
要的，并优先保证这些部分被执行。对于我来说，一切对架构有重要影响的，或对业务非常
关键的，或复杂的，或高度可视化的东西都是重要的。你需要务实，意识到你无法保障所有
方面，但是做一部分总是比什么都不做好。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-delivery-4.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5-设计开发和测试designdevelopment-and-testing&quot;&gt;5 设计、开发和测试（design，development and testing）&lt;/h3&gt;

&lt;p&gt;软件架构师角色的最后任务就是设计、开发和测试。作为一名工作在一线的架构师并不意味
着你必须参与每天的写代码任务，而是说你要持续的参与到项目中，积极主动地去帮助打造
和交付它。话已至此，那我们不禁要说，为什么每天写代码不应该成为架构师角色的一部分
呢？大部分架构师都是经验丰富的程序员，因此保持这项技能的状态是有意义的。除此之外
，架构师还能经历团队成员都会经历的痛苦，在此过程中可以帮助他们从开发的角度理解他
们设计出来的架构。一些公司明令禁止他们的架构师参与编码工作，因为觉得他们的架构
师太宝贵了，不应该从事编码这样普通的工作。显然，这种态度是错误的，如果你不让他
们参与成功交付的过程，那又为什么让他花精力设计架构呢？&lt;/p&gt;

&lt;p&gt;当然，有些情况下让架构师参与到写代码的程度确实不太可行。例如，一个大型项目通常意
味着需要考虑很大一张图，因而不一定有时间参与到实现过程。但通常来说，写代码的
架构师比只是旁观的架构师更加高效和快乐。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/are-you-a-software-architect/architecture-delivery-5.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;你是一名软件架构师吗&quot;&gt;你是一名软件架构师吗？&lt;/h2&gt;

&lt;p&gt;不管将软件开发和软件架构之间的那条线看作是神话还是鸿沟，本文讨论的内容都说明：软
件架构师在这个角色上的经验都随着他们参与到项目的程度和他们对待自己角色的认真程度
而异。大部分开发者都不会周一早上醒来就宣称自己是一名软件架构师了。我自己当然不是
这样，我成为架构师的过程是一个演进的过程。其实，一部分开发者可能已经在承担部分软
件架构师的角色了，虽然他们的 title 并没有显示这一点。&lt;/p&gt;

&lt;p&gt;参与一个软件系统的架构（contributing to the architecture of a software system）
和亲自设计一个软件的架构之间有很大不同。&lt;strong&gt;持续精进的技能、知识和跨多领域的经验成
就了软件架构师的角色&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;跨越软件工程师和软件架构师的主动性在你自己，而首先要做的，就是了解你目前的经验所
处的层次。&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

</description>
        
        <pubDate>Mon, 18 Mar 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/are-you-a-software-architect-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/are-you-a-software-architect-zh/</guid>
        
        
        <category>architect</category>
        
        <category>architecture</category>
        
      </item>
      
    
      
      <item>
        <title>[译] 数据中心网络：Spine-Leaf 架构设计综述</title>
        <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

&lt;p&gt;本文内容翻译自 Cisco 的白皮书 &lt;a href=&quot;https://www.cisco.com/c/en/us/products/collateral/switches/nexus-7000-series-switches/white-paper-c11-737022.pdf&quot;&gt;&lt;strong&gt;&lt;em&gt;Cisco Data Center Spine-and-Leaf Architecture:
Design
Overview&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;
（2016），翻译非逐字逐句，请酌情参考。&lt;/p&gt;

&lt;p&gt;搜索 spine-leaf 资料时看到这篇非常棒的文档，故通过翻译的方式做个笔
记顺便加深理解（不知是否有没有中文版）。&lt;strong&gt;本文翻译仅供个人学习交流，无任何商业目
的，如有侵权将及时删除&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;另外，发现思科、华为、华三等厂商的官网上都有大量的优秀文档，其最终目的虽然是推介
产品，但其中关于基础设施的内容大部分都是厂商无关的，可以作为很好的学习材料
。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。&lt;/strong&gt; 
优秀的英文技术文档用词都比较简单直接，推荐有需要的读者阅读原文。&lt;/p&gt;

&lt;p&gt;以下是译文。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-数据中心演进&quot;&gt;1 数据中心演进&lt;/h2&gt;

&lt;p&gt;数据中心是现代软件技术的基石，在扩展企业能力的过程中扮演着关键角色。传统的数据中
心使用三层架构（three-tier architecture），根据物理位置将服务器划分为不同 pod，
如图 1 所示。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/1-3-tier-arch.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1 传统三层（Three-Tier）数据中心设计&lt;/p&gt;

&lt;p&gt;这种架构由&lt;strong&gt;核心路由器&lt;/strong&gt;、&lt;strong&gt;聚合路由器&lt;/strong&gt;（有时叫分发路由器，distribution routers
）和&lt;strong&gt;接入交换机&lt;/strong&gt;组成。在接入交换机和聚合路由器之间运行生成树协议（Spanning
Tree Protocol，STP），以保证网络的二层部分（L2）没有环路。STP 有许多好处：简单，
即插即用（plug-and-play），只需很少配置。&lt;strong&gt;每个 pod 内的机器都属于同一个 VLAN，
因此服务器无需修改 IP 地址和网关就可以在 pod 内部任意迁移位置&lt;/strong&gt;。但是，STP 无法
使用并行转发路径（parallel forwarding path），它永远会禁用 VLAN 内的冗余路径。&lt;/p&gt;

&lt;p&gt;2010 年，Cisco 提出了 virtual-port-channel (vPC) 技术来解决 STP 的限制。
vPC 解放了被 STP 禁用的端口，提供接入交换机到汇聚路由器之间的 active-active 上行链路，
充分利用可用的带宽，如图 2 所示。使用 vPC 技术时，STP 会作为备用机制（
fail-safe mechanism）。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/2-using-vPC.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 2 使用 vPC 技术的数据中心设计&lt;/p&gt;

&lt;p&gt;从 2003 年开始，随着虚拟化技术的引入，原来三层（three-tier）数据中心中，&lt;strong&gt;在二层（
L2）以 pod 形式做了隔离&lt;/strong&gt;的计算、网络和存储资源，现在都可以被池化（pooled）。这
种革命性的技术产生了&lt;strong&gt;从接入层到核心层的大二层域&lt;/strong&gt;（larger L2 domain）的需求，如
图3 所示
。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/3-extended-L3-domain.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 3 扩展的 L3 域的数据中心设计&lt;/p&gt;

&lt;p&gt;随着 L2 segment（二层网络段，例如 VLAN 划分的二层网络，译者注）被扩展到所有 pod
，数据中心的管理员可以创建一个集中式的、更加灵活的、能够按需分配的资源池。物理服
务器被虚拟化为许多虚拟服务器（VM），无需修改运维参数就可以在物理服务器之间自由漂
移。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;虚拟机的引入，使得应用的部署方式越来越分布式，导致东西向流量（
east-west-traffic）越来越大&lt;/strong&gt;。这些流量需要被高效地处理，并且还要保证低的、可预测的延迟。
然而，vPC 只能提供两个并行上行链路，因此三层数据中心架构中的&lt;strong&gt;带宽成为了瓶颈&lt;/strong&gt;。
三层架构的另一个问题是&lt;strong&gt;服务器到服务器延迟（server-to-server latency）随着流量路
径的不同而不同&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;针对以上问题，提出了一种新的数据中心设计，称作&lt;strong&gt;基于 Clos 网络的 Spine-and-Leaf 架
构&lt;/strong&gt;（Clos network-based Spine-and-Leaf architecture）。事实已经证明，这种架构可
以提供高带宽、低延迟、非阻塞的服务器到服务器连接。&lt;/p&gt;

&lt;h2 id=&quot;2-spine-leaf-架构&quot;&gt;2 Spine-Leaf 架构&lt;/h2&gt;

&lt;p&gt;图 4 是一个典型的两级 Spine-and-Leaf 拓扑。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/4-spine-leaf.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4 典型的 Spine-and-Leaf 拓扑&lt;/p&gt;

&lt;p&gt;在以上两级 Clos 架构中，&lt;strong&gt;每个低层级的交换机（leaf）都会连接到每个高层级的交换机
（spine），形成一个 full-mesh 拓扑&lt;/strong&gt;。leaf 层由接入交换机组成，用于连接服务器等
设备。spine 层是网络的骨干（backbone），负责将所有的 leaf 连接起来。
fabric 中的每个 leaf 都会连接到每个 spine，如果一个 spine 挂了，数据中心的吞吐性
能只会有轻微的下降（slightly degrade）。&lt;/p&gt;

&lt;p&gt;如果某个链路被打满了，扩容过程也很直接：添加一个 spine 交换机就可以扩展每个 leaf
的上行链路，增大了 leaf 和 spine 之间的带宽，缓解了链路被打爆的问题。如果接入层
的端口数量成为了瓶颈，那就直接添加一个新的 leaf，然后将其连接到每个 spine 并做相
应的配置即可。这种易于扩展（ease of expansion）的特性优化了 IT 部门扩展网络的过
程。&lt;strong&gt;leaf 层的接入端口和上行链路都没有瓶颈时，这个架构就实现了无阻塞&lt;/strong&gt;（nonblocking）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在 Spine-and-Leaf 架构中，任意一个服务器到另一个服务器的连接，都会经过相同数量
的设备（除非这两个服务器在同一 leaf 下面），这保证了延迟是可预测的&lt;/strong&gt;，因为一个包
只需要经过一个 spine 和另一个 leaf 就可以到达目的端。&lt;/p&gt;

&lt;h2 id=&quot;3-overlay-网络&quot;&gt;3 Overlay 网络&lt;/h2&gt;

&lt;p&gt;现代虚拟化数据中心的网络要加速应用部署和支持 DevOps，必须满足特定的前提
条件。例如，需要支持扩展转发表、扩展网段、L2 segment
extension、虚拟设备漂移（mobility）、转发路径优化、共享物理基础设施上的网络虚拟
化和多租户等等。&lt;/p&gt;

&lt;p&gt;虽然 overlay 的概念并不是最近才提出的，但因为它可以解决以上提到的问题，因此近几
年这个概念又火了起来。最近专门针对数据中心提出的新的帧封装格式（encapsulation
frame format）更是为这个势头添了一把火。这些格式包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;VXLAN&lt;/strong&gt;：Virtual Extensible LAN&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NVGRE&lt;/strong&gt;: Network Virtualization Using Generic Routing Encapsulation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TRILL&lt;/strong&gt;: Transparent Interconnection of Lots of Links&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;LISP&lt;/strong&gt;:  Location/Identifier Separation Protocol&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;overlay 网络是共享底层网络（underlay network）的节点之间互连形成的虚拟网络，这使
得在不修改底层（underlay）网络的情况下，可以部署对网络拓扑有特定要求的应用，如图
5 所示。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/5-overlay-net.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5 网络 Overlay 概念&lt;/p&gt;

&lt;p&gt;overlay 虚拟化带来的好处包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;优化的设备功能&lt;/strong&gt;：overlay 网络使得可以根据设备在网络中的位置不同而对设备进行
分类（和定制）。edge 或 leaf 设备可以根据终端状态信息和规模优化它的功能和相关
的协议；core 或 spine 设备可以根据链路状态优化它的功能和协议，以及针对快速收敛
进行优化。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;fabric 的扩展性和灵活性&lt;/strong&gt;：overlay 技术使得可以在 overlay 边界设备上进行网络
的扩展。当在 fabric 边界使用 overlay 时，spine 或 core 设备就无
需向自己的转发表中添加终端主机的信息（例如，如果在宿主机内进行 overlay 的封
装和解封装，那 overlay 边界就是在宿主机内部，译者注）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;可重叠的寻址&lt;/strong&gt;：数据中心中使用的大部分 overlay 技术都支持虚拟网络 ID，用来唯
一地对每个私有网络进行范围限定和识别（scope and identify）。这种限定使得不同租
户的 MAC 和 IP 地址可以重叠（overlapping）。overlay 的封装使得租户地址空间和
underlay 地址空间的管理分开。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文档将介绍 Cisco 过去几年和当前提供的、以及不远的将来应该会提供的几种
Spine-and-Leaf 架构设计，这些设计都是为了解决现代虚拟化数据中心中 fabric 面临的
需求：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cisco® FabricPath spine-and-leaf network&lt;/li&gt;
  &lt;li&gt;Cisco VXLAN flood-and-learn spine-and-leaf network&lt;/li&gt;
  &lt;li&gt;Cisco VXLAN Multiprotocol Border Gateway Protocol (MP-BGP) Ethernet Virtual Private Network (EVPN) spine-and-leaf network&lt;/li&gt;
  &lt;li&gt;Cisco Massively Scalable Data Center (MSDC) Layer 3 spine-and-leaf network&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面的几章将围绕写作本文时的一些最重要技术组件、通用设计和设计考虑（例如 L3 网关）进行讨论。&lt;/p&gt;

&lt;p&gt;最重要的技术组件包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;封装&lt;/li&gt;
  &lt;li&gt;end-host 检查和分发（end-host detection and distribution）&lt;/li&gt;
  &lt;li&gt;广播&lt;/li&gt;
  &lt;li&gt;未知单播（unknown unicast）&lt;/li&gt;
  &lt;li&gt;组播流量转发&lt;/li&gt;
  &lt;li&gt;underlay 和 overlay 控制平面&lt;/li&gt;
  &lt;li&gt;多租户支持&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;4-cicso-fabricpath-spine-and-leaf-网络&quot;&gt;4 Cicso FabricPath Spine-and-Leaf 网络&lt;/h2&gt;

&lt;p&gt;Cisco 在 2010 年推出了 FabricPath 技术。FabricPath 提供的新特性和设计选项使得网
络管理员可以创建&lt;strong&gt;以太网 fabrics&lt;/strong&gt;，后者可以提高带宽可用性、提供设计灵活性，以及
简化和降低网络和应用的部署及运维成本。典型的 FabricPath 都是使用 Spine-and-Leaf 架构。&lt;/p&gt;

&lt;p&gt;FabricPath 继承了很多传统 L2 和 L3 技术中的优良特性，它保留了 L2 环境易于配置和
即插即用的部署模型，并引入了一个称为 &lt;strong&gt;FabricPath IS-IS&lt;/strong&gt;（Intermediate System
to Intermediate System）的控制平面协议。在 FabricPath 网络中，给定任意一个
FabricPath 交换机作为目的端，&lt;strong&gt;最短路径优先&lt;/strong&gt;（shortest path first, SPF）路由协
议将用于判断可达性以及寻找最优路径。&lt;/p&gt;

&lt;p&gt;这种设计的好处：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;更稳定、更易扩展&lt;/li&gt;
  &lt;li&gt;快速收敛&lt;/li&gt;
  &lt;li&gt;像典型的 L3 路由环境一样&lt;strong&gt;使用多个并行路径（multiple parallel paths）的能力&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;41-封装格式和标准兼容&quot;&gt;4.1 封装格式和标准兼容&lt;/h3&gt;

&lt;p&gt;FabricPath spine-and-leaf 网络是 Cisco 的专利，但基于 TRILL 标准。它使用
FabricPath &lt;strong&gt;MAC-in-MAC&lt;/strong&gt; 帧封装。&lt;/p&gt;

&lt;h4 id=&quot;411-underlay-网络&quot;&gt;4.1.1 Underlay 网络&lt;/h4&gt;

&lt;p&gt;数据平面使用 L2 FabricPath MAC-in-MAC 封装，控制面在 underlay 网络中使用
FabricPath IS-IS。每个 FabricPath 交换机都有一个 FabricPath switch ID。&lt;strong&gt;Fabric
IS-IS 控制平面构建可达性信息&lt;/strong&gt;（reachability information），即 FabricPath 交换机
如何连接到其它FabricPath 交换机。&lt;/p&gt;

&lt;h4 id=&quot;412-overlay-网络&quot;&gt;4.1.2 Overlay 网络&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;FabricPath 没有 overlay 控制平面。overlay 网络中的 end-host 信息是通过带会话学
习功能的“泛洪-学习”机制学习的&lt;/strong&gt;（flood-and-learn mechanism with conversational
learning）。&lt;/p&gt;

&lt;h3 id=&quot;42-广播和未知单播流量&quot;&gt;4.2 广播和未知单播流量&lt;/h3&gt;

&lt;h3 id=&quot;43-主机检测和可达性&quot;&gt;4.3 主机检测和可达性&lt;/h3&gt;

&lt;h3 id=&quot;44-组播流量&quot;&gt;4.4 组播流量&lt;/h3&gt;

&lt;h3 id=&quot;45-l3-路由功能&quot;&gt;4.5 L3 路由功能&lt;/h3&gt;

&lt;h4 id=&quot;451-在-spine-层做内部和外部路由&quot;&gt;4.5.1 在 Spine 层做内部和外部路由&lt;/h4&gt;

&lt;h4 id=&quot;452-在-border-leaf-做内部和外部路由&quot;&gt;4.5.2 在 Border Leaf 做内部和外部路由&lt;/h4&gt;

&lt;h3 id=&quot;46-多租户&quot;&gt;4.6 多租户&lt;/h3&gt;

&lt;h3 id=&quot;47-总结&quot;&gt;4.7 总结&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/table-1-fabricpath.PNG&quot; width=&quot;95%&quot; height=&quot;95%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;表 1 Cisco FabricPath 网络特性&lt;/p&gt;

&lt;h2 id=&quot;5-cicso-vxlan-flood-and-learn-spine-leaf-网络&quot;&gt;5 Cicso VXLAN Flood-and-Learn Spine-Leaf 网络&lt;/h2&gt;

&lt;p&gt;VXLAN 是网络虚拟化 overlay 技术之一，有一些自己的优势。它是一个工业标准（
industry-standard）协议，使用 underlay IP 网络。它将 L2 网络进行扩展，在 L3
基础设施之上构建出一个 L2 overlay 逻辑网络。它将以太帧封装到 UDP IP 包里面，通
过underlay 网络以正常的 IP 路由和转发机制发送到对端 VTEP（VXLAN tunnel endpoint
）。&lt;/p&gt;

&lt;p&gt;Cisco 从 2014 年开始，陆续在多个 Nexus 系列（例如 Nexus 5600、7000、9000系列）交
换机上支持 VXLAN flood-and-learn spine-and-leaf 技术。本节介绍这些硬件交换机
的 Cisco VXLAN flood-and-learn 特性。&lt;/p&gt;

&lt;h3 id=&quot;51-封装格式和标准兼容&quot;&gt;5.1 封装格式和标准兼容&lt;/h3&gt;

&lt;p&gt;Cisco VXLAN flood-and-learn 技术兼容 IETF VXLAN 标准（RFC 7348），后者定义了&lt;strong&gt;无控
制平面的基于组播的泛洪-学习 VXLAN&lt;/strong&gt;（multicast-based flood-and-learn VXLAN without
a control plane）。原始的 L2 帧封装一个 VXLAN 头，然后放到 UDP IP 包通过 IP 网络
进行传输。&lt;/p&gt;

&lt;h4 id=&quot;511-underlay-网络&quot;&gt;5.1.1 Underlay 网络&lt;/h4&gt;

&lt;p&gt;使用 L3 IP 网络作为 underlay 网络。&lt;/p&gt;

&lt;p&gt;使用 underlay IP multicast 减少 VXLAN 网段的主机之间泛洪的范围。&lt;/p&gt;

&lt;p&gt;每个 VXLAN segment 都有一个 VNI（VXLAN network ID），&lt;strong&gt;VNI 会映射到传输网络中的一
个 IP 多播组&lt;/strong&gt;。每个 VTEP 设备独立配置多播组，参与 PIM 路由。基于参与的 VTEP 的位
置，会在传输网络中形成这个组对应的多播分发树（multicast distribution tree）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这种方案需要在 underlay 网络中开启多播功能，而一些企业可能
并不想在他们的数据中心或 WAN 中开启组播&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Cisco 9000 特色介绍：略（TODO）。&lt;/p&gt;

&lt;h4 id=&quot;512-overlay-网络&quot;&gt;5.1.2 Overlay 网络&lt;/h4&gt;

&lt;p&gt;这种设计&lt;strong&gt;没有 overlay 网络的控制平面&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;它在 L3 IP underlay 网络之上构建了一层 L2 overlay 网络，通过 VTEP 隧道机制传输 L2
包。&lt;strong&gt;overlay 网络使用 flood-and-learn 语义&lt;/strong&gt;，如图 11 所示。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/11-vxlan-overlay.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 11 VXLAN overlay 网络&lt;/p&gt;

&lt;h3 id=&quot;52-广播和未知单播流量&quot;&gt;5.2 广播和未知单播流量&lt;/h3&gt;

&lt;p&gt;使用 underlay IP PIM 或 ingress replication 发送广播和未知的单播（unknown
unicast）流量。注意 ingress replication 只有 Cisco Nexus 9000 系列交换机才支持。&lt;/p&gt;

&lt;h3 id=&quot;53-主机检测和可达性&quot;&gt;5.3 主机检测和可达性&lt;/h3&gt;

&lt;p&gt;依赖初始的数据平面泛洪，每个 VXLAN segment 的 VTEP 能发现其他主机，学习远端主机
的 MAC 和 MAC-to-VTEP 映射。MAC-to-VTEP 映射完成后，VTEP 接下来就通过单播转发
VXLAN 流量。&lt;/p&gt;

&lt;h3 id=&quot;54-组播流量&quot;&gt;5.4 组播流量&lt;/h3&gt;

&lt;p&gt;通过 underlay IP PIM 或 ingress replication 可以支持 overlay 租户的 &lt;strong&gt;L2 组播&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;L3 组播&lt;/strong&gt;流量通过 L3 基于 PIM 的组播路由（L3 PIM-based multicast routing）实现。&lt;/p&gt;

&lt;p&gt;略。&lt;/p&gt;

&lt;h3 id=&quot;55-l3-路由功能&quot;&gt;5.5 L3 路由功能&lt;/h3&gt;

&lt;p&gt;在一个传统的 VLAN 环境中，很多情况下需要 VXLAN segment 和 VLAN segment 之间的路由。
典型的 VXLAN flood-and-learn spine-and-leaf 网络设计中，leaf ToR (top-of-rack)
交换机会作为 VTEP 设备，在机柜（rack）之间扩展 L2 segment。&lt;/p&gt;

&lt;p&gt;VXLAN 和 VLAN 之间的 二层流量转发时，VTEP 作为 L2 VXLAN 网关；三层流量路
由时，还需要开启某些 VTEP 的 L3 VXLAN 网关功能。常见的设计有：内部和外部路由在
spine 层，或内部和外部路由在 leaf 层。这两种设计都是集中式路由（centralized
routing），即：三层的内部和外部路由功能都集中在特定的交换机上做。&lt;/p&gt;

&lt;h4 id=&quot;551-在-spine-层做内部和外部路由&quot;&gt;5.5.1 在 Spine 层做内部和外部路由&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/12-routing-on-spine.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 12 在 spine 上做内部和外部路由&lt;/p&gt;

&lt;p&gt;图 12 是在 spine 层做内部和外部路由的示意图，&lt;strong&gt;leaf ToR VTEP 交换机作为 L2 VXLAN
网关&lt;/strong&gt;，在 underlay 网络上传输 L2 segment。spine 有两功能：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;作为 underlay 网络的一部分，传输 VXLAN 封装的包&lt;/li&gt;
  &lt;li&gt;做内部的 inter-VXLAN 路由，以及外部路由&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;内部和外部路由流量需要从 VTEP 经过 underlay 的一跳到达 spine，然后被 spine 路由。&lt;/p&gt;

&lt;p&gt;注意，在使用 HSRP（Hot-Standby Router Protocol）和 vPC 的配置下，VXLAN 之间
active-active 网关的最大数量是两个。另外，&lt;strong&gt;spine L3 VXLAN 网关会学习主机 MAC
地址&lt;/strong&gt;，所以需要考虑 MAC 地址的规模，以免超出硬件的限制。&lt;/p&gt;

&lt;h4 id=&quot;552-在-border-leaf-做内部和外部路由&quot;&gt;5.5.2 在 Border Leaf 做内部和外部路由&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/13-routing-on-border-leaf.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 13 在 Border Leaf 上做内部和外部路由&lt;/p&gt;

&lt;p&gt;在 Border Leaf 上做内部和外部路由如图 13。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;leaf ToR VTEP 交换机作为 L2 VXLAN 网关&lt;/strong&gt;，在 underlay 网络上传输 L2 segment。&lt;strong&gt;spine
是 underlay 网络的一部分，它并不学习 overlay 主机的 MAC 地址&lt;/strong&gt;。&lt;strong&gt;border leaf 路由器
承担 L3 VXLAN 网关功能&lt;/strong&gt;，负责 inter-VXLAN 路由和外部路由。&lt;/p&gt;

&lt;p&gt;内部和外部路由流量需要&lt;strong&gt;从 VTEP 经过 underlay 的两跳&lt;/strong&gt;（先到 spine 再到 border
leaf）到达 border leaf，然后才能被路由到外部网络。&lt;/p&gt;

&lt;p&gt;同样，在使用 HSRP 和 vPC 的配置下，inter-VXLAN active-active 网关的最大数量是两
个。另外，&lt;strong&gt;border leaf L3 VXLAN 网关会学习主机 MAC地址&lt;/strong&gt;，所以需要考虑 MAC 地
址的规模，以免超出硬件的限制。&lt;/p&gt;

&lt;h3 id=&quot;56-多租户&quot;&gt;5.6 多租户&lt;/h3&gt;

&lt;h3 id=&quot;57-总结&quot;&gt;5.7 总结&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/table-2-vxlan.PNG&quot; width=&quot;95%&quot; height=&quot;95%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;表 2 Cisco VXLAN flood-and-learn 网络特性&lt;/p&gt;

&lt;h2 id=&quot;6-cicso-vxlan-mp-bgp-evpn-spine-leaf-网络&quot;&gt;6 Cicso VXLAN MP-BGP EVPN Spine-Leaf 网络&lt;/h2&gt;

&lt;p&gt;RFC 7348 定义的 VXLAN flood-and-learn 模型中，&lt;strong&gt;end-host（终端主机）学习&lt;/strong&gt;和
&lt;strong&gt;VTEP 发现&lt;/strong&gt;都是基于数据平面，并没有控制平面来在 VTEP 之间分发 end-host 可达性
信息。为了克服这种方案的一些限制，&lt;strong&gt;Cisco VXLAN MP-BGP EVPN Spine-and-Leaf 架构&lt;/strong&gt;使
用了 &lt;strong&gt;MP-BGP EVPN 作为 VXLAN 的控制平面&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这种设计使得&lt;strong&gt;控制平面和数据平面分离&lt;/strong&gt;，并且为 overlay 网络的 L2/L3 转发提供了统
一的控制平面。本节介绍这种方案中 Cisco 硬件交换机（例如 Cisco Nexus 5600
、7000、9000 系列）上的应用。&lt;/p&gt;

&lt;h3 id=&quot;61-封装格式和标准兼容&quot;&gt;6.1 封装格式和标准兼容&lt;/h3&gt;

&lt;p&gt;使用 VXLAN 封装，原始 L2 帧加一层 VXLAN 头然后封装到 UDP-IP 包进行传输。&lt;/p&gt;

&lt;p&gt;与 IETF RFC 7348 和draft-ietf-bess-evpn-overlay 标准是兼容的。&lt;/p&gt;

&lt;h4 id=&quot;611-underlay-网络&quot;&gt;6.1.1 Underlay 网络&lt;/h4&gt;

&lt;p&gt;使用 L3 IP 网络作为 underlay 网络。&lt;/p&gt;

&lt;h4 id=&quot;612-overlay-网络&quot;&gt;6.1.2 Overlay 网络&lt;/h4&gt;

&lt;p&gt;使用 MP-BGP EVPN 作为 VXLAN overlay 网络的控制平面协议。&lt;/p&gt;

&lt;h3 id=&quot;62-广播和未知单播流量&quot;&gt;6.2 广播和未知单播流量&lt;/h3&gt;

&lt;p&gt;使用 underlay IP PIM 或 ingress replication 特性发送&lt;strong&gt;广播&lt;/strong&gt;和&lt;strong&gt;未知单播&lt;/strong&gt;流量。&lt;/p&gt;

&lt;p&gt;underlay 开启 IP 组播的情况下，每个 VXLAN segment，或者 VNI，都会映射到underlay
的一个 IP 组播组（multicast group）。每个 VTEP 设备独立配置组播组，参与PIM 路由
。基于参与的 VTEP 的位置，会在传输网络中形成这个组对应的多播分发树（multicast
distribution tree）。&lt;/p&gt;

&lt;p&gt;如果使用 ingress replication 特性，那 underlay 就无需组播了。VTEP 之间通过 VTEP
的 IP 地址发送广播和未知单播流量。这些 IP 地址是通过 BGP EVPN 控制平面在 VTEP 之
间交换的，或者通过静态配置。&lt;/p&gt;

&lt;h3 id=&quot;63-主机检测和可达性&quot;&gt;6.3 主机检测和可达性&lt;/h3&gt;

&lt;p&gt;MP-BGP EVPN 控制平面提供内置的路由和转发（功能），它会对 VXLAN overlay 网络内的
end-host 的 L2/L3 可达性信息进行分发（distribution）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;每个 VTEP 从与它相连的主机中自动学习 MAC 地址（通过传统的 MAC 地址学习）和 IP
地址信息（基于 ARP snooping），然后通过控制平面进行分发&lt;/strong&gt;，因此远端主机的信息是
控制平面同步过来的。这种方式避免了通过网络泛洪学习远端主机信息的问题，为
end-host 可达性信息的分发提供了更好的控制。&lt;/p&gt;

&lt;h3 id=&quot;64-组播流量&quot;&gt;6.4 组播流量&lt;/h3&gt;

&lt;p&gt;使用 underlay IP 组播或 ingress replication 特性，可以支持 overlay 租户的 L2 组
播。&lt;/p&gt;

&lt;p&gt;通过外部路由器上 L3 PIM-based multicast 路由，可以支持 overlay 租户的 L3 组播。&lt;/p&gt;

&lt;h3 id=&quot;65-l3-路由功能&quot;&gt;6.5 L3 路由功能&lt;/h3&gt;

&lt;p&gt;L3 路由需要解决两个问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;VXLAN 网络内部&lt;/strong&gt;的路由：使用&lt;strong&gt;分布式任播网关&lt;/strong&gt;（distributed anycast gateways）解决&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;VXLAN 网络和外部网络&lt;/strong&gt;（包括园区网、WAN 和互联网）的路由：在几个特定交换机上实现&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;651-分布式任播网关解决-vxlan-网络内部路由&quot;&gt;6.5.1 分布式任播网关：解决 VXLAN 网络内部路由&lt;/h4&gt;

&lt;p&gt;在 MP-BGP EVPN 网络中，一个 VNI 内的任意一个 VTEP 都可以作为它所在子网的分布式
任播网关，对它们配置相同的虚拟网关 IP 和虚拟网关 MAC 即可，如图 16 所示。&lt;/p&gt;

&lt;p&gt;EVPN 的这种任播网关功能，使得 VNI 内的主机可以将本地 VTEP 作为其网关，将跨网段的
流量发送到 VTEP 设备。这使得 VXLAN 网络中从主机出来的北向流量可以达到最优转发。
分布式任播网关还给 overlay 网络带来了透明主机漂移（transparent host mobility）的
好处。因为一个 VNI 的所有 VTEP 设备上的网关 IP 和 MAC 地址都是相同的，当一个主机
从一个 VTEP 移动到另一个 VTEP 后，它无需发送 ARP 请求来重新学习网关的 MAC 地址。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/16-distributed-anycast-gw.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 16 内部路由的分布式任播网关&lt;/p&gt;

&lt;h4 id=&quot;652-在-border-leaf-做外部路由&quot;&gt;6.5.2 在 Border Leaf 做外部路由&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/17-external-routing-at-border-leaf.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 17 Border Leaf 做外部路由的设计&lt;/p&gt;

&lt;p&gt;图 17 是典型的通过一对 border leaf 交换机连接到外部路由设备的设计。Border leaf
在 VXLAN 网络侧运行 MP-BGP EVPN，和网络内的 VTEP 交换 EVPN 路由。同时，它在租户
VRF 实例中运行普通的 IPv4 或 IPv6 单播路由协议和外部路由设备交换路由信息。路由协
议可以是常规 eBGP，或任何内部网关协议（IGP）。Border leaf 将学习来的外部路由
以 EVPN 路由的形式通告到 EVPN 域，因此 VTEP 就能学习到外部路由，然后就可以发送出
VXLAN 网络的流量。&lt;/p&gt;

&lt;p&gt;也可以配置 border leaf 将学习到的 L2 VPN EVPN 地址族到 IPv4 或 IPv6 单播地址族的
路由，通告到外部路由。在这种设计中，租户流量需要经过 underlay 的两跳（VTEP 到
spine 到 border leaf）到达外部网络。然而，这种情况下 spine 只需要运行 BGP-EVPN 控
制平面和 IP 路由，无需支持 VXLAN VTEP 功能（即，无需支持 VXLAN 的封装和解封装，
译者注）。&lt;/p&gt;

&lt;h4 id=&quot;653-在-border-spine-做外部路由&quot;&gt;6.5.3 在 Border Spine 做外部路由&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/18-external-routing-with-border-spine.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 18 Border Spine 做外部路由的设计&lt;/p&gt;

&lt;p&gt;图 18 是典型的通过一对 border spine 交换机连接到外部路由设备的设计。这种设计中，
spine 需要支持 VXLAN 路由。spine 在 VXLAN 网络侧运行 MP-BGP EVPN，和 VTEP 交换
EVPN 路由信息。同时，它在租户
VRF 实例中运行普通的 IPv4 或 IPv6 单播路由协议和外部路由设备交换路由信息。路由协
议可以是常规 eBGP，或任何内部网关协议（IGP）协议。spine 将学习来的外部路由
以 EVPN 路由的形式通告到 EVPN 域，因此 VTEP 就能学习到外部路由，然后就可以发送出
VXLAN 网络的流量。&lt;/p&gt;

&lt;p&gt;也可以配置 spine 将学习到的 L2 VPN EVPN 地址族到 IPv4 或 IPv6 单播地址族的
路由，通告到外部路由。在这种设计中，租户流量只需经过 underlay 的一跳（VTEP 到
spine）就可以到达外部网络。然而，这种情况下 spine 需要运行 BGP-EVPN
控制平面和 IP 路由，以及支持 VXLAN VTEP 功能。&lt;/p&gt;

&lt;h3 id=&quot;66-多租户&quot;&gt;6.6 多租户&lt;/h3&gt;

&lt;p&gt;作为 MP-BGP 的扩展，MP-BGP EVPN 继承了 VPN 通过 VRF 实现的对多租户的支持。&lt;/p&gt;

&lt;p&gt;在 MP-BGP EVPN 中，多个租户可以共存，它们共享同一个 IP 传输网络（underlay），而
在 VXLAN overlay 网络中拥有独立的 VPN，入图 19 所示。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/19-mp-bgp-evpn-multi-tenancy.PNG&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 19 Cisco VXLAN MP-BGP EVPN Spine-and-Leaf 网络的多租户&lt;/p&gt;

&lt;p&gt;在 VXLAN MP-BGP EVPN spine-and-leaf 网络中，&lt;strong&gt;VNI 定义了二层域&lt;/strong&gt;，不允许 L2 流量跨越
VNI 边界。类似地，&lt;strong&gt;VXLAN 租户的三层 segment 是通过 VRF 技术隔离的&lt;/strong&gt;，通过将不同 VNI
映射到不同的 VRF 实例来隔离租户的三层网络。每个租户都有自己的 VRF 路由实例。同一
租户的 VNI 的不同子网，都属于同一个 L3 VRF 实例，这个 VRF 将租户的三层路由与其他
租户的路由隔离开来。&lt;/p&gt;

&lt;h3 id=&quot;67-总结&quot;&gt;6.7 总结&lt;/h3&gt;

&lt;p&gt;控制平面学习到 end-host 的 L2 和 L3 可达性信息（MAC 和 IP），然后通过 EVPN 地址
族分发这些信息，因此提供了 VXLAN overlay 网络的桥接和路由功能。这种方案减少了网
络泛洪，以及本地 VTEP 上的 ARP suppression。三层内部流量直接通过 ToR 上的分布式
网关路由，扩展性（scale-out）比较好。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/spine-leaf-design/table-3-mp-bgp-evpn.PNG&quot; width=&quot;95%&quot; height=&quot;95%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;表 3 Cisco VXLAN MP BGP EVPN 网络特性&lt;/p&gt;

&lt;h2 id=&quot;7-cicso-msdc-layer-3-spine-leaf-网络&quot;&gt;7 Cicso MSDC Layer 3 Spine-Leaf 网络&lt;/h2&gt;

&lt;h2 id=&quot;8-数据中心-fabric-管理和自动化&quot;&gt;8 数据中心 Fabric 管理和自动化&lt;/h2&gt;

&lt;h2 id=&quot;9-总结&quot;&gt;9 总结&lt;/h2&gt;

&lt;h2 id=&quot;10-更多信息&quot;&gt;10 更多信息&lt;/h2&gt;

</description>
        
          <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

</description>
        
        <pubDate>Wed, 06 Mar 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/spine-leaf-design-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/spine-leaf-design-zh/</guid>
        
        
        <category>spine-leaf</category>
        
        <category>network</category>
        
        <category>architecture</category>
        
      </item>
      
    
      
      <item>
        <title>[译] 数据中心网络：分层网络设计综述</title>
        <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

&lt;p&gt;本文内容翻译自 Cisco 的一门叫 &lt;a href=&quot;http://www.ciscopress.com/store/connecting-networks-companion-guide-9781587133329&quot;&gt;&lt;strong&gt;&lt;em&gt;Connecting Networks&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt; 的教材（2014），
英文版可以在官网&lt;a href=&quot;http://www.ciscopress.com/store/connecting-networks-companion-guide-9781587133329&quot;&gt;在线阅读&lt;/a&gt;
，也可以&lt;a href=&quot;http://ptgmedia.pearsoncmg.com/images/9781587133329/samplepages/1587133326.pdf&quot;&gt;在这里下载 PDF&lt;/a&gt;（仅前三章）。&lt;/p&gt;

&lt;p&gt;搜索网络架构的资料时偶然看到这本小册子，其中关于基础网络和数据中心网络架构设计的
内容非常不错，故通过翻译的方式（不知道有没有中文版）做个笔记顺便加深理解。&lt;strong&gt;本文
翻译仅供个人学习交流，无商业目的，如有侵权将及时删除&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;本篇翻译自原书第一章第一节，介绍经典的数据中心三层网络架构：接入层-汇聚层-核
心层。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。&lt;/strong&gt; 
原书英文比较简单，也推荐有需要的读者阅读英文全书。&lt;/p&gt;

&lt;p&gt;以下是译文。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;10-引言&quot;&gt;1.0 引言&lt;/h2&gt;

&lt;p&gt;网络不仅要满足企业的当前需求，还要能演进以支持新的技术。网络设计原则和模型能帮助
网络工程师设计和建造灵活、有弹性和方便管理的网络。&lt;/p&gt;

&lt;p&gt;本章将介绍网络设计的概念、原则、模型和架构，以及遵循系统的设计方法（systematic
design approach）所带来的收益。&lt;/p&gt;

&lt;h2 id=&quot;11-分层网络设计综述&quot;&gt;1.1 分层网络设计综述&lt;/h2&gt;

&lt;p&gt;思科的&lt;strong&gt;分层（三层）互连网络模型&lt;/strong&gt;（hierarchical internetworking model）是工业界
设计可靠、可扩展、高性价比的互连网络时广泛采用的模型。在本章中，你将学习到接入层
、分发层（思科这里称作 distribution layer，但更通用的称呼是 aggregation layer，
即汇聚层。译者注）、核心层，以及它们在分层网络模型中承担的角色。&lt;/p&gt;

&lt;h3 id=&quot;111-企业网络设计&quot;&gt;1.1.1 企业网络设计&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;对网络规模的了解&lt;/strong&gt;，以及&lt;strong&gt;良好的结构化工程原则&lt;/strong&gt;（an understanding of
network scale and knowledge of good structured engineering principles），对讨论
网络设计非常有帮助。&lt;/p&gt;

&lt;h4 id=&quot;1111-网络需求&quot;&gt;1.1.1.1 网络需求&lt;/h4&gt;

&lt;p&gt;讨论网络设计时，通常根据设备数量将网络分成几类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;小型网络：支持最多 200 个设备&lt;/li&gt;
  &lt;li&gt;中型网络：支持 200 ~ 1000 个设备&lt;/li&gt;
  &lt;li&gt;大型网络：支持 1000+ 设备&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网络设计随规模和公司需求的不同而不同。例如，小公司的设备数量比较少，因此网络基础
设施就无需像大公司设计的那么复杂。&lt;/p&gt;

&lt;p&gt;网络设计需要考虑很多变量。例如，图 1-1 是一个由主 site 构成的大型企业网络连接
小型、中型、大型 site 的高层拓扑示例。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-1.PNG&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-1 大型企业网络设计&lt;/p&gt;

&lt;p&gt;网络设计领域还在快速发展，需要用到大量的知识和经验。本节的目的是介绍一些网络设计
领域已经广泛接受的概念。&lt;/p&gt;

&lt;h4 id=&quot;1112-结构化工程原则&quot;&gt;1.1.1.2 结构化工程原则&lt;/h4&gt;

&lt;p&gt;不管网络规模和企业需求如何，结构化工程原则都是设计一个成功的网络架构的关键因
素。这些原则包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;层级化&lt;/strong&gt;（hierarchy）：分层网络模型（hierarchical network model）是设计可靠
的网络基础设施时非常有用的高层工具，它将复杂的网络设计问题拆分为更小的易掌控的
若干个领域。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;模块化&lt;/strong&gt;（modularity）：将功能划分为几个网络模块会使设计更容易。
Cisco 定义的模块包括企业网（enterprise campus）、服务模块（service block）、数
据中心（data center）、以及互联网边缘（internet edge）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;弹性&lt;/strong&gt;（resiliency）：保证网络在正常和异常的情况下都可用（
available for use）。正常的情况包括正常或预期的网络流量和模式（traffic flow
and traffic patterns），计划事件，例如维护窗口（maintenance window）。不正
常的情况包括硬件和软件故障、极端网络流量、异常流量（unusual traffic
patterns）、DoS 事件、计划外事件等等。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;（flexibility）：在不对网络做根本性改造（forklift upgrade）的前提
下（例如更换主要的硬件设备），有修改部分网络、添加新服务或扩容的能力&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;要满足这些基础的设计目标，网络必须构建在分层架构之上，这样的架构足够灵活，并且支
持网络规模的增长。&lt;/p&gt;

&lt;h3 id=&quot;112-分层网络设计&quot;&gt;1.1.2 分层网络设计&lt;/h3&gt;

&lt;p&gt;本节讨论分层网络模型的三个层：接入层、分发层、核心层。&lt;/p&gt;

&lt;h4 id=&quot;1121-网络层级network-hierarchy&quot;&gt;1.1.2.1 网络层级（Network Hierarchy）&lt;/h4&gt;

&lt;p&gt;早期的网络都是扁平拓扑（flat topology），如图 1-2 所示。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-2.PNG&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-2 扁平网络&lt;/p&gt;

&lt;p&gt;当更多的设备需要接入网络时，就添加集线器（hub）和交换机（switch）。扁平网络设计
的缺点是&lt;strong&gt;很难控制广播流量，或者对特定流量进行过滤&lt;/strong&gt;。当网络中的设备越来越多时，
响应时间也会越来越慢，最终使得网络不可用。&lt;/p&gt;

&lt;p&gt;因此，我们需要一个更好的方案。现在，大部分公司都使用图 1-3 所示的分层网络方案。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-3.PNG&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-3 分层网络&lt;/p&gt;

&lt;p&gt;分层网络设计将网络划分为多个独立的层级（discrete layers），每一层（
layer，or tier）提供特定的功能，这些功能也定义了它们在整个网络架构中的角色。这
种设计使得网络设计师和架构师可以针对每层的角色来优化和选择合适的网络硬件
、软件和功能特性。分层网络模型对局域网（LAN）和广域网（WAN）设计均使用。&lt;/p&gt;

&lt;p&gt;将扁平网络划分成更小、更易管理的组成部分的好处是可以&lt;strong&gt;将本地流量限制在本地&lt;/strong&gt;（
local traffic remains local）。只有目的是其他网络的流量才会被传送到更高的层。例
如图 1-3 所示的扁平网络已经被划分为三个独立的广播域（broadcast domains）。&lt;/p&gt;

&lt;p&gt;一个典型的企业分层局域网（hierarchical LAN）包括三层：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;接入层&lt;/strong&gt;：提供工作组/用户接入网络的功能&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分发层&lt;/strong&gt;：提供基于策略的连接功能，控制接入层和核心层的边界&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;核心层&lt;/strong&gt;：提供分发层交换机之间的高速传输&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另一个三层分层网络设计如图 1-4 所示，注意其中的每个 building 都是分层网络模型
，包括了接入层、分发层和核心层。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-4.PNG&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-4 多建筑区（Multi Building）企业网络设计&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：设计网络的物理拓扑并没有绝对的规则。虽然很多网络都是基于三层的物理
设备搭建的，但这并不是强制条件。在小一些的网络中，核心层和分发层可能会合并为
一层，由同一个物理交换机充当，这样网络就变成了两层。这被称为 collapsed core
design（塌缩的核心层设计）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;1121-接入层access-layer&quot;&gt;1.1.2.1 接入层（Access Layer）&lt;/h4&gt;

&lt;p&gt;在局域网中，接入层提供终端设备接入网络的功能；在广域网中，它可能还提供远程办公（
teleworker）或远程 site 通过 WAN 访问公司网络的功能。&lt;/p&gt;

&lt;p&gt;如图 1-5 所示，小的商业网络的接入层通常由 L2 交换机和接入点构成，提供工作站和服
务器之间的互联。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-5.PNG&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-5 接入层&lt;/p&gt;

&lt;p&gt;接入层的功能包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;二层转发&lt;/li&gt;
  &lt;li&gt;高可用&lt;/li&gt;
  &lt;li&gt;端口安全（port security）&lt;/li&gt;
  &lt;li&gt;QoS 分类和标记，信任边界（trust boundaries）&lt;/li&gt;
  &lt;li&gt;ARP inspection&lt;/li&gt;
  &lt;li&gt;虚拟访问控制列表（Virtual ACL, VACL）&lt;/li&gt;
  &lt;li&gt;生成树（spanning tree）&lt;/li&gt;
  &lt;li&gt;Power over Ethernet (PoE) and auxiliary VLANs for VoIP&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;1123-分发层distribution-layer&quot;&gt;1.1.2.3 分发层（Distribution Layer）&lt;/h4&gt;

&lt;p&gt;分发层对接入层的包进行聚合（aggregate），然后送到核心层进行路由。如图 1-6
所示，&lt;strong&gt;分发层是 L2 网络（交换）和 L3 网络（路由）的边界&lt;/strong&gt;。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-6.PNG&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-6 分发层&lt;/p&gt;

&lt;p&gt;分发层设备是布线室（wiring closet）的核心（focal point）。通常使用路由器或者多层
交换机（multilayer switch）划分工作组和隔离网络问题。&lt;/p&gt;

&lt;p&gt;一个分发层交换机可能会为许多接入层交换机提供上游服务（upstream services）。&lt;/p&gt;

&lt;p&gt;分发层提供的功能：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;聚合 LAN 或 WAN 链路&lt;/li&gt;
  &lt;li&gt;基于策略的安全，通过 ACL 和 filtering 形式&lt;/li&gt;
  &lt;li&gt;LAN 和 VLAN 之间，以及路由域（例如 EIGRP 到 OSPF）之间的路由服务&lt;/li&gt;
  &lt;li&gt;冗余和负载均衡&lt;/li&gt;
  &lt;li&gt;路由聚合和摘要的边界，配置在与核心层连接的端口上&lt;/li&gt;
  &lt;li&gt;广播域控制（路由器和多层交换机不转发广播包），分发层设备充当了广播域之间的边界（demarcation）&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;1124-核心层core-layer&quot;&gt;1.1.2.4 核心层（Core Layer）&lt;/h4&gt;

&lt;p&gt;核心层也称作网络骨干（network backbone），由高速网络设备组成，例如 Cisco
Catalyst 6500 和 6800。核心层设计用来&lt;strong&gt;尽可能快地转发包，以及互联多个网络模块&lt;/strong&gt;
，例如分发模块、服务模块、数据中心，以及 WAN 边缘。&lt;/p&gt;

&lt;p&gt;从图 1-7 可以看出，核心层对分发层设备的互联非常关键（例如，将分发层连接到 WAN 和
因特网边缘）。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-7.PNG&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-7 核心层&lt;/p&gt;

&lt;p&gt;核心层应当是高可用和有冗余的。核心层对分发层设备的所有流量进行聚合，因此转
发数据的性能必须很高。&lt;/p&gt;

&lt;p&gt;核心层需要考虑：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;高速交换（例如，fast transport）&lt;/li&gt;
  &lt;li&gt;可靠性和容错&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;通过更快的而不是更多的设备进行扩展&lt;/strong&gt;（scaling by using faster, not more, equipment）&lt;/li&gt;
  &lt;li&gt;避免对包进行 CPU 密集的操作，这些操作可能来自安全、检测、QoS 分类或其他过程&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;1125-two-tier-collapsed-core-design两层塌缩核心层设计&quot;&gt;1.1.2.5 Two-Tier Collapsed Core Design（两层塌缩核心层设计）&lt;/h4&gt;

&lt;p&gt;三层分层设计最大化了性能、网络可用性、以及网络设计的扩展性。&lt;/p&gt;

&lt;p&gt;然而，很多小型企业网络并不会随着时间变的很大。因此，一种将核心层和分发层合并
的两层设计（two-tier hierarchical design）就更加实际。“collapsed core”（塌缩核心
层）就是核心层和分发层合并，由同一个设备实现其功能。这种设计的主要目的就是&lt;strong&gt;在保
留三层模型的大部分好处的同时，降低网络成本&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在图 1-8 中，核心层和分发层设备合并成一层设备，由多层交换机来充当。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/enterprise-network-design/1-8.PNG&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1-8 两级分层设计（Two-Tier Hierarchical Design）&lt;/p&gt;

&lt;p&gt;分层网络模型提供了一个模块化的框架，使得网络设计更加灵活，而且实现和排障（
trouble shooting）也更容易。&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

</description>
        
        <pubDate>Mon, 04 Mar 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/hierarchical-network-design-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/hierarchical-network-design-zh/</guid>
        
        
        <category>network</category>
        
        <category>architecture</category>
        
        <category>design</category>
        
      </item>
      
    
      
      <item>
        <title>[译] 现代网络负载均衡与代理导论</title>
        <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

&lt;p&gt;本文翻译自 Envoy 作者 Matt Klein 2017年的一篇英文博客 &lt;a href=&quot;https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236&quot;&gt;Introduction to modern
network load balancing and proxying
&lt;/a&gt;
。&lt;/p&gt;

&lt;p&gt;Service mesh 是近两年网络、容器编排和微服务领域最火热的话题之一。Envoy 是目前
service mesh 数据平面的首选组件。Matt Klein是 Envoy 的设计者和核心开发。&lt;/p&gt;

&lt;p&gt;文章循序渐进，从最简单的中间代理（middle proxy）负载均衡，逐步过渡到大型互联网公
司经典的 L4/L7 两级架构，再到包括 service mesh 在内的业界最新负载均衡实践。原文
标题虽为 “Introduction”，但“入门”这个词在今天已经被用烂了，无法显示出本文甩开其
他大部分入门系列几条街的水平，故翻译为“导论”，以内容而论，这也确实比学校的某些导
论教材强多了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下是译文。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;近期我注意到，关于现代网络负载均衡和代理的入门级教学材料非常稀少（dearth）。
我问自己：为什么会这样呢？负载均衡是构建可靠的分布式系统最核心的概念之
一。因此网上一定有高质量的相关材料？我做了大量搜索，结果发现信息确实相当稀少。
Wikipedia 上面&lt;a href=&quot;https://en.wikipedia.org/wiki/Load_balancing_%28computing%29&quot;&gt;负载均衡
&lt;/a&gt;和&lt;a href=&quot;https://en.wikipedia.org/wiki/Proxy_server&quot;&gt;代理服务器
&lt;/a&gt;词条只介绍了一些概念，但并没有深入
这些主题，尤其是和当代的微服务架构相关的部分。Google 搜索负载均衡看到的大部分都
是厂商页面，堆砌大量热门的技术词汇，而无实质细节。&lt;/p&gt;

&lt;p&gt;本文将给读者一个关于&lt;strong&gt;现代负载均衡和代理&lt;/strong&gt;的中等程度介绍，希望以此弥补这一
领域的信息缺失。诚实地说，这个主题相当庞大，足以写一整本书出来。为了使本文不至于
过长，我将努力把一些复杂问题简单化；视兴趣和反馈情况，后面我可能会通过额外的文章
单独讨论某一主题。&lt;/p&gt;

&lt;p&gt;好了，以上就是我写作本文的原因。现在让我们正式开始吧！&lt;/p&gt;

&lt;h2 id=&quot;1-网络负载均衡和代理proxy是什么&quot;&gt;1 网络负载均衡和代理（proxy）是什么？&lt;/h2&gt;

&lt;p&gt;Wikipedia 关于负载均衡的 &lt;a href=&quot;https://en.wikipedia.org/wiki/Load_balancing_%28computing%29&quot;&gt;定义&lt;/a&gt;：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In computing, load balancing improves the distribution of workloads across multiple computing resources, such as computers, a computer cluster, network links, central processing units, or disk drives. Load balancing aims to optimize resource use, maximize throughput, minimize response time, and avoid overload of any single resource. Using multiple components with load balancing instead of a single component may increase reliability and availability through redundancy. Load balancing usually involves dedicated software or hardware, such as a multilayer switch or a Domain Name System server process.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;以上定义涵盖了计算的各个方面，不单是网络。操作系统使用负载均衡在不同物理处理器上
调度任务，K8S 这样的容器编排引擎通过负载均衡在计算机集群上调度任务，网络负载均衡
器在可用的后端之间调度网络任务。本文接下来只讨论网络负载均衡。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/network-lb-overview.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 1：网络负载均衡架构图&lt;/p&gt;

&lt;p&gt;图 1 是网络负载均衡的高层架构图。若干客户端正在访问若干后端服务，它们中间是一个
负载均衡器；从高层看，负载均衡器完成以下功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;服务发现&lt;/strong&gt;：系统中的哪些后端是可用的？它们的地址是多少（例如，负责均衡器如何
和它们通信）？&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;健康检查&lt;/strong&gt;：当前哪些后端是健康的，可以接收请求？&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;：应该用什么算法将请求平衡地转发到健康的后端服务？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;负载均衡使用得当可以给分布式系统带来很多好处：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;命名抽象（Naming abstraction）&lt;/strong&gt;：客户端可以通过预设的机制访问 LB，域名解析
工作交给 LB，这样每个客户端就无需知道每个后端（服务发现）。预设的机制包括内置
库、众所周知的 DNS/IP/port，接下来会详细讨论&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;容错&lt;/strong&gt;：通过健康检查和多种算法，LB 可以将请求有效地路由到负载过高的后端
。这意味着运维人员可以从容地修复异常的后端，而不用慌张&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;成本和性能收益&lt;/strong&gt;：分布式系统的网络很少是同构的（homogeneous）。系统很可能跨
多个网络 zone （可用区）和 region（相隔较远的地理区域，这两者都是云计算术语，
有严格定义，想进一步了解请自行搜索）。在每个 zone 内部，网络的利用率相对较低
；zone 之间，利用率经常达到上限。（这里利用率的衡量公式：&lt;code class=&quot;highlighter-rouge&quot;&gt;网卡带宽/路由器
之间带宽&lt;/code&gt;）。智能负载均衡可以最大限度地将请求流量保持在 zone 内部，既提高了性
能（延迟降低），又减少了整体的系统成本（减少跨 zone 带宽及光纤成本）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;11-负载均衡器-vs-代理&quot;&gt;1.1 负载均衡器 vs 代理&lt;/h3&gt;

&lt;p&gt;在业内讨论网络负载均衡器的时候，&lt;strong&gt;负载均衡器&lt;/strong&gt;（load balancer）和&lt;strong&gt;代理&lt;/strong&gt;（proxy）两个
术语经常（大体上）无差别混用。本文中也将沿用这种惯例，认为二者整体上是对等的。
（严格地从学术角度来说，&lt;strong&gt;不是所有代理都是负载均衡器，但绝大部分代理的核心功能都包
括负载均衡&lt;/strong&gt;。）&lt;/p&gt;

&lt;p&gt;有人可能会说，当负载均衡内嵌到客户端库作为库的一部分的时候，负载均衡器并不是一
个代理。对此我的意见是，这种区分只是给本已令人困惑的主题又增加了不必要的复杂性。
本文后面会讨论负载均衡器拓扑的类型，其中将把嵌入式负载均衡器拓扑作为一种特殊的代
理；应用通过内嵌的库进行代理转发，这个库提供的抽象和一个位于应用进程之外的
负载均衡器是一样的。&lt;/p&gt;

&lt;h3 id=&quot;12-l4会话连接层负载均衡&quot;&gt;1.2 L4（会话/连接层）负载均衡&lt;/h3&gt;

&lt;p&gt;现在，当业内讨论负载均衡的时候，所有解决方案通常分为两类：L4 和 L7。这
两者分别对应 &lt;a href=&quot;https://en.wikipedia.org/wiki/OSI_model&quot;&gt;OSI 模型&lt;/a&gt;的 4 层和 7 层。
不过我认为使用这个术语相当不幸，在后面讨论 L7 负载均衡的时候会明显看到这一点。
OSI 模型是一个很差的对负载均衡解决方案复杂度的近似，这些解决方案包含 4 层协议，例
如 TCP 和 UDP，但经常又包括一些 OSI 其他协议层的内容。比如，如果一个 L4 TCP LB
同时支持 TLS termination，那它现在是不是一个 L7 LB？&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/l4-termination-lb.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 2：TCP L4 termination 负载均衡&lt;/p&gt;

&lt;p&gt;图 2 是传统的 L4
&lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&quot;&gt;TCP&lt;/a&gt; 负载均衡器。
这种情况下，客户端建立一个 TCP 连接到 LB。LB &lt;strong&gt;终止&lt;/strong&gt;（terminate）这个连接（例如
，立即应答 SYN 包），选择一个后端，然后建立一个新的 TCP 连接到后端（例如，发送一
个新的 SYN 包）。不要太在意图中的细节，我们在后面章节会专门讨论 L4 负载均衡。&lt;/p&gt;

&lt;p&gt;本节想说明的是，典型情况下，L4 负载均衡器只工作在 L4 TCP/UDP connection/session
。因此，LB 在双向来回转发字节，保证属于同一 session 的字节永远落到同一后端。L4
LB 不感知其转发字节所属应用的任何细节。这些字节可能是 HTTP、Redis、MongoDB，或者
任何其他应用层协议。&lt;/p&gt;

&lt;h3 id=&quot;13-l7应用层负载均衡&quot;&gt;1.3 L7（应用层）负载均衡&lt;/h3&gt;

&lt;p&gt;L4 负载均衡很简单，应用范围也很广。那么，相比于 L7 （应用层）负载均衡，L4 有哪些
缺点？设想如下 L4 特殊场景：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;两个 &lt;a href=&quot;https://en.wikipedia.org/wiki/HTTP/2&quot;&gt;gRPC/HTTP2&lt;/a&gt; 客户端想连接到后端，因此它们通过 L4 LB 建立连接&lt;/li&gt;
  &lt;li&gt;L4 LB 为每个（从客户端）进来的连接建立一个出去的（到后端）的连接，因此
最终由两个进来的连接和两个出去的连接&lt;/li&gt;
  &lt;li&gt;客户端 A 的连接每分钟发送 1 个请求，而客户端 B 的连接每秒发送 50 个请求&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在以上场景中，&lt;strong&gt;选中的处理客户端 A 请求的后端比选中的处理客户端 B 请求的后端，负
载要相差 &lt;code class=&quot;highlighter-rouge&quot;&gt;3000x&lt;/code&gt; 倍。这个问题非常严重，与负载均衡的目的背道而驰&lt;/strong&gt;。而且要注意，
对任何 &lt;strong&gt;&lt;em&gt;multiplexing，kept-alive&lt;/em&gt;&lt;/strong&gt; （多路复用，保活）协议，都存在这个问题。（
Multiplexing 表示通过单个 L4 连接发送并发应用的请求，kept-alive 表示当没有主动的
请求时也不要关闭连接）。出于性能考虑（创建连接的开销是非常大的，尤其是连接是使用
TLS 加密的时候），所有现代协议都在演进以支持 multiplexing 和 kept-alive，因此 L4
LB 的阻抗不匹配问题（impedance mismatch）随时间越来越彰显。这个问题被 L7 LB 解决
了。&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/l7-termination-lb.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 3：HTTP/2 L7 负载均衡&lt;/p&gt;

&lt;p&gt;图 3 是一个 L7 HTTP/2 负载均衡器。这种情况下，客户端与 LB 只建立一个 HTTP /2 TCP
连接。LB 接下来和&lt;strong&gt;两个&lt;/strong&gt;后端建立连接。当客户端向 LB 发送两个 HTTP/2 流（streams
）时，stream 1 会被发送到后端 1，而stream 2 会被发送到后端 2。因此，即使不同客户
端的请求数量差异巨大，这些请求也可以被高效地、平衡地分发到后端。这就是 L7 LB 对
现代协议如此重要的原因。L7 负载均衡具备检测应用层流量的能力，这带来了大量额外的
好处，我们后面会更详细看到。&lt;/p&gt;

&lt;h3 id=&quot;14-l7-负载均衡和-osi-7-层模型&quot;&gt;1.4 L7 负载均衡和 OSI 7 层模型&lt;/h3&gt;

&lt;p&gt;前面讨论 L4 负载均衡时我说过，使用 OSI 模型描述负载均衡特性是有问题的。原因是，
对于 L7，至少按照 OSI 模型的描述，它本身就包括了负载均衡抽象的多个独立层级（
discrete layers），例如，对于 HTTP 流量考虑如下子层级：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可选的 TLS （Transport Layer Security）层。网络领域的人们还在争论 TLS 到底属于
OSI 的哪一层。本文出于讨论目的将假设它属于 L7&lt;/li&gt;
  &lt;li&gt;物理 HTTP 协议（HTTP/1 或者 HTTP/2）&lt;/li&gt;
  &lt;li&gt;逻辑 HTTP 协议（headers, body data, trailers）&lt;/li&gt;
  &lt;li&gt;消息协议（gRPC, REST 等等）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个复杂的 L7 LB 可能会提供与以上全部子层级相关的特性，而另一个 L7 LB可能会认为
其中只有一部分才属于 7 层的功能，因此只提供这个子集的功能。也就是说，如果要比较
负载均衡器的特性（features），L7 的范围比 L4 的复杂的多。（当然，这里我们只涉及
了 HTTP；Redis、Kafka、MongoDB等等都是 L7 LB 应用层协议的例子，它们都受益于 7 层
负载均衡。）&lt;/p&gt;

&lt;h2 id=&quot;2-负载均衡器特性&quot;&gt;2 负载均衡器特性&lt;/h2&gt;

&lt;p&gt;本节将简要总结负载均衡器提供的高层特性（high level features）。但并不是所有负载
均衡器都提供这里的所有特性。&lt;/p&gt;

&lt;h3 id=&quot;21-服务发现&quot;&gt;2.1 服务发现&lt;/h3&gt;

&lt;p&gt;服务发现是负载均衡器判断它有哪些可用后端的过程。用到的方式差异很大，这里给出几个
例子：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;静态配置文件&lt;/li&gt;
  &lt;li&gt;DNS&lt;/li&gt;
  &lt;li&gt;Zookeeper, Etcd, Consul 等待&lt;/li&gt;
  &lt;li&gt;Envoy 的通用数据平面 API（&lt;a href=&quot;https://medium.com/@mattklein123/the-universal-data-plane-api-d15cec7a&quot;&gt;universal data plane API&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;22-健康检查&quot;&gt;2.2 健康检查&lt;/h3&gt;

&lt;p&gt;健康检查是负载均衡器判断它的后端是否可以接收请求的过程。大致分为两类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主动：LB 定时向后端发送 ping 消息（例如，向 &lt;code class=&quot;highlighter-rouge&quot;&gt;/healthcheck&lt;/code&gt; 发送 HTTP 请求），
以此测量后端健康状态&lt;/li&gt;
  &lt;li&gt;被动：LB 从数据流中检测健康状态。例如，L4 LB 可能会认为如果一个后端有三次连接
错误，它就是不健康的；L7 LB 可能会认为如果后端有 503 错误码就是不健康的&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;23-负载均衡&quot;&gt;2.3 负载均衡&lt;/h3&gt;

&lt;p&gt;LB 必须保证负载是均衡的。给定一组健康的后端，如何选择哪个后端来处理一个连接或一
个请求呢？负载均衡算法是一个相对活跃的研究领域，从简单的随机选择、Round Robin，
到更复杂的考虑各种延迟和后端负载状态的算法。最流行的负载均衡算法之一是&lt;a href=&quot;https://brooker.co.za/blog/2012/01/17/two-random.html&quot;&gt;幂次最少
请求&lt;/a&gt;（power of 2 least
request）负载均衡。&lt;/p&gt;

&lt;h3 id=&quot;24-sticky-session黏性会话&quot;&gt;2.4 Sticky Session（黏性会话）&lt;/h3&gt;

&lt;p&gt;对于一些特定应用，保证属于同一 session 的请求落到同一后端非常重要。这可能需要考
虑缓存、结构复杂的临时状态等问题。session 的定义也并不相同，可能会包括 HTTP
cookies、客户端连接特性（properties），或者其他一些属性。一些 L7 LB 支持 sticky
session。但这里我要说明的是，session stickiness 本质上是脆弱的（处理/保持
session 的后端会挂掉），因此如果设计的系统依赖这个特性，那要额外小心。&lt;/p&gt;

&lt;h3 id=&quot;25-tls-termination&quot;&gt;2.5 TLS Termination&lt;/h3&gt;

&lt;p&gt;关于 TLS 以及它在边缘服务（edge serving）和安全的 service-to-service通信中扮演的
角色，值得单独写一篇文章，因此这里不详细展开。许多 L7 LB 会做大量的 TLS 处理工作
，包括 termination、证书验证和绑定（verification and pinning）、使用
&lt;a href=&quot;https://en.wikipedia.org/wiki/Server_Name_Indication&quot;&gt;SNI&lt;/a&gt; 提供证书服务等等。&lt;/p&gt;

&lt;h3 id=&quot;26-可观测性observability&quot;&gt;2.6 可观测性（observability）&lt;/h3&gt;

&lt;p&gt;我在技术分享中喜欢说：“可观测性、可观测性、可观测性。”网络在本质上是不可靠的，LB
通常需要导出统计、跟踪和日志信息，以帮助运维判断出了什么问题并修复它。负载均衡器
输出的可观测性数据差异很大。最高级的负载均衡器提供丰富的输出，包括数值统计、分布
式跟踪以及自定义日志。需要指出的是，丰富的可观测数据并不是没有代价的，负载均衡器
需要做一些额外的工作才能产生这些数据。但是，这些数据带来的收益要远远大于为产生它
们而增加的那点性能损失。&lt;/p&gt;

&lt;h3 id=&quot;27-安全和-dos-防御&quot;&gt;2.7 安全和 DoS 防御&lt;/h3&gt;

&lt;p&gt;至少（尤其）在边缘部署拓扑（下面会看到）情况下，负载均衡器通常需要实现很多安全特
性，包括限速、鉴权和 DoS 防御（例如，给 IP 地址打标签及分配标识符、
&lt;a href=&quot;https://en.wikipedia.org/wiki/Tarpit_%28networking%29&quot;&gt;tarpitting&lt;/a&gt;等等）。&lt;/p&gt;

&lt;h3 id=&quot;28-配置和控制平面&quot;&gt;2.8 配置和控制平面&lt;/h3&gt;

&lt;p&gt;负载均衡器要可以配置。在大型部署场景中，这可能是一项很大的工作。一般地，将配
置负载均衡器的系统称为“控制平面”，其实现方式各异。想了解更多关于这一方面的信息，
可以参考我之前关于 service mesh 数据平面和控制平面的&lt;a href=&quot;https://medium.com/@mattklein123/service-mesh-data-plane-vs-control-plane-2774e720f7fc&quot;&gt;博客&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;29-其他更多特性&quot;&gt;2.9 其他更多特性&lt;/h3&gt;

&lt;p&gt;本节对负载均衡器提供的功能做了一个非常浅的介绍。更多内容我们会在下面讨论 L7 LB
的时候看到。&lt;/p&gt;

&lt;h2 id=&quot;3-负载均衡器的拓扑类型&quot;&gt;3 负载均衡器的拓扑类型&lt;/h2&gt;

&lt;p&gt;前面我们已经覆盖了负载均衡器的高层概览，L4 和 L7 负载均衡器的区别，以及负载均衡
器的功能特性等内容，接下来介绍它的分布式部署拓扑（下面介绍的每种拓扑都适用于 L4
和 L7 负载均衡器）。&lt;/p&gt;

&lt;h3 id=&quot;31-中间代理middle-proxy&quot;&gt;3.1 中间代理（middle proxy）&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/middle-proxy-lb.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 4：中间代理负载均衡拓扑&lt;/p&gt;

&lt;p&gt;图 4 所示的中间代理拓扑应该是大家最熟悉的负载均衡方式。这一类型的方案包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;硬件设备：Cisco、Juniper、F5 等公司的产品&lt;/li&gt;
  &lt;li&gt;云软件解决方案：Amazon 的 &lt;a href=&quot;https://aws.amazon.com/elasticloadbalancing/&quot;&gt;ALB 和
NLB&lt;/a&gt;，Google 的 &lt;a href=&quot;https://cloud.google.com/load-balancing/&quot;&gt;Cloud Load
Balancer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;纯软件方案：&lt;a href=&quot;https://www.haproxy.com/&quot;&gt;HAProxy&lt;/a&gt;、
&lt;a href=&quot;https://www.nginx.com/&quot;&gt;NGINX&lt;/a&gt;、&lt;a href=&quot;https://www.envoyproxy.io/&quot;&gt;Envoy&lt;/a&gt; 等等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;中间代理模式的优点是简单，用户一般只需要通过 DNS 连接到 LB，其他的事情就
不用关心了。&lt;strong&gt;缺点是，这种模式下负载均衡器（即使已经做了集群）是单点的（single
point of failure），而且横向扩展有瓶颈&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;中间代理很多情况下都是一个黑盒子，给运维带来很多困难。例如发生故障的时候，很难判
断问题是出在客户端，中间代理，还是后端。&lt;/p&gt;

&lt;h3 id=&quot;32-边缘代理edge-proxy&quot;&gt;3.2 边缘代理（edge proxy）&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/edge-proxy-lb.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 5：边缘代理负载均衡拓扑&lt;/p&gt;

&lt;p&gt;图 5 所示的边缘代理拓扑其实只是中间代理拓扑的一个变种，这种情况下负载均衡器是可
以从因特网直接访问的。这种场景下，负载均衡器通常还要提供额外的 “API 网关”功能，
例如 TLS termination、限速、鉴权，以及复杂的流量路由等等。&lt;/p&gt;

&lt;p&gt;中间代理拓扑的优缺点对边缘代理也是适用的。需要说明的是，&lt;strong&gt;对于面向因特网的分布式系
统，部署边缘代理通常是无法避免的&lt;/strong&gt;。客户端一般通过 DNS 访问系统，而它使用什么网
络库，服务方是控制不了的（下文会看到的客户端内嵌库或 sidecar 代理拓扑在此不适用）。
另外，从安全的角度考虑，所有来自因特网的流量都通过唯一的网关进入系统是比较好的。&lt;/p&gt;

&lt;h3 id=&quot;33-客户端内嵌库embedded-client-library&quot;&gt;3.3 客户端内嵌库（embedded client library）&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/lb-via-client-lib.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 6：客户端内嵌库实现负载均衡&lt;/p&gt;

&lt;p&gt;为了解决中间代理拓扑固有的单点和扩展问题，出现了一些更复杂的方案，例如将负载均衡
器已函数库的形式内嵌到客户端，如图 6 所示。这些库支持的特性差异非常大，最知名的
库包括 &lt;a href=&quot;https://twitter.github.io/finagle/&quot;&gt;Finagle&lt;/a&gt;、
&lt;a href=&quot;https://netflix.github.io/&quot;&gt;Eureka/Ribbon/Hystrix&lt;/a&gt;、&lt;a href=&quot;https://grpc.io/&quot;&gt;gRPC&lt;/a&gt;（
大致基于一个 Google 内部系统 Stubby）。&lt;/p&gt;

&lt;p&gt;这种拓扑的最大优点是：&lt;strong&gt;将 LB 的全部功能下放到每个客户端，从而完全避免了单点
和扩展问题&lt;/strong&gt;。缺点是：&lt;strong&gt;必须为公司使用的每种语言实现相应的库&lt;/strong&gt;。分布式架构正在变
得越来越 “polyglot”（multilingual，多语言化）。在这种情况下，为多种语言实现一个
复杂的网络库是非常难的（prohibitive）。最后，对大型服务架构，进行客户端升级也是
一件极其痛苦的事情，最终很可能导致生产集群中同时运行多个版本的客户端，增加
运维和认知（cognitive）负担。&lt;/p&gt;

&lt;p&gt;虽然如此，但是那些在能够限制语言数量增加（proliferation）而且能够解决客户端升级
痛苦的公司，这种拓扑还是取得了成功的。&lt;/p&gt;

&lt;h3 id=&quot;34-sidecar-代理&quot;&gt;3.4 sidecar 代理&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/lb-via-sidecar.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 7：sidecar 代理实现负载均衡&lt;/p&gt;

&lt;p&gt;客户端内嵌库拓扑的一个变种是 sidecar 拓扑，如图 7 所示。近年来这种拓扑非常流行，
被称为服务网格（service mesh）。sidecar 代理模式背后的思想是：&lt;strong&gt;通过将流量导到其
他进程的方式，牺牲一点（延迟）性能，实现客户端内嵌库模式的所有好处，而无任何语言
绑定&lt;/strong&gt;（language lock-in）。写作本文时，最流行的 sidecar 代理有
&lt;a href=&quot;https://www.envoyproxy.io/&quot;&gt;Envoy&lt;/a&gt;、&lt;a href=&quot;https://www.nginx.com/&quot;&gt;NGINX&lt;/a&gt;、
&lt;a href=&quot;https://www.haproxy.com/&quot;&gt;HAProxy&lt;/a&gt;、&lt;a href=&quot;https://linkerd.io/&quot;&gt;Linkerd&lt;/a&gt;。
想了解 sidercar 模式负载均衡的更多信息，请查看我之前&lt;a href=&quot;https://eng.lyft.com/announcing-envoy-c-l7-proxy-and-communication-bus-92520b6c8191&quot;&gt;介绍 Envoy 的博客
&lt;/a&gt;，以及
&lt;a href=&quot;https://medium.com/@mattklein123/service-mesh-data-plane-vs-control-plane-2774e720f7fc&quot;&gt;service mesh 数据平面 vs 控制平面的博客
&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;35-不同拓扑类型的优缺点比较&quot;&gt;3.5 不同拓扑类型的优缺点比较&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;中间代理拓扑是最简单的负载均衡方式，缺点是单点故障、扩展性问题、以及黑盒运维&lt;/li&gt;
  &lt;li&gt;边缘代理拓扑和中间代理拓扑类似，但一些场景必须得用这种模式&lt;/li&gt;
  &lt;li&gt;客户端内嵌库拓扑提供了最优的性能和扩展性，但必须为每种语言实现相应的库，并且升
级非常痛苦&lt;/li&gt;
  &lt;li&gt;sidecar 代理拓扑性能不如客户端内嵌库好，但没有后者的那些缺点&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体上我认为在 service-to-service 通信中， sidecar （service mesh）正在逐渐取代
其他所有拓扑类型。另外，在流量进入 service mesh 的地方，总是需要一个边缘代理拓扑
负载均衡器。&lt;/p&gt;

&lt;h2 id=&quot;4-当前-l4-负载均衡最新技术-state-of-the-art&quot;&gt;4 当前 L4 负载均衡最新技术 （state of the art）&lt;/h2&gt;

&lt;h3 id=&quot;41-l4-负载均衡还有用吗&quot;&gt;4.1 L4 负载均衡还有用吗？&lt;/h3&gt;

&lt;p&gt;我们前面已经解释了为什么 L7 负载均衡器对现代协议如此重要，接下来详细讨论 L7 LB的
功能特性。这是否意味着 L4 LB 没用了？不！虽然我认为在service-to-service 通信中L7
负载均衡最终会完全取代 L4 负载均衡，但 L4 负载均衡在边缘仍然是非常有用的，因为几
乎所有的现代大型分布式架构都是&lt;strong&gt;在因特网流量接入处使用 L4/L7 两级负载均衡架构&lt;/strong&gt;。
在边缘 L7 负载均衡器之前部署 L4 负载均衡器的原因：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;L7 LB 承担的更多工作是复杂的分析、变换、以及应用流量路由，他们处理原始流量的能
力（按每秒处理的包数和字节数衡量）比经过优化的 L4 负载均衡器要差。这使得L4 LB
更适合处理特定类型的攻击，例如 SYN 泛洪、通用包（generic packet）泛洪攻击等&lt;/li&gt;
  &lt;li&gt;L7 LB 部署的更多更频繁，bug 也比 L4 LB 多。在 L7 之前加一层 L4 LB，可以在调整
L7 部署的时候，对其做健康检查和流量排除（drain），这比（单纯使用）现代 L4 LB
要简单的多，后者通常使用 BGP 和 ECMP（后面会介绍）。最后，因为 L7 功能更复杂，
它们的 bug 也会比 L4 多，在前面有一层 L4 LB 能及时将有问题的 L7 LB 拉出&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接下来的几节我将介绍中间/边缘代理 L4 LB 的几种不同设计。这些设计通常不适用于客户
端内嵌库和 sidecar 代理拓扑模式。&lt;/p&gt;

&lt;h3 id=&quot;42-tcpudp-termination-负载均衡&quot;&gt;4.2 TCP/UDP termination 负载均衡&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/l4-termination-lb.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 8：TCP L4 termination 负载均衡&lt;/p&gt;

&lt;p&gt;第一种现在仍在用的 L4 LB 是 termination LB，如图 8 所示。这和我们最
开始介绍 L4 负载均衡器时看到的图是一样的（图 2）。这种模式中，会使用两个独立的
TCP 连接：一个用于客户端和负载均衡器之间，一个用于负载均衡器和后端之间。&lt;/p&gt;

&lt;p&gt;L4 负载均衡器仍然在用有两个原因：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;他们实现相对简单&lt;/li&gt;
  &lt;li&gt;连接 terminate 的地方离客户端越近，客户端的性能（延迟）越好。特别地，如果在一
个有丢包的网络（lossy network，例如蜂窝网）中将 termination LB 部署的离客户端
很近，重传可能就会更快的发生（retransmits are likely to happen  faster prior
to the data being moved to reliable fiber transit en-route to its ultimate
location）。换句话说，这种负载均衡方式可能会用于入网点（POP，Point of
Presence）的raw TCP connection termination&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;43-tcpudp-passthrough-负载均衡&quot;&gt;4.3 TCP/UDP passthrough 负载均衡&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/l4-passthrough-lb.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 9：TCP passthrough 负载均衡&lt;/p&gt;

&lt;p&gt;第二种 L4 负载均衡是 passthrough，如图 9 所示。在这种类型中，TCP 连接不会被负载
均衡器 terminate，而是在建立连接跟踪和网络地址转换（NAT）之后直接转发给选中的后
端。我们首先来定义连接跟踪和 NAT：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;连接跟踪&lt;/strong&gt;（connection tracking）：跟踪所有活动的 TCP 连接的状态的过程。这包
括握手是否成功、是否收到 FIN 包、连接已经空闲多久、为当前连接选择哪个后端等&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NAT&lt;/strong&gt;：利用连接跟踪的数据，在包经过负载均衡器时修改包的 IP/port 信息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用连接跟踪和 NAT 技术，负载均衡器可以将大部分 raw TCP 流量从客户端转发到后端。
例如，我们假设客户端正在和负载均衡器 &lt;code class=&quot;highlighter-rouge&quot;&gt;1.2.3.4:80&lt;/code&gt; 通信，选中的后端是
&lt;code class=&quot;highlighter-rouge&quot;&gt;10.0.0.2:9000&lt;/code&gt;。当客户端的 TCP 包到达负载均衡器时，负载均衡器会将包的目的
IP/port （从 &lt;code class=&quot;highlighter-rouge&quot;&gt;1.2.3.4:80&lt;/code&gt;）换成 &lt;code class=&quot;highlighter-rouge&quot;&gt;10.0.0.2:9000&lt;/code&gt;，以及将源 IP/port 换成负载均衡器
自己的 IP/port。当应答包回来的时候，负载均衡器再做相反的转换。&lt;/p&gt;

&lt;p&gt;为什么这种比 terminating LB 更复杂的 LB 类型，会在某些场景中替换前者使用呢？几点原因：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;性能和资源消耗&lt;/strong&gt;：passthrough LB 不会 terminate TCP 连接，因此无需缓存任何
TCP 连接窗口。每个连接的状态数据非常小，通常可以通过哈希表直接查询。因此，
passthrough LB 的性能（packets per second，PPS，每秒处理的包数）要比 terminating
LB 高很多&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;允许后端进行自主拥塞控制&lt;/strong&gt;：&lt;a href=&quot;https://en.wikipedia.org/wiki/TCP_congestion_control&quot;&gt;TCP 拥塞控制
&lt;/a&gt; 是一种避免发送太快导致
超过网络带宽或缓冲区的机制。passthrough LB 不 terminate TCP 连接，因此它不参与
拥塞控制。这使得后端可以根据应用的类型自主决定采用哪种拥塞控制算法。而且，这种
方式还使得验证拥塞控制的改动更容易（例如，最近的
&lt;a href=&quot;https://queue.acm.org/detail.cfm?id=3022184&quot;&gt;BBR&lt;/a&gt; rollout）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;是 Direct server return (DSR) 和 L4 LB 集群化的基础&lt;/strong&gt;：很多高级的 L4 负载
均衡技术基于 passthrough LB，例如 DSR 和一致性哈希集群（下面讨论）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;44-dsr直接服务器返回&quot;&gt;4.4 DSR（直接服务器返回）&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/l4-dsr.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 10：L4 Direct server return (DSR，直接服务器返回）&lt;/p&gt;

&lt;p&gt;DSR LB 如图 10 所示，它基于 passthrough LB，对后者的改进之处是：只允许进来的流量
/请求（ingress/request）经过 LB，而出去的流量/响应（egress/response）直接
从服务器返回到客户端。&lt;/p&gt;

&lt;p&gt;设计 DSR 的主要原因是：&lt;strong&gt;在一些场景中，响应的流量要远远大于请求的流量&lt;/strong&gt;（例如典
型的 HTTP request/response 模式）。假设请求占 10% 的流量，响应占 90%，使用 DSR
技术，只需 1/10 的带宽就可以满足系统需求。因为&lt;strong&gt;早期的负载均衡器非常昂贵&lt;/strong&gt;，这种
类型的优化可以极大地节省成本，还提高了负载均衡器的可靠性（流量越低肯定越好）。
DSR 在如下方面扩展了 passthrough LB：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LB 仍然做一部分连接跟踪工作。因为响应不再经过 LB，LB 无法知道 TCP 连接
的完整状态。但是，它仍然可以根据客户端的包以及多种类型的 idle timeout，（
strongly）推测连接的状态&lt;/li&gt;
  &lt;li&gt;与 NAT 不同，负载均衡器通常使用 GRE（Generic Routing Encapsulation）将 IP 包封
装发送到后端。后端收到后进行解封装，就可以拿到原始的 IP 包，里面有客户端的 IP
和 port 信息。因此后端可以直接将应答包发给客户端，而需要经过 LB&lt;/li&gt;
  &lt;li&gt;DSR 非常的重要一点是：&lt;strong&gt;后端参与负载均衡过程&lt;/strong&gt;。后端需要配置正确的 GRE 隧道，
视网络设置的底层细节，GRE 可能还需要自己的连接跟踪和 NAT&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注意，不管是在 passthrough 还是 DSR 设计中，负载均衡器和后端之间的连接跟踪、NAT
、GRE等等都有多种设置方式。但不幸的是这个话题超出本文的讨论范围。&lt;/p&gt;

&lt;h3 id=&quot;45-通过-ha-pair-实现容错&quot;&gt;4.5 通过 HA pair 实现容错&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/l4-fault-tolerance-via-ha.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 11：通过 HA pair 和 连接跟踪实现 L4 容错&lt;/p&gt;

&lt;p&gt;到目前为止，我们讨论的都是单个 L4 LB。passthrough 和 DSR都需要 LB保存一些连接跟
踪的状态。假如 LB 挂了呢？如果一个 LB实例挂了，那所有经过这个 LB 的连接都
会受到影响。视应用的不同，这可能会对应用性能产生很大影响。&lt;/p&gt;

&lt;p&gt;历史上，L4 负载均衡器是从一些厂商（Cisco、Juniper、F5等等）购买的硬件设备，这些
设备非常昂贵，可以处理大量的网络流量。为了避免单个负载均衡器挂掉导致应用不可用，
负载均衡器通常都是以高可用对（high availability pair）方式部署的，如图 11 所示。
典型的 HA 负载均衡器设置包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一对 HA 边缘路由器提供若干虚拟 IP（virtual IP，VIP），并通过 BGP (Border
Gateway Protocol) 协议通告 VIP。主（primary）边缘路由器的 BGP 权重比备（backup
）边缘路由器的高，在正常情况下处理所有流量。（BGP 是一个非常复杂的协议，出于本
文讨论目的，可以认为 BGP就是一种对外宣告哪个网络设备配置了哪个 IP 的机制，每个
设备有一个表示处理网络流量的权重）&lt;/li&gt;
  &lt;li&gt;类似地，primary L4 LB 向边缘路由器宣告它的权重比 backup LB大，因此正常情况下它
处理所有流量&lt;/li&gt;
  &lt;li&gt;primary LB 交叉连接（cross-connected）到 backup LB，共享所有的连接跟踪状态。因
此，假如 primary LB 挂了，backup LB 可以马上接管所有活动连接&lt;/li&gt;
  &lt;li&gt;两个边缘路由器和两个负载均衡器都是交叉连接的。这意味着，如果一个边缘路由器或一
个负载均衡器挂了，或者由于某种原因之前声明的 BGP 权重收回了（withdraw），
backup 马上可以接受所有流量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上就是许多大流量因特网应用今天仍然在使用的架构。然而，以上架构也有很大的不足：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;VIP 需要做容量规划，并正确 sharding 给两个负载均衡器实例。如果一个 VIP （的连
接数？）增长超过了单个 HA pair 的容量，那这个 VIP 需要分裂成多个 VIP&lt;/li&gt;
  &lt;li&gt;资源利用率很低，平稳状态下 50% 的容量是空闲的。考虑到有史以来硬件负载均衡器都
是非常昂贵的，这意味着大量的资金没有得到有效利用&lt;/li&gt;
  &lt;li&gt;现代分布式系统设计追求比 active/backup 更高的容错（fault tolerance）性。例如，
理想情况下，一个系统有多个实例同时挂掉仍能继续运行。而 HA LB pair 的主备实例同
时挂掉时，服务就彻底挂了&lt;/li&gt;
  &lt;li&gt;供应商提供的专有大型硬件设备非常昂贵，导致用户被锁死到厂商（vendor
lock-in，即买了某个厂商的设备后，后期只能继续买这个厂商的设备或服务）。通常期
望的是，可以用基于通用服务器的、水平扩展性良好的纯软件方案代替这些硬件设备&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;46-基于集群和一致性哈希的容错和可扩展&quot;&gt;4.6 基于集群和一致性哈希的容错和可扩展&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/l4-fault-tolerance-and-scaling-via-cluster.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 12：基于负载均衡器集群和一致性哈希实现 L4 容错和可扩展&lt;/p&gt;

&lt;p&gt;前一节介绍了通过 HA pair 实现 L4 LB 的容错，以及这种设计固有的问题。从 2000s 初
期到中期，大型因特性基础设施（公司）开始设计和部署全新的大规模并行 L4 负载均衡系
统，如图 12所示。这些系统的设计目标是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;避免 HA pair 设计的所有缺点&lt;/li&gt;
  &lt;li&gt;从厂商的商业硬件方案，迁移到基于标准服务器和网卡的通用软件方案&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这种 L4 LB 设计最合适的名称是&lt;strong&gt;基于集群化和一致性哈希的容错和可扩展&lt;/strong&gt;（
fault tolerance and scaling via clustering and distributed consistent hashing）。
它的工作原理如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;N 个边缘路由器以相同的 BGP 权重通告所有
&lt;a href=&quot;https://en.wikipedia.org/wiki/Anycast&quot;&gt;Anycast&lt;/a&gt; VIP。通过 ECMP（Equal-cost,
Multi-path routing）保证每个 flow 的所有包都会到达同一个边缘路由器。一个 flow
通常是 4 元组：源 IP/port 和目的 IP/port。&lt;strong&gt;简单来说，ECMP 是一种通过一致性哈
希将包分发到一组权重相同的网络设备的方式&lt;/strong&gt;。虽然边缘路由器通常并不关心每个包要
发往哪里，但一般都是希望同一 flow 的所有包都以相同路径经过各个设备，因为这可以
避免乱序代理的性能下降&lt;/li&gt;
  &lt;li&gt;N 个 L4 LB 以相同的 BGP 权重向所有的边缘路由器通告所有的 VIP。仍然使用
ECMP，边缘路由器会为相同 flow 的包选择相同的 LB&lt;/li&gt;
  &lt;li&gt;每个 L4 LB 实例会做部分连接跟踪（partial connection tracking）工作，然后使用&lt;a href=&quot;https://en.wikipedia.org/wiki/Consistent_hashing&quot;&gt;
一致性哈希&lt;/a&gt;为每个 flow 选择
一个后端。通过 GRE 封装将包从 LB 发送到后端&lt;/li&gt;
  &lt;li&gt;然后使用 DSR 将应答包从后端直接发送到边缘路由器，最后到客户端&lt;/li&gt;
  &lt;li&gt;L4 LB 用到的一致性哈希算法是一个热门的研究领域。需要在平衡负载、最小化延迟、最
小化后端变化带来的扰动、最小化内存开销等等之间做取舍。关于这一话题的完整讨论超
出了本篇的范围&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们来看看以上的设计是如何避免了 HA pair 的不足的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;边缘路由器和负载均衡器实例可以按需添加。每一层都用到了 ECMP，当新实例加入的时
候，ECMP 能最大程度地减少受影响的 flow 数量&lt;/li&gt;
  &lt;li&gt;在预留足够的突发量（burst margin）和容错的前提下，系统的资源利用率想达到多高就
可以到多高&lt;/li&gt;
  &lt;li&gt;边缘路由器和负载均衡器都可以基于通用硬件搭建，成本只是传统硬件 LB 的很小
一部分（后面有更多信息）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;很多读者可能会问：“为什么不让边缘路由器通过 ECMP 直接和后端通信？为什么我们还需
要这一层负载均衡器？”这样做主要的原因是&lt;strong&gt;防止 DoS 攻击，以及方便后端的运维。没
有这一层负载均衡，后端就得直接参与 BGP，当对后端集群进行滚动（rolling）部署时受
影响程度会大很多&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;所有现代 L4 负载均衡系统都在朝着这种设计（或其变种）演进。其中最有名的两个分别是
来自Google 的 &lt;a href=&quot;https://research.google.com/pubs/pub44824.html&quot;&gt;Maglev&lt;/a&gt; 和来自
Amazon的 &lt;a href=&quot;http://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html&quot;&gt;Network Load
Balancer&lt;/a&gt;
。基于这种设计的开源方案目前还没有，但据我所知，有一家公司准备在 2018 年开源他们
的产品。对此我非常兴奋，因为现代 L4 LB 是网络领域的开源产品中仍然缺失的重要部分
。&lt;/p&gt;

&lt;h2 id=&quot;5-当前-l7-负载均衡最新技术-state-of-the-art&quot;&gt;5 当前 L7 负载均衡最新技术 （state of the art）&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/twt-1.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;是的，的确如此。过去几年见证了 L7 负载均衡器/代理的一阵复兴（resurgence）浪潮，
这紧跟了分布式系统微服务化的发展趋势。本质上，当使用更加频繁时，天生有损的网络（
inherently faulty network）越来越难以有效运维。而且，自动扩缩容（auto scaling）
、容器调度器等技术的崛起，意味着通过静态文件配置静态 IP 的方式早就过时了。系统不
仅使用网络更加频繁，而且使用的方式越来越动态，需要负载均衡器提供更多的功能。本节
我将简要现代 L7 负载均衡器发展最快的几个领域。&lt;/p&gt;

&lt;h3 id=&quot;51-协议支持&quot;&gt;5.1 协议支持&lt;/h3&gt;

&lt;p&gt;现代 L7 负载均衡器正在显示地添加对更多协议的支持。负载均衡器对应用层协议了解的越
多，就可以处理越多更复杂的事情，包括观测输出、高级负载均衡和路由等等。例如，在写
作本文时，Envoy 显式支持如下 L7 协议的解析和路由：HTTP/1、HTTP/2、gRPC、Redis、
MongoDB、DynamoDB。未来可能会添加包括 MySQL 和 Kafka 在内的更多协议。&lt;/p&gt;

&lt;h3 id=&quot;52-动态配置&quot;&gt;5.2 动态配置&lt;/h3&gt;

&lt;p&gt;如前面描述的，分布式系统越来越动态的本质需要同时在两方面做投资：动态和响应式控制
。&lt;a href=&quot;https://istio.io/&quot;&gt;Istio&lt;/a&gt; 即使这种系统的一个例子。更多信息请查看我之前的
&lt;a href=&quot;https://medium.com/@mattklein123/service-mesh-data-plane-vs-control-plane-2774e720f7fc&quot;&gt;service mesh 数据平面 vs 控制平面的博客
&lt;/a&gt;
。&lt;/p&gt;

&lt;h3 id=&quot;53-高级负载均衡&quot;&gt;5.3 高级负载均衡&lt;/h3&gt;

&lt;p&gt;L7 LB 现在一般都内置高级负载均衡的特性，例如超时、重试、限速、熔断（
circuit breaking）、流量镜像（shadowing）、缓存、基于内容的路由等等。&lt;/p&gt;

&lt;h3 id=&quot;54-可观测性&quot;&gt;5.4 可观测性&lt;/h3&gt;

&lt;p&gt;前面在介绍通用负载均衡器特性时讲到，随着部署的系统越来越动态，debug 也越来越困难
。健壮的&lt;strong&gt;协议特定的&lt;/strong&gt;（protocol specific）可观测性输出可能是现代 L7 LB 提供的最
重要的特性。输出数值统计、分布式跟踪以及自定义日志等功能现在几乎是 L7 负载均衡解
决方案的标配。&lt;/p&gt;

&lt;h3 id=&quot;55-可扩展性&quot;&gt;5.5 可扩展性&lt;/h3&gt;

&lt;p&gt;现代 L7 LB 的用户常常希望能够轻松地对它扩展以添加自定义的功能。这可以通过
编写可插拔的过滤器，然后加载到负载均衡器实现。一些负载均衡器还支持脚本编程，典型
的是通过 &lt;a href=&quot;https://www.lua.org/&quot;&gt;Lua&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;56-容错&quot;&gt;5.6 容错&lt;/h3&gt;

&lt;p&gt;前面介绍了很多 L4 LB 容错的内容。那么 L7 LB 的容错又如何呢？通常来说，我们认
为 L7 LB 是&lt;strong&gt;易消耗的和无状态的&lt;/strong&gt;（expendable and stateless）。基于通用软件使得
L7 负载均衡器可以轻松地实现水平扩展。进一步，L7 LB 的处理过程和状态跟踪比
L4 LB 要复杂的多。搭建一个 L7 LB HA pair 技术上是可行的，但代价相当大。&lt;/p&gt;

&lt;p&gt;总体来说，不管是在 L4 还是在 L7 负载均衡领域，业界都在从 HA pair 架构转向基于一
致性哈希的水平可扩展架构。&lt;/p&gt;

&lt;h3 id=&quot;57-其他&quot;&gt;5.7 其他&lt;/h3&gt;

&lt;p&gt;L7 负载均衡器正在以蹒跚的步伐演进。以 Envoy 作为例子，读者可以查看它的 &lt;a href=&quot;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/arch_overview&quot;&gt;架构综述
&lt;/a&gt;
。&lt;/p&gt;

&lt;h2 id=&quot;6-全局负载均衡和集中式控制平面&quot;&gt;6 全局负载均衡和集中式控制平面&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/global-lb.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图 13：全局负载均衡&lt;/p&gt;

&lt;p&gt;未来的负载均衡会越来越将单个负载均衡器看做通用设备（commodity device）。&lt;strong&gt;我个人
觉得，真正的创新和商业机会全部都会在控制平面&lt;/strong&gt;。图 13 展示了全局负载均衡系统的一
个例子。这个例子包含如下内容：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每个 sidecar 同时和位于三个 zone 的后端通信&lt;/li&gt;
  &lt;li&gt;图上可以看到，90% 的流量到了 zone C，而 zone A 和 B 各只有 5%&lt;/li&gt;
  &lt;li&gt;sidecar 和后端都定期向全局负载均衡器汇报状态。这使得全局负载均衡器可以基于
延迟、代价、负载、当前失败率等参数做出决策&lt;/li&gt;
  &lt;li&gt;全局负载均衡器定期配置每个 sidecar 的路由信息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;全局负载均衡器可以做越来越复杂、单个负载均衡器无法完成的事情。例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;自动检测和路由 zonal failure（可用区级别失败）&lt;/li&gt;
  &lt;li&gt;应用全局安全和路由策略&lt;/li&gt;
  &lt;li&gt;使用机器学习和神经网络技术检测和缓解流量异常，包括 DDoS 攻击&lt;/li&gt;
  &lt;li&gt;提供集中式 UI 和可视化平台，方便工程师理解和运维整个分布式系统&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了实现分布式负载均衡，作为数据平面使用的负载均衡器必须具有支持复杂的动态配置的
能力。这一话题的更多信息请参考我之前关于 &lt;a href=&quot;https://medium.com/@mattklein123/the-universal-data-plane-api-d15cec7a&quot;&gt;Envoy’s universal data plane
API&lt;/a&gt; 以
及&lt;a href=&quot;https://medium.com/@mattklein123/service-mesh-data-plane-vs-control-plane-2774e720f7fc&quot;&gt;service mesh data plane vs. control
plane&lt;/a&gt;
的博客。&lt;/p&gt;

&lt;h2 id=&quot;7-从硬件进化到软件&quot;&gt;7 从硬件进化到软件&lt;/h2&gt;

&lt;p&gt;到目前为止本文只是对硬件和软件做了简要对比，大部分内容是在介绍传统 L4 LB HA pair
的时候。那么，这一领域当前的趋势是什么呢？&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/intro-to-modern-lb/twt-2.png&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面这条 tweet 是一个很幽默的夸张，但确实很好地总结了当前的趋势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从历史来说，路由器和负载均衡器都是厂商提供的专有硬件，非常昂贵&lt;/li&gt;
  &lt;li&gt;越来越多的专有 L3/L4 网络设备被通用服务器、通用网卡，以及基于 &lt;a href=&quot;http://www.linuxvirtualserver.org/software/ipvs.html&quot;&gt;IPVS&lt;/a&gt;、&lt;a href=&quot;http://dpdk.org/&quot;&gt;DPDK&lt;/a&gt;、
fd.io](https://fd.io/) 等框架的特殊软件方案代替。一台现代数据中心的价格 $5K 以
下机器，基于 DPDK 开发用户态应用程序在 Linux 发小包，很容易就可以用满 80Gbps
的网卡带宽。同时，价格便宜的、ECMP 路由聚合带宽能力惊人的基础路由器/交换机
ASICs 正在被组装成通用路由器&lt;/li&gt;
  &lt;li&gt;NGINX、HAProxy 以及 Envoy 这样的功能复杂的 L7 负载均衡器正在快速迭代，并不断侵
蚀原来硬件厂商例如 F5 的地盘。因此，L7 LB 也在非常有气势地朝着通用软件方案迈进&lt;/li&gt;
  &lt;li&gt;同时，工业界几个主要云厂商主导的以 IaaS、CaaS、FaaA 为整体演进的趋势，意味着将
来只有很少一部分工程师需要了解物理的网络是如何工作的（这些就是“黑科技”）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;8-总结及展望&quot;&gt;8 总结及展望&lt;/h2&gt;

&lt;p&gt;最后总结，本文的核心内容：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;负载均衡器是现代分布式系统的一个核心组件&lt;/li&gt;
  &lt;li&gt;有两类通用负载均衡器：L4 和 L7&lt;/li&gt;
  &lt;li&gt;L4 和 L7 负载均衡器在现代架构中都有很重要的应用场景&lt;/li&gt;
  &lt;li&gt;L4 负载均衡器正在朝着&lt;strong&gt;基于分布式一致性哈希的水平可扩展架构&lt;/strong&gt;演进&lt;/li&gt;
  &lt;li&gt;L7 负载均衡器近年来投入的资源非常大，源于最近火热的动态微服务架构的需求&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;全局负载均衡，以及控制平面和数据平面的分离是负载均衡的未来&lt;/strong&gt;，将来大部分创新
和商业机会也都会在这两个方向&lt;/li&gt;
  &lt;li&gt;对于网络解决方案，工业界正在大步迈向&lt;strong&gt;通用开源硬件和软件解决方案&lt;/strong&gt;。我相信传统
负载均衡厂商，比如 F5，会是最先被开源软件和云厂商干掉的。传统路由器/交换机厂商
，例如 Arista/Cumulus等，由于 on-premise deployments （本地部署）的需求，我认
为存在时间会更长一些，但最终会被云厂商和他们的自研物理网络干掉&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体来说，我认为这是计算机网络的一个令人振奋的时代。朝着开源和软件方向的转变使得
大部分系统的迭代速度有了数量级（orders of magnitude）的提高。而且，随着分布系统
基于 serverless 设计，继续朝着&lt;strong&gt;动态化&lt;/strong&gt;的目标长征，底层网络和负载均衡系统的复杂
性也会成比例的（commensurately）增加。&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

</description>
        
        <pubDate>Thu, 21 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/intro-to-modern-lb-and-proxy-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/intro-to-modern-lb-and-proxy-zh/</guid>
        
        
        <category>load-balancing</category>
        
        <category>proxying</category>
        
      </item>
      
    
      
      <item>
        <title>[译] 深入理解 iptables 和 netfilter 架构</title>
        <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

&lt;p&gt;本文翻译自2015年的一篇英文博客 &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture&quot;&gt;A Deep Dive into Iptables and Netfilter
Architecture&lt;/a&gt;
。&lt;/p&gt;

&lt;p&gt;这篇对 iptables 和 netfilter 的设计和原理介绍比较全面，美中不足的是没有那张
内核协议栈各 hook 点位置和 iptables 规则优先级的经典配图，这里补充如下（来自
&lt;a href=&quot;https://upload.wikimedia.org/wikipedia/commons/3/37/Netfilter-packet-flow.svg&quot;&gt;Wikipedia&lt;/a&gt;
）：&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/assets/img/deep-dive-into-iptables-netfilter/Netfilter-packet-flow.svg&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;另外，本文只讲理论，而下面这篇则侧重实战（基于 iptables 做 NAT）：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/nat-zh/&quot;&gt;(译) NAT - 网络地址转换&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;可作为本文的补充阅读。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以下是译文。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;防火墙是保护服务器和基础设施安全的重要工具。在 Linux 生态系统中，&lt;code class=&quot;highlighter-rouge&quot;&gt;iptables&lt;/code&gt; 是使
用很广泛的防火墙工具之一，它基于内核的包过滤框架（packet filtering framework）
&lt;code class=&quot;highlighter-rouge&quot;&gt;netfilter&lt;/code&gt;。如果管理员或用户不了解这些系统的架构，那可能就无法创建出可靠的防火
墙策略，一方面是因为 iptables 的语法颇有挑战性，另外一方面是 netfilter 框架内部
相互交织而变得错综复杂。&lt;/p&gt;

&lt;p&gt;本文将带领读者深入理解 &lt;code class=&quot;highlighter-rouge&quot;&gt;iptables&lt;/code&gt; 框架，让那些需要创建防火墙策略的用户对它有一个
更全面的认识。我们会讨论 iptables 是如何与 netfilter 交互的，几个组件是如何组织
成&lt;strong&gt;一个全面的过滤和矫正系统&lt;/strong&gt;（a comprehensive filtering and mangling system）的。&lt;/p&gt;

&lt;h2 id=&quot;1-iptables-和-netfilter-是什么&quot;&gt;1 IPTables 和 Netfilter 是什么？&lt;/h2&gt;

&lt;p&gt;Linux 上最常用的防火墙工具是 iptables。iptables 与协议栈内有包过滤功能的hook 交
互来完成工作。这些内核 hook 构成了 netfilter 框架。&lt;/p&gt;

&lt;p&gt;每个进入网络系统的包（接收或发送）在经过协议栈时都会触发这些 hook，程序
可以通过&lt;strong&gt;注册 hook 函数&lt;/strong&gt;的方式在一些关键路径上处理网络流量。iptables 相关的内核模
块在这些 hook 点注册了处理函数，因此可以通过配置 iptables 规则来使得网络流量符合
防火墙规则。&lt;/p&gt;

&lt;h2 id=&quot;2-netfilter-hooks&quot;&gt;2. Netfilter Hooks&lt;/h2&gt;

&lt;p&gt;netfilter 提供了 5 个 hook 点。包经过协议栈时会触发&lt;strong&gt;内核模块注册在这里的处理函数&lt;/strong&gt;
。触发哪个 hook 取决于包的方向（是发送还是接收）、包的目的地址、以及包在上一个
hook 点是被丢弃还是拒绝等等。&lt;/p&gt;

&lt;p&gt;下面几个 hook 是内核协议栈中已经定义好的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_PRE_ROUTING&lt;/code&gt;: 接收到的包进入协议栈后立即触发此 hook，在进行任何路由判断
（将包发往哪里）之前&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_LOCAL_IN&lt;/code&gt;: 接收到的包经过路由判断，如果目的是本机，将触发此 hook&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_FORWARD&lt;/code&gt;: 接收到的包经过路由判断，如果目的是其他机器，将触发此 hook&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_LOCAL_OUT&lt;/code&gt;: 本机产生的准备发送的包，在进入协议栈后立即触发此 hook&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_POST_ROUTING&lt;/code&gt;: 本机产生的准备发送的包或者转发的包，在经过路由判断之后，
将触发此 hook&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;注册处理函数时必须提供优先级&lt;/strong&gt;，以便 hook 触发时能按照
优先级高低调用处理函数。这使得&lt;strong&gt;多个模块（或者同一内核模块的多个实例）可以在同一
hook 点注册，并且有确定的处理顺序&lt;/strong&gt;。内核模块会依次被调用，每次返回一个结果给
netfilter 框架，提示该对这个包做什么操作。&lt;/p&gt;

&lt;h2 id=&quot;3-iptables-表和链tables-and-chains&quot;&gt;3 IPTables 表和链（Tables and Chains）&lt;/h2&gt;

&lt;p&gt;iptables 使用 table 来组织规则，根据&lt;strong&gt;用来做什么类型的判断&lt;/strong&gt;（the type of
decisions they are used to make）标准，将规则分为不同table。例如，如果规则是处理
网络地址转换的，那会放到 &lt;code class=&quot;highlighter-rouge&quot;&gt;nat&lt;/code&gt; table；如果是判断是否允许包继续向前，那可能会放到
&lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt; table。&lt;/p&gt;

&lt;p&gt;在每个 table 内部，规则被进一步组织成 chain，&lt;strong&gt;内置的 chain 是由内置的 hook 触发
的&lt;/strong&gt;。chain 基本上能决定（basically determin）规则&lt;strong&gt;何时&lt;/strong&gt;被匹配。&lt;/p&gt;

&lt;p&gt;下面可以看出，内置的 chain 名字和 netfilter hook 名字是一一对应的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PREROUTING&lt;/code&gt;: 由 &lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_PRE_ROUTING&lt;/code&gt; hook 触发&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;INPUT&lt;/code&gt;: 由 &lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_LOCAL_IN&lt;/code&gt; hook 触发&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;FORWARD&lt;/code&gt;: 由 &lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_FORWARD&lt;/code&gt; hook 触发&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OUTPUT&lt;/code&gt;: 由 &lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_LOCAL_OUT&lt;/code&gt; hook 触发&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;POSTROUTING&lt;/code&gt;: 由 &lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_POST_ROUTING&lt;/code&gt; hook 触发&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;chain 使管理员可以控制在&lt;strong&gt;包的传输路径上哪个点&lt;/strong&gt;（where in a packet’s delivery
path）应用策略。因为每个 table 有多个 chain，因此一个 table 可以在处理过程中的多
个地方施加影响。&lt;strong&gt;特定类型的规则只在协议栈的特定点有意义，因此并不是每个table 都
会在内核的每个 hook 注册 chain&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;内核一共只有 5 个 netfilter hook，因此不同 table 的 chain 最终都是注册到这几个点
。例如，有三个 table 有 &lt;code class=&quot;highlighter-rouge&quot;&gt;PRETOUTING&lt;/code&gt; chain。当这些 chain 注册到对应的
&lt;code class=&quot;highlighter-rouge&quot;&gt;NF_IP_PRE_ROUTING&lt;/code&gt; hook 点时，它们需要指定优先级，应该依次调用哪个 table 的
&lt;code class=&quot;highlighter-rouge&quot;&gt;PRETOUTING&lt;/code&gt; chain，优先级从高到低。我们一会就会看到 chain 的优先级问题。&lt;/p&gt;

&lt;h2 id=&quot;4-table-种类&quot;&gt;4. table 种类&lt;/h2&gt;

&lt;p&gt;先来看看 iptables 提供的 table 类型。这些 table 是按规则类型区分的。&lt;/p&gt;

&lt;h3 id=&quot;41-filter-table&quot;&gt;4.1 Filter Table&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt; table 是最常用的 table 之一，用于&lt;strong&gt;判断是否允许一个包通过&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在防火墙领域，这通常称作“过滤”包（”filtering” packets）。这个 table 提供了防火墙
的一些常见功能。&lt;/p&gt;

&lt;h3 id=&quot;42-nat-table&quot;&gt;4.2 NAT Table&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nat&lt;/code&gt; table 用于实现网络地址转换规则。&lt;/p&gt;

&lt;p&gt;当包进入协议栈的时候，这些规则决定是否以及如何修改包的源/目的地址，以改变包被
路由时的行为。&lt;code class=&quot;highlighter-rouge&quot;&gt;nat&lt;/code&gt; table 通常用于将包路由到无法直接访问的网络。&lt;/p&gt;

&lt;h3 id=&quot;43-mangle-table&quot;&gt;4.3 Mangle Table&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mangle&lt;/code&gt; （修正）table 用于&lt;strong&gt;修改包的 IP 头&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;例如，可以修改包的 TTL，增加或减少包可以经过的跳数。&lt;/p&gt;

&lt;p&gt;这个 table 还可以对包打&lt;strong&gt;只在内核内有效的&lt;/strong&gt;“标记”（internal kernel “mark”），后
续的 table 或工具处理的时候可以用到这些标记。标记不会修改包本身，只是在包的内核
表示上做标记。&lt;/p&gt;

&lt;h3 id=&quot;44-raw-table&quot;&gt;4.4 Raw Table&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;iptables 防火墙是有状态的&lt;/strong&gt;：对每个包进行判断的时候是&lt;strong&gt;依赖已经判断过的包&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;建立在 netfilter 之上的连接跟踪（connection tracking）特性&lt;strong&gt;使得 iptables 将包
看作已有的连接或会话的一部分&lt;/strong&gt;，而不是一个由独立、不相关的包组成的流。连接跟踪逻
辑在包到达网络接口之后很快就应用了。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;raw&lt;/code&gt; table 定义的功能非常有限，其&lt;strong&gt;唯一目的就是提供一个让包绕过连接跟踪的框架&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;45-security-table&quot;&gt;4.5 Security Table&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;security&lt;/code&gt; table 的作用是给包打上 SELinux 标记，以此影响 SELinux 或其他可以解读
SELinux 安全上下文的系统处理包的行为。这些标记可以基于单个包，也可以基于连接。&lt;/p&gt;

&lt;h2 id=&quot;5-每种-table-实现的-chain&quot;&gt;5 每种 table 实现的 chain&lt;/h2&gt;

&lt;p&gt;前面已经分别讨论了 table 和 chain，接下来看每个 table 里各有哪些 chain。另外，我
们还将讨论注册到同一 hook 的不同 chain 的优先级问题。例如，如果三个 table 都有
&lt;code class=&quot;highlighter-rouge&quot;&gt;PRETOUTING&lt;/code&gt; chain，那应该按照什么顺序调用它们呢？&lt;/p&gt;

&lt;p&gt;下面的表格展示了 table 和 chain 的关系。横向是 table， 纵向是 chain，Y 表示 这个
table 里面有这个 chain。例如，第二行表示 &lt;code class=&quot;highlighter-rouge&quot;&gt;raw&lt;/code&gt; table 有&lt;code class=&quot;highlighter-rouge&quot;&gt;PRETOUTING&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;OUTPUT&lt;/code&gt; 两
个 chain。具体到每列，从上倒下的顺序就是netfilter hook 触发的时候，（对应
table 的）chain 被调用的顺序。&lt;/p&gt;

&lt;p&gt;有几点需要说明一下。在下面的图中，&lt;code class=&quot;highlighter-rouge&quot;&gt;nat&lt;/code&gt; table 被细分成了 &lt;code class=&quot;highlighter-rouge&quot;&gt;DNAT&lt;/code&gt; （修改目的地址）
和 &lt;code class=&quot;highlighter-rouge&quot;&gt;SNAT&lt;/code&gt;（修改源地址），以更方便地展示他们的优先级。另外，我们添加了路由决策点
和连接跟踪点，以使得整个过程更完整全面：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Tables/Chains&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;PREROUTING&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;INPUT&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;FORWARD&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;OUTPUT&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;POSTROUTING&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;(路由判断)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;raw&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;(连接跟踪）&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;mangle&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;nat (DNAT)&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;(路由判断)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;filter&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;security&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;nat (SNAT)&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Y&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;当一个包触发 netfilter hook 时，处理过程将沿着列从上向下执行。&lt;/strong&gt; 触发哪个 hook
（列）和包的方向（ingress/egress）、路由判断、过滤条件等相关。&lt;/p&gt;

&lt;p&gt;特定事件会导致 table 的 chain 被跳过。例如，只有每个连接的第一个包会去匹配 NAT
规则，对这个包的动作会应用于此连接后面的所有包。到这个连接的应答包会被自动应用反
方向的 NAT 规则。&lt;/p&gt;

&lt;h3 id=&quot;chain-遍历优先级&quot;&gt;Chain 遍历优先级&lt;/h3&gt;

&lt;p&gt;假设服务器知道如何路由数据包，而且防火墙允许数据包传输，下面就是不同场景下包的游
走流程：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;收到的、目的是本机的包：&lt;code class=&quot;highlighter-rouge&quot;&gt;PRETOUTING&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;INPUT&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;收到的、目的是其他主机的包：&lt;code class=&quot;highlighter-rouge&quot;&gt;PRETOUTING&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;FORWARD&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;POSTROUTING&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;本地产生的包：&lt;code class=&quot;highlighter-rouge&quot;&gt;OUTPUT&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;POSTROUTING&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;综合前面讨论的 table 顺序问题，我们可以看到对于一个收到的、目的是本机的包&lt;/strong&gt;：
首先依次经过 &lt;code class=&quot;highlighter-rouge&quot;&gt;PRETOUTING&lt;/code&gt; chain 上面的 &lt;code class=&quot;highlighter-rouge&quot;&gt;raw&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;mangle&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;nat&lt;/code&gt; table；然后依次经
过&lt;code class=&quot;highlighter-rouge&quot;&gt;INPUT&lt;/code&gt; chain 的 &lt;code class=&quot;highlighter-rouge&quot;&gt;mangle&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;security&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;nat&lt;/code&gt; table，然后才会到达本机
的某个 socket。&lt;/p&gt;

&lt;h2 id=&quot;6-iptables-规则&quot;&gt;6 IPTables 规则&lt;/h2&gt;

&lt;p&gt;规则放置在特定 table 的特定 chain 里面。当 chain 被调用的时候，包会依次匹配chain
里面的规则。每条规则都有一个匹配部分和一个动作部分。&lt;/p&gt;

&lt;h3 id=&quot;61-匹配&quot;&gt;6.1 匹配&lt;/h3&gt;

&lt;p&gt;规则的匹配部分指定了一些条件，包必须满足这些条件才会和相应的将要执行的动作（“
target”）进行关联。&lt;/p&gt;

&lt;p&gt;匹配系统非常灵活，还可以通过 iptables extension大大扩展其功能。规则可以匹配&lt;strong&gt;协
议类型、目的或源地址、目的或源端口、目的或源网段、接收或发送的接口（网卡）、协议
头、连接状态&lt;/strong&gt;等等条件。这些综合起来，能够组合成非常复杂的规则来区分不同的网络流
量。&lt;/p&gt;

&lt;h3 id=&quot;62-目标&quot;&gt;6.2 目标&lt;/h3&gt;

&lt;p&gt;包符合某种规则的条件而触发的动作（action）叫做目标（target）。目标分为两种类型：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;终止目标&lt;/strong&gt;（terminating targets）：这种 target 会终止 chain 的匹配，将控制权
转移回 netfilter hook。根据返回值的不同，hook 或者将包丢弃，或者允许包进行下一
阶段的处理&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;非终止目标&lt;/strong&gt;（non-terminating targets）：非终止目标执行动作，然后继续 chain
的执行。虽然每个 chain 最终都会回到一个终止目标，但是在这之前，可以执行任意多
个非终止目标&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个规则可以跳转到哪个 target 依上下文而定，例如，table 和 chain 可能会设置
target 可用或不可用。规则里激活的 extensions 和匹配条件也影响 target 的可用性。&lt;/p&gt;

&lt;h2 id=&quot;7-跳转到用户自定义-chain&quot;&gt;7 跳转到用户自定义 chain&lt;/h2&gt;

&lt;p&gt;这里要介绍一种特殊的非终止目标：跳转目标（jump target）。jump target 是跳转到其
他 chain 继续处理的动作。我们已经讨论了很多内置的 chain，它们和调用它们的
netfilter hook 紧密联系在一起。然而，iptables 也支持管理员创建他们自己的用于管理
目的的 chain。&lt;/p&gt;

&lt;p&gt;向用户自定义 chain 添加规则和向内置的 chain 添加规则的方式是相同的。&lt;strong&gt;不同的地方
在于，用户定义的 chain 只能通过从另一个规则跳转（jump）到它，因为它们没有注册到
netfilter hook&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;用户定义的 chain 可以看作是对调用它的 chain 的扩展。例如，用户定义的 chain 在结
束的时候，可以返回 netfilter hook，也可以继续跳转到其他自定义 chain。&lt;/p&gt;

&lt;p&gt;这种设计使框架具有强大的分支功能，使得管理员可以组织更大更复杂的网络规则。&lt;/p&gt;

&lt;h2 id=&quot;8-iptables-和连接跟踪&quot;&gt;8 IPTables 和连接跟踪&lt;/h2&gt;

&lt;p&gt;在讨论 &lt;code class=&quot;highlighter-rouge&quot;&gt;raw&lt;/code&gt; table 和 匹配连接状态的时候，我们介绍了构建在 netfilter 之上的连
接跟踪系统。连接跟踪系统使得 iptables 基于连接上下文而不是单个包来做出规则判
断，给 iptables 提供了有状态操作的功能。&lt;/p&gt;

&lt;p&gt;连接跟踪在包进入协议栈之后很快（very soon）就开始工作了。在给包分配连接之前所做
的工作非常少，只有检查 &lt;code class=&quot;highlighter-rouge&quot;&gt;raw&lt;/code&gt; table 和一些基本的完整性检查。&lt;/p&gt;

&lt;p&gt;跟踪系统将包和已有的连接进行比较，如果包所属的连接已经存在就更新连接状态，否则就
创建一个新连接。如果 &lt;code class=&quot;highlighter-rouge&quot;&gt;raw&lt;/code&gt; table 的某个 chain 对包标记为目标是 &lt;code class=&quot;highlighter-rouge&quot;&gt;NOTRACK&lt;/code&gt;，那这
个包会跳过连接跟踪系统。&lt;/p&gt;

&lt;h3 id=&quot;连接的状态&quot;&gt;连接的状态&lt;/h3&gt;

&lt;p&gt;连接跟踪系统中的连接状态有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NEW&lt;/code&gt;：如果到达的包关连不到任何已有的连接，但包是合法的，就为这个包创建一个新连接。对
面向连接的（connection-aware）的协议例如 TCP 以及非面向连接的（connectionless
）的协议例如 UDP 都适用&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ESTABLISHED&lt;/code&gt;：当一个连接收到应答方向的合法包时，状态从 &lt;code class=&quot;highlighter-rouge&quot;&gt;NEW&lt;/code&gt; 变成
&lt;code class=&quot;highlighter-rouge&quot;&gt;ESTABLISHED&lt;/code&gt;。对 TCP 这个合法包其实就是 &lt;code class=&quot;highlighter-rouge&quot;&gt;SYN/ACK&lt;/code&gt; 包；对 UDP 和 ICMP 是源和目
的 IP 与原包相反的包&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RELATED&lt;/code&gt;：包不属于已有的连接，但是和已有的连接有一定关系。这可能是辅助连接（
helper connection），例如 FTP 数据传输连接，或者是其他协议试图建立连接时的
ICMP 应答包&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;INVALID&lt;/code&gt;：包不属于已有连接，并且因为某些原因不能用来创建一个新连接，例如无法
识别、无法路由等等&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UNTRACKED&lt;/code&gt;：如果在 &lt;code class=&quot;highlighter-rouge&quot;&gt;raw&lt;/code&gt; table 中标记为目标是 &lt;code class=&quot;highlighter-rouge&quot;&gt;UNTRACKED&lt;/code&gt;，这个包将不会进入连
接跟踪系统&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SNAT&lt;/code&gt;：包的源地址被 NAT 修改之后会进入的虚拟状态。连接跟踪系统据此在收到
反向包时对地址做反向转换&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DNAT&lt;/code&gt;：包的目的地址被 NAT 修改之后会进入的虚拟状态。连接跟踪系统据此在收到
反向包时对地址做反向转换&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些状态可以定位到连接生命周期内部，管理员可以编写出更加细粒度、适用范围更大、更
安全的规则。&lt;/p&gt;

&lt;h2 id=&quot;9-总结&quot;&gt;9 总结&lt;/h2&gt;

&lt;p&gt;netfilter 包过滤框架和 iptables 防火墙是 Linux 服务器上大部分防火墙解决方案的基
础。netfilter 的内核 hook 和协议栈足够紧密，提供了包经过系统时的强大控制功能。
iptables 防火墙基于这些功能提供了一个灵活的、可扩展的、将策略需求转化到内核的方
法。理解了这些不同部分是如何联系到一起的，就可以使用它们控制和保护你的的服务器环
境。&lt;/p&gt;

&lt;p&gt;想了解更多 iptables 使用方式，参考这个&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-choose-an-effective-firewall-policy-to-secure-your-servers&quot;&gt;教程
&lt;/a&gt;
。&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;译者序&quot;&gt;译者序&lt;/h3&gt;

</description>
        
        <pubDate>Mon, 18 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:4000/blog/deep-dive-into-iptables-and-netfilter-arch-zh/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/blog/deep-dive-into-iptables-and-netfilter-arch-zh/</guid>
        
        
        <category>iptables</category>
        
        <category>netfilter</category>
        
      </item>
      
    
  </channel>
</rss>
